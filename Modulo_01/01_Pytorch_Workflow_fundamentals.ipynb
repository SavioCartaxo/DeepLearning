{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba7434b9",
   "metadata": {},
   "source": [
    "# O que aprenderei neste módulo?\n",
    "\n",
    "Qual o caminho para treinar uma IA com oq aprendemos até agora?\n",
    "\n",
    "<ol>\n",
    "    <li>Preparar dados</li>\n",
    "    <li>construir o modelo</li>\n",
    "    <li>ajustar o modelo aos dados (treinamento)</li>\n",
    "    <li>fazer previsões e avaliar um modelo (inferência)</li>\n",
    "    <li>salvar e carregar o modelo</li>\n",
    "    <li>juntar tudo</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c7ddc54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn # nn contém todos os blocos de construção do PyTorch para redes neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b8a8a2",
   "metadata": {},
   "source": [
    "## Machine Learn é dividido em 2 partes\n",
    "\n",
    "<ol>\n",
    "    <li>Tratar dados e os Transformar em Números</li>\n",
    "    <li>Escolher ou construir um modelo para aprender da melhor forma possivel</li>\n",
    "</ol>\n",
    "\n",
    "Para evitar ter que pegar outros dados no momento, iremos criar os nossos dados utilizando Regrassão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5d5c60db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1) # Tensor 1 - Entrada\n",
    "\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "y = weight * X + bias                               # Tensor 2 - Saida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a73d0f",
   "metadata": {},
   "source": [
    "# Dividir os dados em treino, teste e validação\n",
    "\n",
    "Por enquanto, vou dividir apenas em Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4e92ada5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dividindo em Treino e Test\n",
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1eae6fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para ajudar na vizualização dos dados\n",
    "\n",
    "def plot_predictions(train_data=X_train, \n",
    "                     train_labels=y_train, \n",
    "                     test_data=X_test, \n",
    "                     test_labels=y_test, \n",
    "                     predictions=None):\n",
    "  \n",
    "  #Plots training data, test data and compares predictions.\n",
    "  \n",
    "  plt.figure(figsize=(10, 7))\n",
    "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\") # Plot training data in blue\n",
    "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")    # Plot test data in green\n",
    "\n",
    "  if predictions is not None:\n",
    "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")   # Plot the predictions in red (predictions were made on the test data)\n",
    "\n",
    "  plt.legend(prop={\"size\": 14}) # Show the legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fbee7b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "844ae60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module): # nn.Model\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # nn.Parameter\n",
    "        self.weights = nn.Parameter(torch.randn(1,                 #comece com pesos aleatórios \n",
    "                                                dtype=torch.float, # Pytorch funciona bem com float32 como padrão\n",
    "                                                requires_grad=True # podemos atualizar esse valor com gradiente descendente?\n",
    "                                                )\n",
    "                                   )\n",
    "        \n",
    "        self.bias = nn.Parameter(torch.randn(1,                    #comece com pesos aleatórios \n",
    "                                                dtype=torch.float, # Pytorch funciona bem com float32 como padrão\n",
    "                                                requires_grad=True # podemos atualizar esse valor com gradiente descendente?\n",
    "                                            )\n",
    "                                )\n",
    "\n",
    "    # Forward define o calculo no modelo\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor: # <- \"x\" is the input data (e.g. training/testing features)\n",
    "        return self.weights * x + self.bias # <- this is the linear regression formula (y = m*x + b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885d5049",
   "metadata": {},
   "source": [
    "## Layers\n",
    "\n",
    "Uma layer é um bloco de processamento dentro de uma rede neural.\n",
    "Ela recebe um tensor como entrada, faz uma transformação matemática e produz outro tensor como saída.\n",
    "\n",
    "<br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d14bc7",
   "metadata": {},
   "source": [
    "### PyTorch tem quatro modelos essenciais (mais ou menos) que você pode usar para criar quase qualquer tipo de rede neural que você possa imaginar.\n",
    "\n",
    "<ol>\n",
    "    <li>torch.nn</li>\n",
    "    Contém todos os blocos de construção para gráficos computacionais (essencialmente uma série de cálculos executados de uma maneira específica).\n",
    "    <br><br>\n",
    "    <li>torch.nn.Parameter</li>\n",
    "    Armazena tensores que podem ser usados ​​com nn.Module. Se os gradientes require_grad=True (usados ​​para atualizar os parâmetros do modelo por meio da descida do gradiente) forem calculados automaticamente, isso geralmente é chamado de \"autograd\"\n",
    "    <br><br>\n",
    "    <li>torch.nn.Module</li>\n",
    "    A classe base para todos os módulos de rede neural, todos os blocos de construção de redes neurais são subclasses. Se você estiver construindo uma rede neural no PyTorch, seus modelos deverão ser uma subclasse nn.Module. Requer que um método forward() seja implementado.\n",
    "    <br><br>\n",
    "    <li>torch.optim</li>\n",
    "    Contém vários algoritmos de otimização (eles informam aos parâmetros do modelo armazenados em nn.Parameter como alterar melhor para melhorar a descida do gradiente e, por sua vez, reduzir a perda).\n",
    "    <br><br>\n",
    "    <li>def forward()</li>\n",
    "    Todas as subclasses nn.Module requerem um método forward(), que define o cálculo que ocorrerá nos dados passados ​​para o nn.Module específico (por exemplo, a fórmula de regressão linear acima).\n",
    "</ol>\n",
    "\n",
    "Em resumo:\n",
    "<ol>\n",
    "    <li>nn.Module contém os blocos de construção maiores (camadas)</li>\n",
    "    <li>nn.Parameter contém os parâmetros menores, como pesos e tendências (junte-os para formar nn.Module(s))</li>\n",
    "    <li>forward() informa aos blocos maiores como fazer cálculos nas entradas (tensores cheios de dados) dentro de nn.Module(s)</li>\n",
    "    <li>torch.optim contém métodos de otimização sobre como melhorar os parâmetros dentro de nn.Parameter para representar melhor os dados de entrada</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a445ea7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([0.3367], requires_grad=True), Parameter containing:\n",
      "tensor([0.1288], requires_grad=True)]\n",
      "\n",
      " OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])\n"
     ]
    }
   ],
   "source": [
    "# Seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Instancia do Modelo\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "# Checa os nn.Parameter que criamos\n",
    "print(list(model_0.parameters()))\n",
    "\n",
    "# Também podemos obter o estado (o que o modelo contém) do modelo usando .state_dict()\n",
    "print(\"\\n\", model_0.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99654641",
   "metadata": {},
   "source": [
    "## Fazendo previsões usando torch.inference_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "64101ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing samples: 10\n",
      "Number of predictions made: 10\n",
      "Predicted values:\n",
      "tensor([[0.3982],\n",
      "        [0.4049],\n",
      "        [0.4116],\n",
      "        [0.4184],\n",
      "        [0.4251],\n",
      "        [0.4318],\n",
      "        [0.4386],\n",
      "        [0.4453],\n",
      "        [0.4520],\n",
      "        [0.4588]])\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode(): # Ideal para inferência (previsão), não para treino\n",
    "    y_preds = model_0(X_test)\n",
    "\n",
    "# Inferência é quando um modelo já treinado faz uma previsão.\n",
    "\n",
    "# Check the predictions\n",
    "print(f\"Number of testing samples: {len(X_test)}\") \n",
    "print(f\"Number of predictions made: {len(y_preds)}\")\n",
    "print(f\"Predicted values:\\n{y_preds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7a226127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checagem dos resultados\n",
    "\n",
    "plot_predictions(predictions=y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2dc360",
   "metadata": {},
   "source": [
    "Está longe do esperado, mas isso é obvio, pois estamos apenas utilizando números aleatórios para gerar essa previsão. então algo precisa ser feito...\n",
    "<br><hr>\n",
    "\n",
    "# Treinando o Modelo\n",
    "\n",
    "Para corrigir isso, podemos atualizar seus parâmetros internos (também me refiro aos parâmetros como padrões), os pesos e valores de polarização que definimos aleatoriamente usando nn.Parameter() e torch.randn() para ser algo que melhor represente os dados.\n",
    "\n",
    "Precisamos de 2 funções\n",
    "<ol>\n",
    "<li>Funções de perda(loos function): mostra o quão erradas estão as previsões do modelo - existem algumas prontas em torch.nn</li>\n",
    "\n",
    "- Dependendo do tipo de problema em que você está trabalhando, dependerá de qual função de perda e de qual otimizador você usa.\n",
    "\n",
    "- No entanto, existem alguns valores comuns que funcionam bem, como o SGD (descida gradiente estocástica) ou o otimizador Adam. E a função de perda MAE (erro médio absoluto) para problemas de regressão (previsão de um número) ou função de perda de entropia cruzada binária para problemas de classificação (previsão de uma coisa ou de outra).\n",
    "\n",
    "- Para o nosso problema, como estamos prevendo um número, vamos usar MAE (que está em torch.nn.L1Loss()) no PyTorch como nossa função de perda.\n",
    "\n",
    "- O erro absoluto médio (MAE, em PyTorch: torch.nn.L1Loss) mede a diferença absoluta entre dois pontos (previsões e rótulos) e, em seguida, calcula a média de todos os exemplos.\n",
    "\n",
    "<li>params são os parâmetros do modelo alvo que você deseja otimizar (por exemplo, os pesos e valores de tendência que definimos aleatoriamente antes).</li>\n",
    "\n",
    "- Optimizer: Ele usa o erro calculado para ajustar os pesos, tentando diminuir o erro na próxima tentativa. - existem algumas prontas em torch.optim\n",
    "\n",
    "- Usaremos SGD, torch.optim.SGD(params, lr) onde:\n",
    "\n",
    "- params são os parâmetros do modelo alvo que você deseja otimizar (por exemplo, os pesos e valores de tendência que definimos aleatoriamente antes).\n",
    "- lr é a taxa de aprendizado na qual você gostaria que o otimizador atualizasse os parâmetros, maior significa que o otimizador tentará atualizações maiores (às vezes podem ser muito grandes e o otimizador não funcionará), menor significa que o otimizador tentará atualizações menores (às vezes podem ser muito pequenas e o otimizador demorará muito para encontrar os valores ideais). A taxa de aprendizado é considerada um hiperparâmetro (porque é definida por um engenheiro de aprendizado de máquina). Os valores iniciais comuns para a taxa de aprendizagem são 0,01, 0,001, 0,0001; no entanto, também podem ser ajustados ao longo do tempo (isso é chamado de programação da taxa de aprendizagem).\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "378b05fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss() # MAE\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), # parâmetros do modelo alvo para otimizar\n",
    "                           lr=0.001 # taxa de aprendizado -- Learn rate -- quanto o otimizador deve alterar os parâmetros em cada etapa, maior=mais (menos estável), menor=menos (pode levar muito tempo)\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e0fb19",
   "metadata": {},
   "source": [
    "# Loop de treino\n",
    "\n",
    "Agora que temos o modelo e as funções de perda e otimização, precisamos fazer um loop de treino e teste, comparando feature e labels\n",
    "\n",
    "Para o loop de treinamento, construiremos as seguintes etapas:\n",
    "\n",
    "<ol>\n",
    "\n",
    "<li>Passar por cada um dos elementos</li>\n",
    "\n",
    "- O modelo passa por todos os dados de treinamento uma vez, realizando os cálculos da função forward().\n",
    "- model(x_train)\n",
    "\n",
    "<li>Calcula a perda</li>\n",
    "\n",
    "- Os resultados do modelo (previsões) são comparados com a verdade básica e avaliados para ver até que ponto estão errados.\n",
    "- loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "<li>zera os gradiantes</li>\n",
    "\n",
    "- Os gradientes dos otimizadores são definidos como zero (eles são acumulados por padrão) para que possam ser recalculados para a etapa de treinamento específica.\n",
    "- optimizer.zero_grad()\n",
    "\n",
    "<li>Execute retropropagação na perda</li>\n",
    "\n",
    "- Calcula o gradiente da perda em relação a cada parâmetro do modelo a ser atualizado (cada parâmetro com require_grad=True). Isso é conhecido como retropropagação, portanto, \"para trás\"\n",
    "- loss.backward()\n",
    "\n",
    "<li>Atualize o otimizador (gradiente descendente)</li>\n",
    "\n",
    "- Atualize os parâmetros com require_grad=True em relação aos gradientes de perda para melhorá-los.\n",
    "- optimizer.step()\n",
    "\n",
    "</ol>\n",
    "\n",
    "<img src=\"01_ptyorch_trining_loop.png\" style=\"display:block; margin:auto;\">\n",
    "\n",
    "Ainda, depois do treinamento, é importante fazer comparações com os dados de testes(no caso, vaçidação), para observar se há overfliting.\n",
    "\n",
    "Vamos colocar tudo isso junto e observar o comportamento de 100 epocas de treinamentoe comparando os valores a cada 10 epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d41e2459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | MAE Train Loss: 0.31288138031959534 | MAE Test Loss: 0.4931890368461609 \n",
      "Epoch: 1 | MAE Train Loss: 0.3117292523384094 | MAE Test Loss: 0.4918419420719147 \n",
      "Epoch: 2 | MAE Train Loss: 0.3105771541595459 | MAE Test Loss: 0.49049490690231323 \n",
      "Epoch: 3 | MAE Train Loss: 0.3094250559806824 | MAE Test Loss: 0.48914775252342224 \n",
      "Epoch: 4 | MAE Train Loss: 0.30827295780181885 | MAE Test Loss: 0.4878006875514984 \n",
      "Epoch: 5 | MAE Train Loss: 0.3071208596229553 | MAE Test Loss: 0.4864535331726074 \n",
      "Epoch: 6 | MAE Train Loss: 0.3059687614440918 | MAE Test Loss: 0.4851064682006836 \n",
      "Epoch: 7 | MAE Train Loss: 0.3048166334629059 | MAE Test Loss: 0.48375946283340454 \n",
      "Epoch: 8 | MAE Train Loss: 0.30366456508636475 | MAE Test Loss: 0.48241233825683594 \n",
      "Epoch: 9 | MAE Train Loss: 0.3025124669075012 | MAE Test Loss: 0.48106521368026733 \n",
      "Epoch: 10 | MAE Train Loss: 0.3013603389263153 | MAE Test Loss: 0.4797181189060211 \n",
      "Epoch: 11 | MAE Train Loss: 0.30020827054977417 | MAE Test Loss: 0.4783710837364197 \n",
      "Epoch: 12 | MAE Train Loss: 0.29905614256858826 | MAE Test Loss: 0.4770239293575287 \n",
      "Epoch: 13 | MAE Train Loss: 0.2979040741920471 | MAE Test Loss: 0.47567683458328247 \n",
      "Epoch: 14 | MAE Train Loss: 0.2967519462108612 | MAE Test Loss: 0.47432971000671387 \n",
      "Epoch: 15 | MAE Train Loss: 0.29559987783432007 | MAE Test Loss: 0.47298264503479004 \n",
      "Epoch: 16 | MAE Train Loss: 0.29444774985313416 | MAE Test Loss: 0.47163552045822144 \n",
      "Epoch: 17 | MAE Train Loss: 0.293295681476593 | MAE Test Loss: 0.4702884256839752 \n",
      "Epoch: 18 | MAE Train Loss: 0.2921435832977295 | MAE Test Loss: 0.4689413607120514 \n",
      "Epoch: 19 | MAE Train Loss: 0.2909914553165436 | MAE Test Loss: 0.4675942361354828 \n",
      "Epoch: 20 | MAE Train Loss: 0.28983938694000244 | MAE Test Loss: 0.4662471413612366 \n",
      "Epoch: 21 | MAE Train Loss: 0.28868725895881653 | MAE Test Loss: 0.46490007638931274 \n",
      "Epoch: 22 | MAE Train Loss: 0.287535160779953 | MAE Test Loss: 0.46355295181274414 \n",
      "Epoch: 23 | MAE Train Loss: 0.2863830626010895 | MAE Test Loss: 0.4622058868408203 \n",
      "Epoch: 24 | MAE Train Loss: 0.28523099422454834 | MAE Test Loss: 0.4608587324619293 \n",
      "Epoch: 25 | MAE Train Loss: 0.2840788662433624 | MAE Test Loss: 0.4595116674900055 \n",
      "Epoch: 26 | MAE Train Loss: 0.2829267382621765 | MAE Test Loss: 0.4581645429134369 \n",
      "Epoch: 27 | MAE Train Loss: 0.281774640083313 | MAE Test Loss: 0.45681753754615784 \n",
      "Epoch: 28 | MAE Train Loss: 0.28062254190444946 | MAE Test Loss: 0.45547038316726685 \n",
      "Epoch: 29 | MAE Train Loss: 0.2794705033302307 | MAE Test Loss: 0.454123318195343 \n",
      "Epoch: 30 | MAE Train Loss: 0.2783183455467224 | MAE Test Loss: 0.4527761936187744 \n",
      "Epoch: 31 | MAE Train Loss: 0.2771662771701813 | MAE Test Loss: 0.4514291286468506 \n",
      "Epoch: 32 | MAE Train Loss: 0.27601414918899536 | MAE Test Loss: 0.450082004070282 \n",
      "Epoch: 33 | MAE Train Loss: 0.2748620808124542 | MAE Test Loss: 0.44873490929603577 \n",
      "Epoch: 34 | MAE Train Loss: 0.2737099528312683 | MAE Test Loss: 0.44738784432411194 \n",
      "Epoch: 35 | MAE Train Loss: 0.2725578844547272 | MAE Test Loss: 0.44604071974754333 \n",
      "Epoch: 36 | MAE Train Loss: 0.27140578627586365 | MAE Test Loss: 0.4446936249732971 \n",
      "Epoch: 37 | MAE Train Loss: 0.2702536880970001 | MAE Test Loss: 0.4433465003967285 \n",
      "Epoch: 38 | MAE Train Loss: 0.2691015899181366 | MAE Test Loss: 0.4419994354248047 \n",
      "Epoch: 39 | MAE Train Loss: 0.26794949173927307 | MAE Test Loss: 0.44065237045288086 \n",
      "Epoch: 40 | MAE Train Loss: 0.26679736375808716 | MAE Test Loss: 0.43930521607398987 \n",
      "Epoch: 41 | MAE Train Loss: 0.265645295381546 | MAE Test Loss: 0.43795815110206604 \n",
      "Epoch: 42 | MAE Train Loss: 0.2644931674003601 | MAE Test Loss: 0.43661102652549744 \n",
      "Epoch: 43 | MAE Train Loss: 0.2633410692214966 | MAE Test Loss: 0.4352639615535736 \n",
      "Epoch: 44 | MAE Train Loss: 0.26218897104263306 | MAE Test Loss: 0.4339168071746826 \n",
      "Epoch: 45 | MAE Train Loss: 0.26103687286376953 | MAE Test Loss: 0.43256980180740356 \n",
      "Epoch: 46 | MAE Train Loss: 0.259884774684906 | MAE Test Loss: 0.4312226176261902 \n",
      "Epoch: 47 | MAE Train Loss: 0.2587326467037201 | MAE Test Loss: 0.42987555265426636 \n",
      "Epoch: 48 | MAE Train Loss: 0.25758057832717896 | MAE Test Loss: 0.42852845788002014 \n",
      "Epoch: 49 | MAE Train Loss: 0.2564285099506378 | MAE Test Loss: 0.4271813929080963 \n",
      "Epoch: 50 | MAE Train Loss: 0.2552763819694519 | MAE Test Loss: 0.4258342385292053 \n",
      "Epoch: 51 | MAE Train Loss: 0.2541242837905884 | MAE Test Loss: 0.4244872033596039 \n",
      "Epoch: 52 | MAE Train Loss: 0.25297218561172485 | MAE Test Loss: 0.4231400489807129 \n",
      "Epoch: 53 | MAE Train Loss: 0.2518201172351837 | MAE Test Loss: 0.42179298400878906 \n",
      "Epoch: 54 | MAE Train Loss: 0.2506679892539978 | MAE Test Loss: 0.42044591903686523 \n",
      "Epoch: 55 | MAE Train Loss: 0.24951589107513428 | MAE Test Loss: 0.41909879446029663 \n",
      "Epoch: 56 | MAE Train Loss: 0.24836377799510956 | MAE Test Loss: 0.4177517294883728 \n",
      "Epoch: 57 | MAE Train Loss: 0.24721169471740723 | MAE Test Loss: 0.4164046347141266 \n",
      "Epoch: 58 | MAE Train Loss: 0.2460596114397049 | MAE Test Loss: 0.415057510137558 \n",
      "Epoch: 59 | MAE Train Loss: 0.2449074685573578 | MAE Test Loss: 0.41371044516563416 \n",
      "Epoch: 60 | MAE Train Loss: 0.24375538527965546 | MAE Test Loss: 0.41236335039138794 \n",
      "Epoch: 61 | MAE Train Loss: 0.24260330200195312 | MAE Test Loss: 0.41101622581481934 \n",
      "Epoch: 62 | MAE Train Loss: 0.2414511889219284 | MAE Test Loss: 0.40966910123825073 \n",
      "Epoch: 63 | MAE Train Loss: 0.2402990758419037 | MAE Test Loss: 0.4083220064640045 \n",
      "Epoch: 64 | MAE Train Loss: 0.23914699256420135 | MAE Test Loss: 0.4069749414920807 \n",
      "Epoch: 65 | MAE Train Loss: 0.23799486458301544 | MAE Test Loss: 0.4056278169155121 \n",
      "Epoch: 66 | MAE Train Loss: 0.2368427962064743 | MAE Test Loss: 0.40428075194358826 \n",
      "Epoch: 67 | MAE Train Loss: 0.23569071292877197 | MAE Test Loss: 0.40293365716934204 \n",
      "Epoch: 68 | MAE Train Loss: 0.23453858494758606 | MAE Test Loss: 0.4015865921974182 \n",
      "Epoch: 69 | MAE Train Loss: 0.23338651657104492 | MAE Test Loss: 0.4002394676208496 \n",
      "Epoch: 70 | MAE Train Loss: 0.232234388589859 | MAE Test Loss: 0.398892343044281 \n",
      "Epoch: 71 | MAE Train Loss: 0.23108229041099548 | MAE Test Loss: 0.3975452482700348 \n",
      "Epoch: 72 | MAE Train Loss: 0.22993019223213196 | MAE Test Loss: 0.3961981534957886 \n",
      "Epoch: 73 | MAE Train Loss: 0.22877809405326843 | MAE Test Loss: 0.39485102891921997 \n",
      "Epoch: 74 | MAE Train Loss: 0.2276259958744049 | MAE Test Loss: 0.39350399374961853 \n",
      "Epoch: 75 | MAE Train Loss: 0.22647389769554138 | MAE Test Loss: 0.3921568691730499 \n",
      "Epoch: 76 | MAE Train Loss: 0.22532181441783905 | MAE Test Loss: 0.3908098042011261 \n",
      "Epoch: 77 | MAE Train Loss: 0.22416970133781433 | MAE Test Loss: 0.3894627094268799 \n",
      "Epoch: 78 | MAE Train Loss: 0.223017618060112 | MAE Test Loss: 0.3881155848503113 \n",
      "Epoch: 79 | MAE Train Loss: 0.2218654900789261 | MAE Test Loss: 0.38676849007606506 \n",
      "Epoch: 80 | MAE Train Loss: 0.22071340680122375 | MAE Test Loss: 0.38542139530181885 \n",
      "Epoch: 81 | MAE Train Loss: 0.21956129372119904 | MAE Test Loss: 0.38407427072525024 \n",
      "Epoch: 82 | MAE Train Loss: 0.2184092104434967 | MAE Test Loss: 0.3827272057533264 \n",
      "Epoch: 83 | MAE Train Loss: 0.21725709736347198 | MAE Test Loss: 0.3813800811767578 \n",
      "Epoch: 84 | MAE Train Loss: 0.21610502898693085 | MAE Test Loss: 0.38003304600715637 \n",
      "Epoch: 85 | MAE Train Loss: 0.21495290100574493 | MAE Test Loss: 0.3786858916282654 \n",
      "Epoch: 86 | MAE Train Loss: 0.2138008177280426 | MAE Test Loss: 0.37733882665634155 \n",
      "Epoch: 87 | MAE Train Loss: 0.21264871954917908 | MAE Test Loss: 0.37599173188209534 \n",
      "Epoch: 88 | MAE Train Loss: 0.21149662137031555 | MAE Test Loss: 0.3746446371078491 \n",
      "Epoch: 89 | MAE Train Loss: 0.21034450829029083 | MAE Test Loss: 0.3732975423336029 \n",
      "Epoch: 90 | MAE Train Loss: 0.2091923952102661 | MAE Test Loss: 0.3719504475593567 \n",
      "Epoch: 91 | MAE Train Loss: 0.20804031193256378 | MAE Test Loss: 0.3706033527851105 \n",
      "Epoch: 92 | MAE Train Loss: 0.20688819885253906 | MAE Test Loss: 0.36925622820854187 \n",
      "Epoch: 93 | MAE Train Loss: 0.20573611557483673 | MAE Test Loss: 0.36790916323661804 \n",
      "Epoch: 94 | MAE Train Loss: 0.2045840322971344 | MAE Test Loss: 0.3665620684623718 \n",
      "Epoch: 95 | MAE Train Loss: 0.20343191921710968 | MAE Test Loss: 0.36521491408348083 \n",
      "Epoch: 96 | MAE Train Loss: 0.20227983593940735 | MAE Test Loss: 0.3638678789138794 \n",
      "Epoch: 97 | MAE Train Loss: 0.20112769305706024 | MAE Test Loss: 0.3625207543373108 \n",
      "Epoch: 98 | MAE Train Loss: 0.1999756097793579 | MAE Test Loss: 0.36117368936538696 \n",
      "Epoch: 99 | MAE Train Loss: 0.1988234966993332 | MAE Test Loss: 0.35982653498649597 \n",
      "Epoch: 100 | MAE Train Loss: 0.19767141342163086 | MAE Test Loss: 0.35847947001457214 \n",
      "Epoch: 101 | MAE Train Loss: 0.19651933014392853 | MAE Test Loss: 0.3571323752403259 \n",
      "Epoch: 102 | MAE Train Loss: 0.19536720216274261 | MAE Test Loss: 0.3557852506637573 \n",
      "Epoch: 103 | MAE Train Loss: 0.19421511888504028 | MAE Test Loss: 0.3544381558895111 \n",
      "Epoch: 104 | MAE Train Loss: 0.19306302070617676 | MAE Test Loss: 0.35309112071990967 \n",
      "Epoch: 105 | MAE Train Loss: 0.19191092252731323 | MAE Test Loss: 0.35174399614334106 \n",
      "Epoch: 106 | MAE Train Loss: 0.19075879454612732 | MAE Test Loss: 0.35039690136909485 \n",
      "Epoch: 107 | MAE Train Loss: 0.189606711268425 | MAE Test Loss: 0.34904980659484863 \n",
      "Epoch: 108 | MAE Train Loss: 0.18845462799072266 | MAE Test Loss: 0.3477027118206024 \n",
      "Epoch: 109 | MAE Train Loss: 0.18730251491069794 | MAE Test Loss: 0.3463556468486786 \n",
      "Epoch: 110 | MAE Train Loss: 0.18615040183067322 | MAE Test Loss: 0.34500852227211 \n",
      "Epoch: 111 | MAE Train Loss: 0.18499833345413208 | MAE Test Loss: 0.34366142749786377 \n",
      "Epoch: 112 | MAE Train Loss: 0.18384622037410736 | MAE Test Loss: 0.34231433272361755 \n",
      "Epoch: 113 | MAE Train Loss: 0.18269412219524384 | MAE Test Loss: 0.3409672677516937 \n",
      "Epoch: 114 | MAE Train Loss: 0.1815420240163803 | MAE Test Loss: 0.3396201729774475 \n",
      "Epoch: 115 | MAE Train Loss: 0.18038992583751678 | MAE Test Loss: 0.3382730484008789 \n",
      "Epoch: 116 | MAE Train Loss: 0.17923781275749207 | MAE Test Loss: 0.3369259238243103 \n",
      "Epoch: 117 | MAE Train Loss: 0.17808572947978973 | MAE Test Loss: 0.3355788290500641 \n",
      "Epoch: 118 | MAE Train Loss: 0.17693361639976501 | MAE Test Loss: 0.33423173427581787 \n",
      "Epoch: 119 | MAE Train Loss: 0.1757815182209015 | MAE Test Loss: 0.33288463950157166 \n",
      "Epoch: 120 | MAE Train Loss: 0.17462942004203796 | MAE Test Loss: 0.33153754472732544 \n",
      "Epoch: 121 | MAE Train Loss: 0.17347732186317444 | MAE Test Loss: 0.3301904797554016 \n",
      "Epoch: 122 | MAE Train Loss: 0.1723252385854721 | MAE Test Loss: 0.3288434147834778 \n",
      "Epoch: 123 | MAE Train Loss: 0.17117314040660858 | MAE Test Loss: 0.3274962902069092 \n",
      "Epoch: 124 | MAE Train Loss: 0.17002105712890625 | MAE Test Loss: 0.3261492848396301 \n",
      "Epoch: 125 | MAE Train Loss: 0.1688689887523651 | MAE Test Loss: 0.3248021602630615 \n",
      "Epoch: 126 | MAE Train Loss: 0.16771690547466278 | MAE Test Loss: 0.3234550952911377 \n",
      "Epoch: 127 | MAE Train Loss: 0.16656479239463806 | MAE Test Loss: 0.32210803031921387 \n",
      "Epoch: 128 | MAE Train Loss: 0.16541273891925812 | MAE Test Loss: 0.32076090574264526 \n",
      "Epoch: 129 | MAE Train Loss: 0.1642606407403946 | MAE Test Loss: 0.31941384077072144 \n",
      "Epoch: 130 | MAE Train Loss: 0.16310855746269226 | MAE Test Loss: 0.3180667459964752 \n",
      "Epoch: 131 | MAE Train Loss: 0.16195647418498993 | MAE Test Loss: 0.3167196810245514 \n",
      "Epoch: 132 | MAE Train Loss: 0.1608043909072876 | MAE Test Loss: 0.3153725862503052 \n",
      "Epoch: 133 | MAE Train Loss: 0.15965232253074646 | MAE Test Loss: 0.31402549147605896 \n",
      "Epoch: 134 | MAE Train Loss: 0.15850022435188293 | MAE Test Loss: 0.31267839670181274 \n",
      "Epoch: 135 | MAE Train Loss: 0.1573481261730194 | MAE Test Loss: 0.3113313317298889 \n",
      "Epoch: 136 | MAE Train Loss: 0.15619607269763947 | MAE Test Loss: 0.3099842667579651 \n",
      "Epoch: 137 | MAE Train Loss: 0.15504398941993713 | MAE Test Loss: 0.30863717198371887 \n",
      "Epoch: 138 | MAE Train Loss: 0.1538918912410736 | MAE Test Loss: 0.30729013681411743 \n",
      "Epoch: 139 | MAE Train Loss: 0.15273980796337128 | MAE Test Loss: 0.30594301223754883 \n",
      "Epoch: 140 | MAE Train Loss: 0.15158770978450775 | MAE Test Loss: 0.304595947265625 \n",
      "Epoch: 141 | MAE Train Loss: 0.1504356414079666 | MAE Test Loss: 0.30324888229370117 \n",
      "Epoch: 142 | MAE Train Loss: 0.14928355813026428 | MAE Test Loss: 0.30190175771713257 \n",
      "Epoch: 143 | MAE Train Loss: 0.14813147485256195 | MAE Test Loss: 0.30055469274520874 \n",
      "Epoch: 144 | MAE Train Loss: 0.14697939157485962 | MAE Test Loss: 0.2992075979709625 \n",
      "Epoch: 145 | MAE Train Loss: 0.1458273082971573 | MAE Test Loss: 0.2978605329990387 \n",
      "Epoch: 146 | MAE Train Loss: 0.14467521011829376 | MAE Test Loss: 0.2965134382247925 \n",
      "Epoch: 147 | MAE Train Loss: 0.14352312684059143 | MAE Test Loss: 0.29516634345054626 \n",
      "Epoch: 148 | MAE Train Loss: 0.1423710286617279 | MAE Test Loss: 0.29381924867630005 \n",
      "Epoch: 149 | MAE Train Loss: 0.14121896028518677 | MAE Test Loss: 0.292472243309021 \n",
      "Epoch: 150 | MAE Train Loss: 0.14006686210632324 | MAE Test Loss: 0.2911251187324524 \n",
      "Epoch: 151 | MAE Train Loss: 0.1389147937297821 | MAE Test Loss: 0.28977805376052856 \n",
      "Epoch: 152 | MAE Train Loss: 0.13776269555091858 | MAE Test Loss: 0.28843095898628235 \n",
      "Epoch: 153 | MAE Train Loss: 0.13661061227321625 | MAE Test Loss: 0.28708386421203613 \n",
      "Epoch: 154 | MAE Train Loss: 0.1354585438966751 | MAE Test Loss: 0.2857367992401123 \n",
      "Epoch: 155 | MAE Train Loss: 0.13430646061897278 | MAE Test Loss: 0.2843897342681885 \n",
      "Epoch: 156 | MAE Train Loss: 0.13315437734127045 | MAE Test Loss: 0.28304266929626465 \n",
      "Epoch: 157 | MAE Train Loss: 0.13200227916240692 | MAE Test Loss: 0.28169554471969604 \n",
      "Epoch: 158 | MAE Train Loss: 0.13085021078586578 | MAE Test Loss: 0.2803484797477722 \n",
      "Epoch: 159 | MAE Train Loss: 0.12969812750816345 | MAE Test Loss: 0.279001384973526 \n",
      "Epoch: 160 | MAE Train Loss: 0.12854602932929993 | MAE Test Loss: 0.2776543200016022 \n",
      "Epoch: 161 | MAE Train Loss: 0.1273939311504364 | MAE Test Loss: 0.27630725502967834 \n",
      "Epoch: 162 | MAE Train Loss: 0.12624187767505646 | MAE Test Loss: 0.27496016025543213 \n",
      "Epoch: 163 | MAE Train Loss: 0.12508977949619293 | MAE Test Loss: 0.2736130952835083 \n",
      "Epoch: 164 | MAE Train Loss: 0.12393768876791 | MAE Test Loss: 0.2722659707069397 \n",
      "Epoch: 165 | MAE Train Loss: 0.12278560549020767 | MAE Test Loss: 0.27091890573501587 \n",
      "Epoch: 166 | MAE Train Loss: 0.12163352966308594 | MAE Test Loss: 0.26957181096076965 \n",
      "Epoch: 167 | MAE Train Loss: 0.1204814463853836 | MAE Test Loss: 0.2682247459888458 \n",
      "Epoch: 168 | MAE Train Loss: 0.11932935565710068 | MAE Test Loss: 0.2668776512145996 \n",
      "Epoch: 169 | MAE Train Loss: 0.11817727237939835 | MAE Test Loss: 0.2655305862426758 \n",
      "Epoch: 170 | MAE Train Loss: 0.11702518165111542 | MAE Test Loss: 0.26418352127075195 \n",
      "Epoch: 171 | MAE Train Loss: 0.11587311327457428 | MAE Test Loss: 0.26283639669418335 \n",
      "Epoch: 172 | MAE Train Loss: 0.11476147174835205 | MAE Test Loss: 0.2615393400192261 \n",
      "Epoch: 173 | MAE Train Loss: 0.11370686441659927 | MAE Test Loss: 0.260242223739624 \n",
      "Epoch: 174 | MAE Train Loss: 0.1126522570848465 | MAE Test Loss: 0.258945107460022 \n",
      "Epoch: 175 | MAE Train Loss: 0.11159764230251312 | MAE Test Loss: 0.2576480209827423 \n",
      "Epoch: 176 | MAE Train Loss: 0.11054304987192154 | MAE Test Loss: 0.25635093450546265 \n",
      "Epoch: 177 | MAE Train Loss: 0.10948844254016876 | MAE Test Loss: 0.2550538182258606 \n",
      "Epoch: 178 | MAE Train Loss: 0.10846539586782455 | MAE Test Loss: 0.25380760431289673 \n",
      "Epoch: 179 | MAE Train Loss: 0.10750406980514526 | MAE Test Loss: 0.2525613605976105 \n",
      "Epoch: 180 | MAE Train Loss: 0.10654274374246597 | MAE Test Loss: 0.251315176486969 \n",
      "Epoch: 181 | MAE Train Loss: 0.10558142513036728 | MAE Test Loss: 0.25006893277168274 \n",
      "Epoch: 182 | MAE Train Loss: 0.10462009906768799 | MAE Test Loss: 0.24882273375988007 \n",
      "Epoch: 183 | MAE Train Loss: 0.1036587730050087 | MAE Test Loss: 0.247576504945755 \n",
      "Epoch: 184 | MAE Train Loss: 0.10270978510379791 | MAE Test Loss: 0.24638208746910095 \n",
      "Epoch: 185 | MAE Train Loss: 0.10183751583099365 | MAE Test Loss: 0.2451876401901245 \n",
      "Epoch: 186 | MAE Train Loss: 0.10096526145935059 | MAE Test Loss: 0.24399319291114807 \n",
      "Epoch: 187 | MAE Train Loss: 0.10009298473596573 | MAE Test Loss: 0.24279877543449402 \n",
      "Epoch: 188 | MAE Train Loss: 0.09922071546316147 | MAE Test Loss: 0.24160432815551758 \n",
      "Epoch: 189 | MAE Train Loss: 0.09834843873977661 | MAE Test Loss: 0.24040989577770233 \n",
      "Epoch: 190 | MAE Train Loss: 0.09747617691755295 | MAE Test Loss: 0.2392154484987259 \n",
      "Epoch: 191 | MAE Train Loss: 0.09663032740354538 | MAE Test Loss: 0.2380737066268921 \n",
      "Epoch: 192 | MAE Train Loss: 0.09584285318851471 | MAE Test Loss: 0.23693189024925232 \n",
      "Epoch: 193 | MAE Train Loss: 0.09505538642406464 | MAE Test Loss: 0.23579013347625732 \n",
      "Epoch: 194 | MAE Train Loss: 0.09426790475845337 | MAE Test Loss: 0.23464834690093994 \n",
      "Epoch: 195 | MAE Train Loss: 0.09348044544458389 | MAE Test Loss: 0.23350660502910614 \n",
      "Epoch: 196 | MAE Train Loss: 0.09269297122955322 | MAE Test Loss: 0.23236480355262756 \n",
      "Epoch: 197 | MAE Train Loss: 0.09190551191568375 | MAE Test Loss: 0.23122303187847137 \n",
      "Epoch: 198 | MAE Train Loss: 0.09114636480808258 | MAE Test Loss: 0.23013481497764587 \n",
      "Epoch: 199 | MAE Train Loss: 0.09043945372104645 | MAE Test Loss: 0.22904661297798157 \n",
      "Epoch: 200 | MAE Train Loss: 0.08973254263401031 | MAE Test Loss: 0.22795839607715607 \n",
      "Epoch: 201 | MAE Train Loss: 0.08902563154697418 | MAE Test Loss: 0.22687020897865295 \n",
      "Epoch: 202 | MAE Train Loss: 0.08831872791051865 | MAE Test Loss: 0.22578194737434387 \n",
      "Epoch: 203 | MAE Train Loss: 0.08761182427406311 | MAE Test Loss: 0.22469374537467957 \n",
      "Epoch: 204 | MAE Train Loss: 0.08690490573644638 | MAE Test Loss: 0.22360554337501526 \n",
      "Epoch: 205 | MAE Train Loss: 0.08621595799922943 | MAE Test Loss: 0.22257176041603088 \n",
      "Epoch: 206 | MAE Train Loss: 0.0855853408575058 | MAE Test Loss: 0.22153803706169128 \n",
      "Epoch: 207 | MAE Train Loss: 0.08495471626520157 | MAE Test Loss: 0.2205042839050293 \n",
      "Epoch: 208 | MAE Train Loss: 0.08432409167289734 | MAE Test Loss: 0.2194705307483673 \n",
      "Epoch: 209 | MAE Train Loss: 0.08369346708059311 | MAE Test Loss: 0.21843676269054413 \n",
      "Epoch: 210 | MAE Train Loss: 0.08306284993886948 | MAE Test Loss: 0.21740305423736572 \n",
      "Epoch: 211 | MAE Train Loss: 0.08243221789598465 | MAE Test Loss: 0.21636930108070374 \n",
      "Epoch: 212 | MAE Train Loss: 0.08180160820484161 | MAE Test Loss: 0.21533556282520294 \n",
      "Epoch: 213 | MAE Train Loss: 0.08120343089103699 | MAE Test Loss: 0.21435710787773132 \n",
      "Epoch: 214 | MAE Train Loss: 0.08064477890729904 | MAE Test Loss: 0.21337871253490448 \n",
      "Epoch: 215 | MAE Train Loss: 0.0800861120223999 | MAE Test Loss: 0.21240031719207764 \n",
      "Epoch: 216 | MAE Train Loss: 0.07952746003866196 | MAE Test Loss: 0.2114218920469284 \n",
      "Epoch: 217 | MAE Train Loss: 0.07896880060434341 | MAE Test Loss: 0.21044349670410156 \n",
      "Epoch: 218 | MAE Train Loss: 0.07841013371944427 | MAE Test Loss: 0.20946505665779114 \n",
      "Epoch: 219 | MAE Train Loss: 0.07785148918628693 | MAE Test Loss: 0.2084866464138031 \n",
      "Epoch: 220 | MAE Train Loss: 0.07729282230138779 | MAE Test Loss: 0.20750825107097626 \n",
      "Epoch: 221 | MAE Train Loss: 0.07676678895950317 | MAE Test Loss: 0.206586092710495 \n",
      "Epoch: 222 | MAE Train Loss: 0.07627572864294052 | MAE Test Loss: 0.20566387474536896 \n",
      "Epoch: 223 | MAE Train Loss: 0.07578467577695847 | MAE Test Loss: 0.20474162697792053 \n",
      "Epoch: 224 | MAE Train Loss: 0.07529362291097641 | MAE Test Loss: 0.20381946861743927 \n",
      "Epoch: 225 | MAE Train Loss: 0.07480257004499435 | MAE Test Loss: 0.20289726555347443 \n",
      "Epoch: 226 | MAE Train Loss: 0.0743115097284317 | MAE Test Loss: 0.20197506248950958 \n",
      "Epoch: 227 | MAE Train Loss: 0.07382047176361084 | MAE Test Loss: 0.20105287432670593 \n",
      "Epoch: 228 | MAE Train Loss: 0.07332941144704819 | MAE Test Loss: 0.2001306712627411 \n",
      "Epoch: 229 | MAE Train Loss: 0.072856605052948 | MAE Test Loss: 0.19926562905311584 \n",
      "Epoch: 230 | MAE Train Loss: 0.07242877781391144 | MAE Test Loss: 0.19840054214000702 \n",
      "Epoch: 231 | MAE Train Loss: 0.07200097292661667 | MAE Test Loss: 0.19753551483154297 \n",
      "Epoch: 232 | MAE Train Loss: 0.0715731531381607 | MAE Test Loss: 0.19667045772075653 \n",
      "Epoch: 233 | MAE Train Loss: 0.07114534080028534 | MAE Test Loss: 0.19580543041229248 \n",
      "Epoch: 234 | MAE Train Loss: 0.07071752846240997 | MAE Test Loss: 0.19494035840034485 \n",
      "Epoch: 235 | MAE Train Loss: 0.0702897235751152 | MAE Test Loss: 0.19407527148723602 \n",
      "Epoch: 236 | MAE Train Loss: 0.06986190378665924 | MAE Test Loss: 0.19321021437644958 \n",
      "Epoch: 237 | MAE Train Loss: 0.06943409144878387 | MAE Test Loss: 0.19234518706798553 \n",
      "Epoch: 238 | MAE Train Loss: 0.06902603805065155 | MAE Test Loss: 0.19153812527656555 \n",
      "Epoch: 239 | MAE Train Loss: 0.06865701824426651 | MAE Test Loss: 0.19073110818862915 \n",
      "Epoch: 240 | MAE Train Loss: 0.06828799843788147 | MAE Test Loss: 0.18992407619953156 \n",
      "Epoch: 241 | MAE Train Loss: 0.06791899353265762 | MAE Test Loss: 0.18911704421043396 \n",
      "Epoch: 242 | MAE Train Loss: 0.06754995882511139 | MAE Test Loss: 0.18830999732017517 \n",
      "Epoch: 243 | MAE Train Loss: 0.06718094646930695 | MAE Test Loss: 0.18750298023223877 \n",
      "Epoch: 244 | MAE Train Loss: 0.0668119341135025 | MAE Test Loss: 0.18669594824314117 \n",
      "Epoch: 245 | MAE Train Loss: 0.06644289940595627 | MAE Test Loss: 0.18588891625404358 \n",
      "Epoch: 246 | MAE Train Loss: 0.06607388705015182 | MAE Test Loss: 0.1850818693637848 \n",
      "Epoch: 247 | MAE Train Loss: 0.06570921093225479 | MAE Test Loss: 0.18433372676372528 \n",
      "Epoch: 248 | MAE Train Loss: 0.06539449840784073 | MAE Test Loss: 0.18358558416366577 \n",
      "Epoch: 249 | MAE Train Loss: 0.06507977098226547 | MAE Test Loss: 0.18283741176128387 \n",
      "Epoch: 250 | MAE Train Loss: 0.06476505100727081 | MAE Test Loss: 0.18208928406238556 \n",
      "Epoch: 251 | MAE Train Loss: 0.06445033103227615 | MAE Test Loss: 0.18134114146232605 \n",
      "Epoch: 252 | MAE Train Loss: 0.0641356036067009 | MAE Test Loss: 0.18059298396110535 \n",
      "Epoch: 253 | MAE Train Loss: 0.06382088363170624 | MAE Test Loss: 0.17984485626220703 \n",
      "Epoch: 254 | MAE Train Loss: 0.06350617110729218 | MAE Test Loss: 0.17909672856330872 \n",
      "Epoch: 255 | MAE Train Loss: 0.06319145113229752 | MAE Test Loss: 0.178348571062088 \n",
      "Epoch: 256 | MAE Train Loss: 0.06287673115730286 | MAE Test Loss: 0.1776004284620285 \n",
      "Epoch: 257 | MAE Train Loss: 0.0625620037317276 | MAE Test Loss: 0.1768522709608078 \n",
      "Epoch: 258 | MAE Train Loss: 0.062271296977996826 | MAE Test Loss: 0.1761639267206192 \n",
      "Epoch: 259 | MAE Train Loss: 0.06200631707906723 | MAE Test Loss: 0.17547550797462463 \n",
      "Epoch: 260 | MAE Train Loss: 0.06174134090542793 | MAE Test Loss: 0.17478716373443604 \n",
      "Epoch: 261 | MAE Train Loss: 0.06147634983062744 | MAE Test Loss: 0.17409880459308624 \n",
      "Epoch: 262 | MAE Train Loss: 0.061211369931697845 | MAE Test Loss: 0.17341041564941406 \n",
      "Epoch: 263 | MAE Train Loss: 0.06094638630747795 | MAE Test Loss: 0.17272204160690308 \n",
      "Epoch: 264 | MAE Train Loss: 0.06068141385912895 | MAE Test Loss: 0.1720336377620697 \n",
      "Epoch: 265 | MAE Train Loss: 0.06041641905903816 | MAE Test Loss: 0.1713452786207199 \n",
      "Epoch: 266 | MAE Train Loss: 0.060151439160108566 | MAE Test Loss: 0.17065691947937012 \n",
      "Epoch: 267 | MAE Train Loss: 0.05988645553588867 | MAE Test Loss: 0.16996853053569794 \n",
      "Epoch: 268 | MAE Train Loss: 0.05962147191166878 | MAE Test Loss: 0.16928015649318695 \n",
      "Epoch: 269 | MAE Train Loss: 0.05937860533595085 | MAE Test Loss: 0.1686524599790573 \n",
      "Epoch: 270 | MAE Train Loss: 0.05915876477956772 | MAE Test Loss: 0.16802480816841125 \n",
      "Epoch: 271 | MAE Train Loss: 0.058938927948474884 | MAE Test Loss: 0.16739711165428162 \n",
      "Epoch: 272 | MAE Train Loss: 0.05871908739209175 | MAE Test Loss: 0.16676943004131317 \n",
      "Epoch: 273 | MAE Train Loss: 0.05849923565983772 | MAE Test Loss: 0.16614174842834473 \n",
      "Epoch: 274 | MAE Train Loss: 0.05827939510345459 | MAE Test Loss: 0.16551408171653748 \n",
      "Epoch: 275 | MAE Train Loss: 0.05805954337120056 | MAE Test Loss: 0.16488640010356903 \n",
      "Epoch: 276 | MAE Train Loss: 0.05783969908952713 | MAE Test Loss: 0.16425874829292297 \n",
      "Epoch: 277 | MAE Train Loss: 0.057619858533144 | MAE Test Loss: 0.16363103687763214 \n",
      "Epoch: 278 | MAE Train Loss: 0.05740001052618027 | MAE Test Loss: 0.1630033701658249 \n",
      "Epoch: 279 | MAE Train Loss: 0.05718017369508743 | MAE Test Loss: 0.16237568855285645 \n",
      "Epoch: 280 | MAE Train Loss: 0.0569603331387043 | MAE Test Loss: 0.161748006939888 \n",
      "Epoch: 281 | MAE Train Loss: 0.05676015466451645 | MAE Test Loss: 0.16118189692497253 \n",
      "Epoch: 282 | MAE Train Loss: 0.05658075958490372 | MAE Test Loss: 0.16061577200889587 \n",
      "Epoch: 283 | MAE Train Loss: 0.05640135332942009 | MAE Test Loss: 0.1600496768951416 \n",
      "Epoch: 284 | MAE Train Loss: 0.05622195079922676 | MAE Test Loss: 0.15948358178138733 \n",
      "Epoch: 285 | MAE Train Loss: 0.05604255199432373 | MAE Test Loss: 0.15891747176647186 \n",
      "Epoch: 286 | MAE Train Loss: 0.0558631531894207 | MAE Test Loss: 0.1583513766527176 \n",
      "Epoch: 287 | MAE Train Loss: 0.05568375438451767 | MAE Test Loss: 0.15778525173664093 \n",
      "Epoch: 288 | MAE Train Loss: 0.05550435930490494 | MAE Test Loss: 0.15721914172172546 \n",
      "Epoch: 289 | MAE Train Loss: 0.05532495304942131 | MAE Test Loss: 0.1566530466079712 \n",
      "Epoch: 290 | MAE Train Loss: 0.05514555424451828 | MAE Test Loss: 0.15608695149421692 \n",
      "Epoch: 291 | MAE Train Loss: 0.05496615171432495 | MAE Test Loss: 0.15552084147930145 \n",
      "Epoch: 292 | MAE Train Loss: 0.05478675290942192 | MAE Test Loss: 0.1549547165632248 \n",
      "Epoch: 293 | MAE Train Loss: 0.05460735410451889 | MAE Test Loss: 0.15438862144947052 \n",
      "Epoch: 294 | MAE Train Loss: 0.05443967133760452 | MAE Test Loss: 0.15388496220111847 \n",
      "Epoch: 295 | MAE Train Loss: 0.05429593846201897 | MAE Test Loss: 0.15338130295276642 \n",
      "Epoch: 296 | MAE Train Loss: 0.05415221303701401 | MAE Test Loss: 0.15287765860557556 \n",
      "Epoch: 297 | MAE Train Loss: 0.05400847643613815 | MAE Test Loss: 0.15237398445606232 \n",
      "Epoch: 298 | MAE Train Loss: 0.05386475846171379 | MAE Test Loss: 0.15187029540538788 \n",
      "Epoch: 299 | MAE Train Loss: 0.05372103303670883 | MAE Test Loss: 0.15136666595935822 \n",
      "Epoch: 300 | MAE Train Loss: 0.05357731133699417 | MAE Test Loss: 0.15086300671100616 \n",
      "Epoch: 301 | MAE Train Loss: 0.05343357473611832 | MAE Test Loss: 0.1503593474626541 \n",
      "Epoch: 302 | MAE Train Loss: 0.05328984931111336 | MAE Test Loss: 0.14985567331314087 \n",
      "Epoch: 303 | MAE Train Loss: 0.0531461238861084 | MAE Test Loss: 0.14935199916362762 \n",
      "Epoch: 304 | MAE Train Loss: 0.05300239473581314 | MAE Test Loss: 0.14884835481643677 \n",
      "Epoch: 305 | MAE Train Loss: 0.052858661860227585 | MAE Test Loss: 0.14834468066692352 \n",
      "Epoch: 306 | MAE Train Loss: 0.052714936435222626 | MAE Test Loss: 0.14784102141857147 \n",
      "Epoch: 307 | MAE Train Loss: 0.052571214735507965 | MAE Test Loss: 0.1473373919725418 \n",
      "Epoch: 308 | MAE Train Loss: 0.05242748185992241 | MAE Test Loss: 0.14683370292186737 \n",
      "Epoch: 309 | MAE Train Loss: 0.05229362100362778 | MAE Test Loss: 0.14639338850975037 \n",
      "Epoch: 310 | MAE Train Loss: 0.05218071490526199 | MAE Test Loss: 0.14595307409763336 \n",
      "Epoch: 311 | MAE Train Loss: 0.05206780880689621 | MAE Test Loss: 0.14551277458667755 \n",
      "Epoch: 312 | MAE Train Loss: 0.05195491388440132 | MAE Test Loss: 0.14507248997688293 \n",
      "Epoch: 313 | MAE Train Loss: 0.05184202268719673 | MAE Test Loss: 0.14463214576244354 \n",
      "Epoch: 314 | MAE Train Loss: 0.05172910541296005 | MAE Test Loss: 0.14419183135032654 \n",
      "Epoch: 315 | MAE Train Loss: 0.05161619931459427 | MAE Test Loss: 0.14375153183937073 \n",
      "Epoch: 316 | MAE Train Loss: 0.05150330066680908 | MAE Test Loss: 0.14331121742725372 \n",
      "Epoch: 317 | MAE Train Loss: 0.0513903982937336 | MAE Test Loss: 0.14287090301513672 \n",
      "Epoch: 318 | MAE Train Loss: 0.05127749592065811 | MAE Test Loss: 0.14243058860301971 \n",
      "Epoch: 319 | MAE Train Loss: 0.05116458982229233 | MAE Test Loss: 0.1419902741909027 \n",
      "Epoch: 320 | MAE Train Loss: 0.05105169489979744 | MAE Test Loss: 0.1415499746799469 \n",
      "Epoch: 321 | MAE Train Loss: 0.05093878507614136 | MAE Test Loss: 0.1411096602678299 \n",
      "Epoch: 322 | MAE Train Loss: 0.05082588270306587 | MAE Test Loss: 0.1406693160533905 \n",
      "Epoch: 323 | MAE Train Loss: 0.05071298032999039 | MAE Test Loss: 0.1402290314435959 \n",
      "Epoch: 324 | MAE Train Loss: 0.0506000742316246 | MAE Test Loss: 0.13978871703147888 \n",
      "Epoch: 325 | MAE Train Loss: 0.050487179309129715 | MAE Test Loss: 0.13934841752052307 \n",
      "Epoch: 326 | MAE Train Loss: 0.050378382205963135 | MAE Test Loss: 0.13897234201431274 \n",
      "Epoch: 327 | MAE Train Loss: 0.050291359424591064 | MAE Test Loss: 0.1385962963104248 \n",
      "Epoch: 328 | MAE Train Loss: 0.050204355269670486 | MAE Test Loss: 0.13822023570537567 \n",
      "Epoch: 329 | MAE Train Loss: 0.050117332488298416 | MAE Test Loss: 0.13784417510032654 \n",
      "Epoch: 330 | MAE Train Loss: 0.050030313432216644 | MAE Test Loss: 0.1374681293964386 \n",
      "Epoch: 331 | MAE Train Loss: 0.049943309277296066 | MAE Test Loss: 0.13709203898906708 \n",
      "Epoch: 332 | MAE Train Loss: 0.0498562827706337 | MAE Test Loss: 0.13671600818634033 \n",
      "Epoch: 333 | MAE Train Loss: 0.049769263714551926 | MAE Test Loss: 0.13633993268013 \n",
      "Epoch: 334 | MAE Train Loss: 0.04968224838376045 | MAE Test Loss: 0.13596387207508087 \n",
      "Epoch: 335 | MAE Train Loss: 0.04959522932767868 | MAE Test Loss: 0.13558778166770935 \n",
      "Epoch: 336 | MAE Train Loss: 0.049508217722177505 | MAE Test Loss: 0.1352117508649826 \n",
      "Epoch: 337 | MAE Train Loss: 0.04942120611667633 | MAE Test Loss: 0.13483569025993347 \n",
      "Epoch: 338 | MAE Train Loss: 0.04933418333530426 | MAE Test Loss: 0.13445964455604553 \n",
      "Epoch: 339 | MAE Train Loss: 0.04924716800451279 | MAE Test Loss: 0.1340835690498352 \n",
      "Epoch: 340 | MAE Train Loss: 0.049160152673721313 | MAE Test Loss: 0.13370750844478607 \n",
      "Epoch: 341 | MAE Train Loss: 0.04907313734292984 | MAE Test Loss: 0.13333146274089813 \n",
      "Epoch: 342 | MAE Train Loss: 0.04898611828684807 | MAE Test Loss: 0.1329553872346878 \n",
      "Epoch: 343 | MAE Train Loss: 0.048899102956056595 | MAE Test Loss: 0.13257935643196106 \n",
      "Epoch: 344 | MAE Train Loss: 0.04881208389997482 | MAE Test Loss: 0.13220326602458954 \n",
      "Epoch: 345 | MAE Train Loss: 0.04872506856918335 | MAE Test Loss: 0.1318272203207016 \n",
      "Epoch: 346 | MAE Train Loss: 0.048638053238391876 | MAE Test Loss: 0.13145115971565247 \n",
      "Epoch: 347 | MAE Train Loss: 0.04855869710445404 | MAE Test Loss: 0.13114026188850403 \n",
      "Epoch: 348 | MAE Train Loss: 0.048492539674043655 | MAE Test Loss: 0.1308293491601944 \n",
      "Epoch: 349 | MAE Train Loss: 0.04842637851834297 | MAE Test Loss: 0.13051843643188477 \n",
      "Epoch: 350 | MAE Train Loss: 0.04836020991206169 | MAE Test Loss: 0.13020753860473633 \n",
      "Epoch: 351 | MAE Train Loss: 0.04829404503107071 | MAE Test Loss: 0.1298966407775879 \n",
      "Epoch: 352 | MAE Train Loss: 0.04822787642478943 | MAE Test Loss: 0.12958571314811707 \n",
      "Epoch: 353 | MAE Train Loss: 0.048161718994379044 | MAE Test Loss: 0.12927480041980743 \n",
      "Epoch: 354 | MAE Train Loss: 0.048095546662807465 | MAE Test Loss: 0.128963902592659 \n",
      "Epoch: 355 | MAE Train Loss: 0.04802938550710678 | MAE Test Loss: 0.12865300476551056 \n",
      "Epoch: 356 | MAE Train Loss: 0.0479632243514061 | MAE Test Loss: 0.12834210693836212 \n",
      "Epoch: 357 | MAE Train Loss: 0.04789705574512482 | MAE Test Loss: 0.1280311793088913 \n",
      "Epoch: 358 | MAE Train Loss: 0.04783089831471443 | MAE Test Loss: 0.12772028148174286 \n",
      "Epoch: 359 | MAE Train Loss: 0.04776472598314285 | MAE Test Loss: 0.12740938365459442 \n",
      "Epoch: 360 | MAE Train Loss: 0.04769856110215187 | MAE Test Loss: 0.12709848582744598 \n",
      "Epoch: 361 | MAE Train Loss: 0.04763239622116089 | MAE Test Loss: 0.12678757309913635 \n",
      "Epoch: 362 | MAE Train Loss: 0.04756623134016991 | MAE Test Loss: 0.12647667527198792 \n",
      "Epoch: 363 | MAE Train Loss: 0.04750007390975952 | MAE Test Loss: 0.12616576254367828 \n",
      "Epoch: 364 | MAE Train Loss: 0.04743390530347824 | MAE Test Loss: 0.12585484981536865 \n",
      "Epoch: 365 | MAE Train Loss: 0.04736773669719696 | MAE Test Loss: 0.12554392218589783 \n",
      "Epoch: 366 | MAE Train Loss: 0.04730157181620598 | MAE Test Loss: 0.1252330243587494 \n",
      "Epoch: 367 | MAE Train Loss: 0.0472353920340538 | MAE Test Loss: 0.12492211908102036 \n",
      "Epoch: 368 | MAE Train Loss: 0.047169238328933716 | MAE Test Loss: 0.12461123615503311 \n",
      "Epoch: 369 | MAE Train Loss: 0.047103073447942734 | MAE Test Loss: 0.12430031597614288 \n",
      "Epoch: 370 | MAE Train Loss: 0.04703690856695175 | MAE Test Loss: 0.12398938834667206 \n",
      "Epoch: 371 | MAE Train Loss: 0.04697074741125107 | MAE Test Loss: 0.12367852032184601 \n",
      "Epoch: 372 | MAE Train Loss: 0.04690460115671158 | MAE Test Loss: 0.12343358993530273 \n",
      "Epoch: 373 | MAE Train Loss: 0.04685414209961891 | MAE Test Loss: 0.12318868935108185 \n",
      "Epoch: 374 | MAE Train Loss: 0.046803683042526245 | MAE Test Loss: 0.12294378131628036 \n",
      "Epoch: 375 | MAE Train Loss: 0.046753231436014175 | MAE Test Loss: 0.12269886583089828 \n",
      "Epoch: 376 | MAE Train Loss: 0.04670276492834091 | MAE Test Loss: 0.122453972697258 \n",
      "Epoch: 377 | MAE Train Loss: 0.046652309596538544 | MAE Test Loss: 0.12220907211303711 \n",
      "Epoch: 378 | MAE Train Loss: 0.04660185053944588 | MAE Test Loss: 0.12196417152881622 \n",
      "Epoch: 379 | MAE Train Loss: 0.04655139893293381 | MAE Test Loss: 0.12171925604343414 \n",
      "Epoch: 380 | MAE Train Loss: 0.04650093987584114 | MAE Test Loss: 0.12147434055805206 \n",
      "Epoch: 381 | MAE Train Loss: 0.04645047336816788 | MAE Test Loss: 0.12122943252325058 \n",
      "Epoch: 382 | MAE Train Loss: 0.04640001803636551 | MAE Test Loss: 0.1209845319390297 \n",
      "Epoch: 383 | MAE Train Loss: 0.046349555253982544 | MAE Test Loss: 0.12073962390422821 \n",
      "Epoch: 384 | MAE Train Loss: 0.04629909247159958 | MAE Test Loss: 0.12049472332000732 \n",
      "Epoch: 385 | MAE Train Loss: 0.04624864086508751 | MAE Test Loss: 0.12024979293346405 \n",
      "Epoch: 386 | MAE Train Loss: 0.046198178082704544 | MAE Test Loss: 0.12000487744808197 \n",
      "Epoch: 387 | MAE Train Loss: 0.046147722750902176 | MAE Test Loss: 0.11975999176502228 \n",
      "Epoch: 388 | MAE Train Loss: 0.04609726741909981 | MAE Test Loss: 0.1195150837302208 \n",
      "Epoch: 389 | MAE Train Loss: 0.04604680463671684 | MAE Test Loss: 0.11927016079425812 \n",
      "Epoch: 390 | MAE Train Loss: 0.045996345579624176 | MAE Test Loss: 0.11902527511119843 \n",
      "Epoch: 391 | MAE Train Loss: 0.04594588279724121 | MAE Test Loss: 0.11878037452697754 \n",
      "Epoch: 392 | MAE Train Loss: 0.04589542746543884 | MAE Test Loss: 0.11853544414043427 \n",
      "Epoch: 393 | MAE Train Loss: 0.04584496468305588 | MAE Test Loss: 0.11829052865505219 \n",
      "Epoch: 394 | MAE Train Loss: 0.045794516801834106 | MAE Test Loss: 0.1180456131696701 \n",
      "Epoch: 395 | MAE Train Loss: 0.04574405029416084 | MAE Test Loss: 0.11780073493719101 \n",
      "Epoch: 396 | MAE Train Loss: 0.045693591237068176 | MAE Test Loss: 0.11755583435297012 \n",
      "Epoch: 397 | MAE Train Loss: 0.04564313963055611 | MAE Test Loss: 0.11731092631816864 \n",
      "Epoch: 398 | MAE Train Loss: 0.04559267684817314 | MAE Test Loss: 0.11706600338220596 \n",
      "Epoch: 399 | MAE Train Loss: 0.045542217791080475 | MAE Test Loss: 0.11682109534740448 \n",
      "Epoch: 400 | MAE Train Loss: 0.04549176245927811 | MAE Test Loss: 0.11657620966434479 \n",
      "Epoch: 401 | MAE Train Loss: 0.04544129967689514 | MAE Test Loss: 0.11633126437664032 \n",
      "Epoch: 402 | MAE Train Loss: 0.04539085179567337 | MAE Test Loss: 0.11608636379241943 \n",
      "Epoch: 403 | MAE Train Loss: 0.04534038156270981 | MAE Test Loss: 0.11584146320819855 \n",
      "Epoch: 404 | MAE Train Loss: 0.04528992623090744 | MAE Test Loss: 0.11559655517339706 \n",
      "Epoch: 405 | MAE Train Loss: 0.04523947089910507 | MAE Test Loss: 0.11535165458917618 \n",
      "Epoch: 406 | MAE Train Loss: 0.045189011842012405 | MAE Test Loss: 0.1151067465543747 \n",
      "Epoch: 407 | MAE Train Loss: 0.04513854905962944 | MAE Test Loss: 0.1148618683218956 \n",
      "Epoch: 408 | MAE Train Loss: 0.04509454965591431 | MAE Test Loss: 0.1146838441491127 \n",
      "Epoch: 409 | MAE Train Loss: 0.045054562389850616 | MAE Test Loss: 0.1145058423280716 \n",
      "Epoch: 410 | MAE Train Loss: 0.045014552772045135 | MAE Test Loss: 0.11432783305644989 \n",
      "Epoch: 411 | MAE Train Loss: 0.04497454687952995 | MAE Test Loss: 0.11414983123540878 \n",
      "Epoch: 412 | MAE Train Loss: 0.04493454843759537 | MAE Test Loss: 0.11397182941436768 \n",
      "Epoch: 413 | MAE Train Loss: 0.04489455372095108 | MAE Test Loss: 0.11379382759332657 \n",
      "Epoch: 414 | MAE Train Loss: 0.044854551553726196 | MAE Test Loss: 0.11361582577228546 \n",
      "Epoch: 415 | MAE Train Loss: 0.044814541935920715 | MAE Test Loss: 0.11343781650066376 \n",
      "Epoch: 416 | MAE Train Loss: 0.04477455094456673 | MAE Test Loss: 0.11325981467962265 \n",
      "Epoch: 417 | MAE Train Loss: 0.044734545052051544 | MAE Test Loss: 0.11308183521032333 \n",
      "Epoch: 418 | MAE Train Loss: 0.04469455033540726 | MAE Test Loss: 0.11290381103754044 \n",
      "Epoch: 419 | MAE Train Loss: 0.04465455189347267 | MAE Test Loss: 0.11272580921649933 \n",
      "Epoch: 420 | MAE Train Loss: 0.04461454600095749 | MAE Test Loss: 0.11254779994487762 \n",
      "Epoch: 421 | MAE Train Loss: 0.0445745475590229 | MAE Test Loss: 0.11236979812383652 \n",
      "Epoch: 422 | MAE Train Loss: 0.04453454539179802 | MAE Test Loss: 0.1121918112039566 \n",
      "Epoch: 423 | MAE Train Loss: 0.044494546949863434 | MAE Test Loss: 0.1120137944817543 \n",
      "Epoch: 424 | MAE Train Loss: 0.04445454478263855 | MAE Test Loss: 0.1118357926607132 \n",
      "Epoch: 425 | MAE Train Loss: 0.044414542615413666 | MAE Test Loss: 0.11165778338909149 \n",
      "Epoch: 426 | MAE Train Loss: 0.04437453672289848 | MAE Test Loss: 0.11147978156805038 \n",
      "Epoch: 427 | MAE Train Loss: 0.0443345345556736 | MAE Test Loss: 0.11130179464817047 \n",
      "Epoch: 428 | MAE Train Loss: 0.04429454356431961 | MAE Test Loss: 0.11112377792596817 \n",
      "Epoch: 429 | MAE Train Loss: 0.04425454139709473 | MAE Test Loss: 0.11094577610492706 \n",
      "Epoch: 430 | MAE Train Loss: 0.04421453922986984 | MAE Test Loss: 0.11076776683330536 \n",
      "Epoch: 431 | MAE Train Loss: 0.04417454078793526 | MAE Test Loss: 0.11058976501226425 \n",
      "Epoch: 432 | MAE Train Loss: 0.04413453862071037 | MAE Test Loss: 0.11041177809238434 \n",
      "Epoch: 433 | MAE Train Loss: 0.04409453272819519 | MAE Test Loss: 0.11023376137018204 \n",
      "Epoch: 434 | MAE Train Loss: 0.0440545380115509 | MAE Test Loss: 0.11005575954914093 \n",
      "Epoch: 435 | MAE Train Loss: 0.04401453956961632 | MAE Test Loss: 0.10987772792577744 \n",
      "Epoch: 436 | MAE Train Loss: 0.04397452995181084 | MAE Test Loss: 0.10969976335763931 \n",
      "Epoch: 437 | MAE Train Loss: 0.04393453150987625 | MAE Test Loss: 0.1095217615365982 \n",
      "Epoch: 438 | MAE Train Loss: 0.043894533067941666 | MAE Test Loss: 0.1093437448143959 \n",
      "Epoch: 439 | MAE Train Loss: 0.04385453090071678 | MAE Test Loss: 0.1091657504439354 \n",
      "Epoch: 440 | MAE Train Loss: 0.043814532458782196 | MAE Test Loss: 0.1089877337217331 \n",
      "Epoch: 441 | MAE Train Loss: 0.043774526566267014 | MAE Test Loss: 0.10880974680185318 \n",
      "Epoch: 442 | MAE Train Loss: 0.043734531849622726 | MAE Test Loss: 0.10863174498081207 \n",
      "Epoch: 443 | MAE Train Loss: 0.04369453340768814 | MAE Test Loss: 0.10845372825860977 \n",
      "Epoch: 444 | MAE Train Loss: 0.04365452378988266 | MAE Test Loss: 0.10827572643756866 \n",
      "Epoch: 445 | MAE Train Loss: 0.04361452907323837 | MAE Test Loss: 0.10809771716594696 \n",
      "Epoch: 446 | MAE Train Loss: 0.04357453063130379 | MAE Test Loss: 0.10791973024606705 \n",
      "Epoch: 447 | MAE Train Loss: 0.043534524738788605 | MAE Test Loss: 0.10774173587560654 \n",
      "Epoch: 448 | MAE Train Loss: 0.04349452629685402 | MAE Test Loss: 0.10756371915340424 \n",
      "Epoch: 449 | MAE Train Loss: 0.043454527854919434 | MAE Test Loss: 0.10738573223352432 \n",
      "Epoch: 450 | MAE Train Loss: 0.04341452196240425 | MAE Test Loss: 0.10720770061016083 \n",
      "Epoch: 451 | MAE Train Loss: 0.043374527245759964 | MAE Test Loss: 0.10702969878911972 \n",
      "Epoch: 452 | MAE Train Loss: 0.04333452507853508 | MAE Test Loss: 0.1068517193198204 \n",
      "Epoch: 453 | MAE Train Loss: 0.043294526636600494 | MAE Test Loss: 0.1066737174987793 \n",
      "Epoch: 454 | MAE Train Loss: 0.04325452446937561 | MAE Test Loss: 0.106495700776577 \n",
      "Epoch: 455 | MAE Train Loss: 0.04321451857686043 | MAE Test Loss: 0.1063176840543747 \n",
      "Epoch: 456 | MAE Train Loss: 0.04317452758550644 | MAE Test Loss: 0.10613970458507538 \n",
      "Epoch: 457 | MAE Train Loss: 0.04313452169299126 | MAE Test Loss: 0.10596170276403427 \n",
      "Epoch: 458 | MAE Train Loss: 0.04309451952576637 | MAE Test Loss: 0.10578368604183197 \n",
      "Epoch: 459 | MAE Train Loss: 0.04305451363325119 | MAE Test Loss: 0.10560569912195206 \n",
      "Epoch: 460 | MAE Train Loss: 0.043014515191316605 | MAE Test Loss: 0.10542766749858856 \n",
      "Epoch: 461 | MAE Train Loss: 0.04297452047467232 | MAE Test Loss: 0.10524968802928925 \n",
      "Epoch: 462 | MAE Train Loss: 0.042934514582157135 | MAE Test Loss: 0.10507168620824814 \n",
      "Epoch: 463 | MAE Train Loss: 0.04289551451802254 | MAE Test Loss: 0.10496147722005844 \n",
      "Epoch: 464 | MAE Train Loss: 0.04286060854792595 | MAE Test Loss: 0.10485129058361053 \n",
      "Epoch: 465 | MAE Train Loss: 0.04282570630311966 | MAE Test Loss: 0.10474108159542084 \n",
      "Epoch: 466 | MAE Train Loss: 0.04279080033302307 | MAE Test Loss: 0.10463090240955353 \n",
      "Epoch: 467 | MAE Train Loss: 0.04275590553879738 | MAE Test Loss: 0.10452067852020264 \n",
      "Epoch: 468 | MAE Train Loss: 0.042720992118120193 | MAE Test Loss: 0.10441050678491592 \n",
      "Epoch: 469 | MAE Train Loss: 0.0426860973238945 | MAE Test Loss: 0.10430029779672623 \n",
      "Epoch: 470 | MAE Train Loss: 0.04265119880437851 | MAE Test Loss: 0.10419009625911713 \n",
      "Epoch: 471 | MAE Train Loss: 0.04261629283428192 | MAE Test Loss: 0.10407988727092743 \n",
      "Epoch: 472 | MAE Train Loss: 0.04258139431476593 | MAE Test Loss: 0.10396971553564072 \n",
      "Epoch: 473 | MAE Train Loss: 0.04254649952054024 | MAE Test Loss: 0.10385950654745102 \n",
      "Epoch: 474 | MAE Train Loss: 0.04251159727573395 | MAE Test Loss: 0.10374931991100311 \n",
      "Epoch: 475 | MAE Train Loss: 0.04247669130563736 | MAE Test Loss: 0.10363911092281342 \n",
      "Epoch: 476 | MAE Train Loss: 0.04244178533554077 | MAE Test Loss: 0.1035289317369461 \n",
      "Epoch: 477 | MAE Train Loss: 0.04240688681602478 | MAE Test Loss: 0.10341870784759521 \n",
      "Epoch: 478 | MAE Train Loss: 0.042371977120637894 | MAE Test Loss: 0.1033085361123085 \n",
      "Epoch: 479 | MAE Train Loss: 0.0423370823264122 | MAE Test Loss: 0.1031983271241188 \n",
      "Epoch: 480 | MAE Train Loss: 0.04230218380689621 | MAE Test Loss: 0.1030881255865097 \n",
      "Epoch: 481 | MAE Train Loss: 0.04226727783679962 | MAE Test Loss: 0.10297791659832001 \n",
      "Epoch: 482 | MAE Train Loss: 0.04223238304257393 | MAE Test Loss: 0.1028677448630333 \n",
      "Epoch: 483 | MAE Train Loss: 0.04219748452305794 | MAE Test Loss: 0.1027575358748436 \n",
      "Epoch: 484 | MAE Train Loss: 0.04216257855296135 | MAE Test Loss: 0.10264734923839569 \n",
      "Epoch: 485 | MAE Train Loss: 0.04212767630815506 | MAE Test Loss: 0.102537140250206 \n",
      "Epoch: 486 | MAE Train Loss: 0.04209277033805847 | MAE Test Loss: 0.10242696106433868 \n",
      "Epoch: 487 | MAE Train Loss: 0.04205787554383278 | MAE Test Loss: 0.10231673717498779 \n",
      "Epoch: 488 | MAE Train Loss: 0.042022962123155594 | MAE Test Loss: 0.10220656543970108 \n",
      "Epoch: 489 | MAE Train Loss: 0.0419880673289299 | MAE Test Loss: 0.10209635645151138 \n",
      "Epoch: 490 | MAE Train Loss: 0.04195316880941391 | MAE Test Loss: 0.10198615491390228 \n",
      "Epoch: 491 | MAE Train Loss: 0.04191826283931732 | MAE Test Loss: 0.10187594592571259 \n",
      "Epoch: 492 | MAE Train Loss: 0.04188336431980133 | MAE Test Loss: 0.10176577419042587 \n",
      "Epoch: 493 | MAE Train Loss: 0.04184846952557564 | MAE Test Loss: 0.10165556520223618 \n",
      "Epoch: 494 | MAE Train Loss: 0.04181356728076935 | MAE Test Loss: 0.10154537856578827 \n",
      "Epoch: 495 | MAE Train Loss: 0.04177866131067276 | MAE Test Loss: 0.10143516957759857 \n",
      "Epoch: 496 | MAE Train Loss: 0.04174375534057617 | MAE Test Loss: 0.10132499039173126 \n",
      "Epoch: 497 | MAE Train Loss: 0.04170885682106018 | MAE Test Loss: 0.10121476650238037 \n",
      "Epoch: 498 | MAE Train Loss: 0.041673947125673294 | MAE Test Loss: 0.10110459476709366 \n",
      "Epoch: 499 | MAE Train Loss: 0.0416390523314476 | MAE Test Loss: 0.10099438577890396 \n",
      "Epoch: 500 | MAE Train Loss: 0.04160415381193161 | MAE Test Loss: 0.10088418424129486 \n",
      "Epoch: 501 | MAE Train Loss: 0.04156924784183502 | MAE Test Loss: 0.10077397525310516 \n",
      "Epoch: 502 | MAE Train Loss: 0.04153435304760933 | MAE Test Loss: 0.10066380351781845 \n",
      "Epoch: 503 | MAE Train Loss: 0.04149945452809334 | MAE Test Loss: 0.10055359452962875 \n",
      "Epoch: 504 | MAE Train Loss: 0.04146454855799675 | MAE Test Loss: 0.10044340789318085 \n",
      "Epoch: 505 | MAE Train Loss: 0.04142964631319046 | MAE Test Loss: 0.10033319890499115 \n",
      "Epoch: 506 | MAE Train Loss: 0.04139474034309387 | MAE Test Loss: 0.10022301971912384 \n",
      "Epoch: 507 | MAE Train Loss: 0.04135984554886818 | MAE Test Loss: 0.10011279582977295 \n",
      "Epoch: 508 | MAE Train Loss: 0.041324932128190994 | MAE Test Loss: 0.10000262409448624 \n",
      "Epoch: 509 | MAE Train Loss: 0.0412900373339653 | MAE Test Loss: 0.09989241510629654 \n",
      "Epoch: 510 | MAE Train Loss: 0.04125513881444931 | MAE Test Loss: 0.09978221356868744 \n",
      "Epoch: 511 | MAE Train Loss: 0.04122023284435272 | MAE Test Loss: 0.09967201203107834 \n",
      "Epoch: 512 | MAE Train Loss: 0.04118533432483673 | MAE Test Loss: 0.09956184029579163 \n",
      "Epoch: 513 | MAE Train Loss: 0.04115043953061104 | MAE Test Loss: 0.09945162385702133 \n",
      "Epoch: 514 | MAE Train Loss: 0.04111553728580475 | MAE Test Loss: 0.09934143722057343 \n",
      "Epoch: 515 | MAE Train Loss: 0.04108063131570816 | MAE Test Loss: 0.09923122823238373 \n",
      "Epoch: 516 | MAE Train Loss: 0.04104572534561157 | MAE Test Loss: 0.09912104904651642 \n",
      "Epoch: 517 | MAE Train Loss: 0.04101082682609558 | MAE Test Loss: 0.09901082515716553 \n",
      "Epoch: 518 | MAE Train Loss: 0.040975917130708694 | MAE Test Loss: 0.09890064597129822 \n",
      "Epoch: 519 | MAE Train Loss: 0.040941022336483 | MAE Test Loss: 0.09879044443368912 \n",
      "Epoch: 520 | MAE Train Loss: 0.04090612381696701 | MAE Test Loss: 0.09868024289608002 \n",
      "Epoch: 521 | MAE Train Loss: 0.04087121784687042 | MAE Test Loss: 0.09857004135847092 \n",
      "Epoch: 522 | MAE Train Loss: 0.04083632305264473 | MAE Test Loss: 0.0984598696231842 \n",
      "Epoch: 523 | MAE Train Loss: 0.04080142453312874 | MAE Test Loss: 0.09834965318441391 \n",
      "Epoch: 524 | MAE Train Loss: 0.04076651856303215 | MAE Test Loss: 0.098239466547966 \n",
      "Epoch: 525 | MAE Train Loss: 0.04073161631822586 | MAE Test Loss: 0.0981292575597763 \n",
      "Epoch: 526 | MAE Train Loss: 0.04069671034812927 | MAE Test Loss: 0.098019078373909 \n",
      "Epoch: 527 | MAE Train Loss: 0.04066181555390358 | MAE Test Loss: 0.0979088544845581 \n",
      "Epoch: 528 | MAE Train Loss: 0.040626902133226395 | MAE Test Loss: 0.0977986752986908 \n",
      "Epoch: 529 | MAE Train Loss: 0.0405920073390007 | MAE Test Loss: 0.0976884737610817 \n",
      "Epoch: 530 | MAE Train Loss: 0.04055710881948471 | MAE Test Loss: 0.0975782722234726 \n",
      "Epoch: 531 | MAE Train Loss: 0.04052220284938812 | MAE Test Loss: 0.0974680706858635 \n",
      "Epoch: 532 | MAE Train Loss: 0.04048730432987213 | MAE Test Loss: 0.09735789895057678 \n",
      "Epoch: 533 | MAE Train Loss: 0.04045240953564644 | MAE Test Loss: 0.09724768251180649 \n",
      "Epoch: 534 | MAE Train Loss: 0.04041750729084015 | MAE Test Loss: 0.09713749587535858 \n",
      "Epoch: 535 | MAE Train Loss: 0.04038260132074356 | MAE Test Loss: 0.09702728688716888 \n",
      "Epoch: 536 | MAE Train Loss: 0.04034769535064697 | MAE Test Loss: 0.09691710770130157 \n",
      "Epoch: 537 | MAE Train Loss: 0.04031279683113098 | MAE Test Loss: 0.09680688381195068 \n",
      "Epoch: 538 | MAE Train Loss: 0.040277887135744095 | MAE Test Loss: 0.09669670462608337 \n",
      "Epoch: 539 | MAE Train Loss: 0.0402429923415184 | MAE Test Loss: 0.09658650308847427 \n",
      "Epoch: 540 | MAE Train Loss: 0.04020809382200241 | MAE Test Loss: 0.09647630155086517 \n",
      "Epoch: 541 | MAE Train Loss: 0.04017318785190582 | MAE Test Loss: 0.09636610001325607 \n",
      "Epoch: 542 | MAE Train Loss: 0.04013829305768013 | MAE Test Loss: 0.09625592827796936 \n",
      "Epoch: 543 | MAE Train Loss: 0.04010339453816414 | MAE Test Loss: 0.09614574164152145 \n",
      "Epoch: 544 | MAE Train Loss: 0.04006849601864815 | MAE Test Loss: 0.09603555500507355 \n",
      "Epoch: 545 | MAE Train Loss: 0.04003359004855156 | MAE Test Loss: 0.09592534601688385 \n",
      "Epoch: 546 | MAE Train Loss: 0.03999868780374527 | MAE Test Loss: 0.09581514447927475 \n",
      "Epoch: 547 | MAE Train Loss: 0.03996378555893898 | MAE Test Loss: 0.09570496529340744 \n",
      "Epoch: 548 | MAE Train Loss: 0.03992888331413269 | MAE Test Loss: 0.09559475630521774 \n",
      "Epoch: 549 | MAE Train Loss: 0.0398939847946167 | MAE Test Loss: 0.09548455476760864 \n",
      "Epoch: 550 | MAE Train Loss: 0.03985908254981041 | MAE Test Loss: 0.09537436813116074 \n",
      "Epoch: 551 | MAE Train Loss: 0.03982418030500412 | MAE Test Loss: 0.09526417404413223 \n",
      "Epoch: 552 | MAE Train Loss: 0.03978928178548813 | MAE Test Loss: 0.09515395760536194 \n",
      "Epoch: 553 | MAE Train Loss: 0.039754386991262436 | MAE Test Loss: 0.09504377096891403 \n",
      "Epoch: 554 | MAE Train Loss: 0.03971948102116585 | MAE Test Loss: 0.09493358433246613 \n",
      "Epoch: 555 | MAE Train Loss: 0.03968457505106926 | MAE Test Loss: 0.09482337534427643 \n",
      "Epoch: 556 | MAE Train Loss: 0.03964967280626297 | MAE Test Loss: 0.09471317380666733 \n",
      "Epoch: 557 | MAE Train Loss: 0.03961477428674698 | MAE Test Loss: 0.09460299462080002 \n",
      "Epoch: 558 | MAE Train Loss: 0.03957986459136009 | MAE Test Loss: 0.09449278563261032 \n",
      "Epoch: 559 | MAE Train Loss: 0.0395449697971344 | MAE Test Loss: 0.09438258409500122 \n",
      "Epoch: 560 | MAE Train Loss: 0.03951007127761841 | MAE Test Loss: 0.09427239745855331 \n",
      "Epoch: 561 | MAE Train Loss: 0.03947516530752182 | MAE Test Loss: 0.09416220337152481 \n",
      "Epoch: 562 | MAE Train Loss: 0.03944026678800583 | MAE Test Loss: 0.09405198693275452 \n",
      "Epoch: 563 | MAE Train Loss: 0.03940536826848984 | MAE Test Loss: 0.09394180029630661 \n",
      "Epoch: 564 | MAE Train Loss: 0.03937046602368355 | MAE Test Loss: 0.0938316136598587 \n",
      "Epoch: 565 | MAE Train Loss: 0.03933556005358696 | MAE Test Loss: 0.093721404671669 \n",
      "Epoch: 566 | MAE Train Loss: 0.03930065780878067 | MAE Test Loss: 0.0936112031340599 \n",
      "Epoch: 567 | MAE Train Loss: 0.03926575928926468 | MAE Test Loss: 0.0935010239481926 \n",
      "Epoch: 568 | MAE Train Loss: 0.03923085331916809 | MAE Test Loss: 0.0933908149600029 \n",
      "Epoch: 569 | MAE Train Loss: 0.0391959547996521 | MAE Test Loss: 0.0932806134223938 \n",
      "Epoch: 570 | MAE Train Loss: 0.03916105255484581 | MAE Test Loss: 0.09317042678594589 \n",
      "Epoch: 571 | MAE Train Loss: 0.03912615031003952 | MAE Test Loss: 0.09306023269891739 \n",
      "Epoch: 572 | MAE Train Loss: 0.03909125179052353 | MAE Test Loss: 0.0929500162601471 \n",
      "Epoch: 573 | MAE Train Loss: 0.039056356996297836 | MAE Test Loss: 0.09283982962369919 \n",
      "Epoch: 574 | MAE Train Loss: 0.03902145102620125 | MAE Test Loss: 0.09272964298725128 \n",
      "Epoch: 575 | MAE Train Loss: 0.03898654505610466 | MAE Test Loss: 0.09261943399906158 \n",
      "Epoch: 576 | MAE Train Loss: 0.03895164281129837 | MAE Test Loss: 0.09250923246145248 \n",
      "Epoch: 577 | MAE Train Loss: 0.03891674429178238 | MAE Test Loss: 0.09239905327558517 \n",
      "Epoch: 578 | MAE Train Loss: 0.03888183459639549 | MAE Test Loss: 0.09228884428739548 \n",
      "Epoch: 579 | MAE Train Loss: 0.0388469398021698 | MAE Test Loss: 0.09217864274978638 \n",
      "Epoch: 580 | MAE Train Loss: 0.03881204128265381 | MAE Test Loss: 0.09206845611333847 \n",
      "Epoch: 581 | MAE Train Loss: 0.03877713531255722 | MAE Test Loss: 0.09195826202630997 \n",
      "Epoch: 582 | MAE Train Loss: 0.03874223679304123 | MAE Test Loss: 0.09184804558753967 \n",
      "Epoch: 583 | MAE Train Loss: 0.03870733827352524 | MAE Test Loss: 0.09173785895109177 \n",
      "Epoch: 584 | MAE Train Loss: 0.03867243602871895 | MAE Test Loss: 0.09162767231464386 \n",
      "Epoch: 585 | MAE Train Loss: 0.03863753005862236 | MAE Test Loss: 0.09151746332645416 \n",
      "Epoch: 586 | MAE Train Loss: 0.03860262781381607 | MAE Test Loss: 0.09140726178884506 \n",
      "Epoch: 587 | MAE Train Loss: 0.03856772929430008 | MAE Test Loss: 0.09129708260297775 \n",
      "Epoch: 588 | MAE Train Loss: 0.03853282332420349 | MAE Test Loss: 0.09118687361478806 \n",
      "Epoch: 589 | MAE Train Loss: 0.0384979248046875 | MAE Test Loss: 0.09107667207717896 \n",
      "Epoch: 590 | MAE Train Loss: 0.03846302255988121 | MAE Test Loss: 0.09096648544073105 \n",
      "Epoch: 591 | MAE Train Loss: 0.03842812031507492 | MAE Test Loss: 0.09085629135370255 \n",
      "Epoch: 592 | MAE Train Loss: 0.03839322179555893 | MAE Test Loss: 0.09074607491493225 \n",
      "Epoch: 593 | MAE Train Loss: 0.03835832700133324 | MAE Test Loss: 0.09063588827848434 \n",
      "Epoch: 594 | MAE Train Loss: 0.03832342103123665 | MAE Test Loss: 0.09052570164203644 \n",
      "Epoch: 595 | MAE Train Loss: 0.03828851506114006 | MAE Test Loss: 0.09041549265384674 \n",
      "Epoch: 596 | MAE Train Loss: 0.03825361281633377 | MAE Test Loss: 0.09030529111623764 \n",
      "Epoch: 597 | MAE Train Loss: 0.03821871429681778 | MAE Test Loss: 0.09019511193037033 \n",
      "Epoch: 598 | MAE Train Loss: 0.03818380460143089 | MAE Test Loss: 0.09008490294218063 \n",
      "Epoch: 599 | MAE Train Loss: 0.0381489098072052 | MAE Test Loss: 0.08997470140457153 \n",
      "Epoch: 600 | MAE Train Loss: 0.03811401128768921 | MAE Test Loss: 0.08986451476812363 \n",
      "Epoch: 601 | MAE Train Loss: 0.03807910531759262 | MAE Test Loss: 0.08975431323051453 \n",
      "Epoch: 602 | MAE Train Loss: 0.03804420679807663 | MAE Test Loss: 0.08964410424232483 \n",
      "Epoch: 603 | MAE Train Loss: 0.03800930827856064 | MAE Test Loss: 0.08953391760587692 \n",
      "Epoch: 604 | MAE Train Loss: 0.03797440603375435 | MAE Test Loss: 0.08942373096942902 \n",
      "Epoch: 605 | MAE Train Loss: 0.03793950006365776 | MAE Test Loss: 0.08931352198123932 \n",
      "Epoch: 606 | MAE Train Loss: 0.03790459781885147 | MAE Test Loss: 0.08920332044363022 \n",
      "Epoch: 607 | MAE Train Loss: 0.03786969929933548 | MAE Test Loss: 0.08909314125776291 \n",
      "Epoch: 608 | MAE Train Loss: 0.03783479332923889 | MAE Test Loss: 0.08898293226957321 \n",
      "Epoch: 609 | MAE Train Loss: 0.0377998948097229 | MAE Test Loss: 0.08887273073196411 \n",
      "Epoch: 610 | MAE Train Loss: 0.03776499256491661 | MAE Test Loss: 0.0887625440955162 \n",
      "Epoch: 611 | MAE Train Loss: 0.03773009032011032 | MAE Test Loss: 0.0886523425579071 \n",
      "Epoch: 612 | MAE Train Loss: 0.03769519180059433 | MAE Test Loss: 0.08854213356971741 \n",
      "Epoch: 613 | MAE Train Loss: 0.03766029700636864 | MAE Test Loss: 0.0884319469332695 \n",
      "Epoch: 614 | MAE Train Loss: 0.03762539103627205 | MAE Test Loss: 0.0883217602968216 \n",
      "Epoch: 615 | MAE Train Loss: 0.03759048506617546 | MAE Test Loss: 0.0882115513086319 \n",
      "Epoch: 616 | MAE Train Loss: 0.03755558282136917 | MAE Test Loss: 0.0881013497710228 \n",
      "Epoch: 617 | MAE Train Loss: 0.03752068430185318 | MAE Test Loss: 0.08799117058515549 \n",
      "Epoch: 618 | MAE Train Loss: 0.03748577460646629 | MAE Test Loss: 0.08788096159696579 \n",
      "Epoch: 619 | MAE Train Loss: 0.0374508798122406 | MAE Test Loss: 0.08777076005935669 \n",
      "Epoch: 620 | MAE Train Loss: 0.03741598129272461 | MAE Test Loss: 0.08766057342290878 \n",
      "Epoch: 621 | MAE Train Loss: 0.03738107532262802 | MAE Test Loss: 0.08755037188529968 \n",
      "Epoch: 622 | MAE Train Loss: 0.03734617680311203 | MAE Test Loss: 0.08744016289710999 \n",
      "Epoch: 623 | MAE Train Loss: 0.03731127828359604 | MAE Test Loss: 0.08732997626066208 \n",
      "Epoch: 624 | MAE Train Loss: 0.03727637603878975 | MAE Test Loss: 0.08721978962421417 \n",
      "Epoch: 625 | MAE Train Loss: 0.03724147006869316 | MAE Test Loss: 0.08710958063602448 \n",
      "Epoch: 626 | MAE Train Loss: 0.03720656782388687 | MAE Test Loss: 0.08699937909841537 \n",
      "Epoch: 627 | MAE Train Loss: 0.03717166930437088 | MAE Test Loss: 0.08688919991254807 \n",
      "Epoch: 628 | MAE Train Loss: 0.03713676333427429 | MAE Test Loss: 0.08677899092435837 \n",
      "Epoch: 629 | MAE Train Loss: 0.0371018648147583 | MAE Test Loss: 0.08666878938674927 \n",
      "Epoch: 630 | MAE Train Loss: 0.037067197263240814 | MAE Test Loss: 0.08662726730108261 \n",
      "Epoch: 631 | MAE Train Loss: 0.037033338099718094 | MAE Test Loss: 0.08651705086231232 \n",
      "Epoch: 632 | MAE Train Loss: 0.036998435854911804 | MAE Test Loss: 0.08640686422586441 \n",
      "Epoch: 633 | MAE Train Loss: 0.036964669823646545 | MAE Test Loss: 0.08636530488729477 \n",
      "Epoch: 634 | MAE Train Loss: 0.036929916590452194 | MAE Test Loss: 0.08625511080026627 \n",
      "Epoch: 635 | MAE Train Loss: 0.036895763128995895 | MAE Test Loss: 0.08621358126401901 \n",
      "Epoch: 636 | MAE Train Loss: 0.03686138987541199 | MAE Test Loss: 0.08610336482524872 \n",
      "Epoch: 637 | MAE Train Loss: 0.036826856434345245 | MAE Test Loss: 0.08606183528900146 \n",
      "Epoch: 638 | MAE Train Loss: 0.03679286316037178 | MAE Test Loss: 0.08595161885023117 \n",
      "Epoch: 639 | MAE Train Loss: 0.03675796836614609 | MAE Test Loss: 0.08584143966436386 \n",
      "Epoch: 640 | MAE Train Loss: 0.03672432154417038 | MAE Test Loss: 0.08579986542463303 \n",
      "Epoch: 641 | MAE Train Loss: 0.03668942302465439 | MAE Test Loss: 0.08568969368934631 \n",
      "Epoch: 642 | MAE Train Loss: 0.03665542230010033 | MAE Test Loss: 0.08564814180135727 \n",
      "Epoch: 643 | MAE Train Loss: 0.03662090748548508 | MAE Test Loss: 0.08553795516490936 \n",
      "Epoch: 644 | MAE Train Loss: 0.03658652305603027 | MAE Test Loss: 0.08549639582633972 \n",
      "Epoch: 645 | MAE Train Loss: 0.03655238077044487 | MAE Test Loss: 0.08538620173931122 \n",
      "Epoch: 646 | MAE Train Loss: 0.03651762008666992 | MAE Test Loss: 0.08534465730190277 \n",
      "Epoch: 647 | MAE Train Loss: 0.03648385405540466 | MAE Test Loss: 0.08523445576429367 \n",
      "Epoch: 648 | MAE Train Loss: 0.03644895553588867 | MAE Test Loss: 0.08512424677610397 \n",
      "Epoch: 649 | MAE Train Loss: 0.03641509264707565 | MAE Test Loss: 0.08508270978927612 \n",
      "Epoch: 650 | MAE Train Loss: 0.03638043254613876 | MAE Test Loss: 0.08497253060340881 \n",
      "Epoch: 651 | MAE Train Loss: 0.036346182227134705 | MAE Test Loss: 0.08493097871541977 \n",
      "Epoch: 652 | MAE Train Loss: 0.036311905831098557 | MAE Test Loss: 0.08482077717781067 \n",
      "Epoch: 653 | MAE Train Loss: 0.03627727925777435 | MAE Test Loss: 0.08477924019098282 \n",
      "Epoch: 654 | MAE Train Loss: 0.03624338284134865 | MAE Test Loss: 0.08466903120279312 \n",
      "Epoch: 655 | MAE Train Loss: 0.03620847314596176 | MAE Test Loss: 0.08455883711576462 \n",
      "Epoch: 656 | MAE Train Loss: 0.036174751818180084 | MAE Test Loss: 0.08451729267835617 \n",
      "Epoch: 657 | MAE Train Loss: 0.03613995760679245 | MAE Test Loss: 0.08440708369016647 \n",
      "Epoch: 658 | MAE Train Loss: 0.036105841398239136 | MAE Test Loss: 0.08436556160449982 \n",
      "Epoch: 659 | MAE Train Loss: 0.03607143089175224 | MAE Test Loss: 0.08425535261631012 \n",
      "Epoch: 660 | MAE Train Loss: 0.036036938428878784 | MAE Test Loss: 0.08421380817890167 \n",
      "Epoch: 661 | MAE Train Loss: 0.03600289672613144 | MAE Test Loss: 0.08410360664129257 \n",
      "Epoch: 662 | MAE Train Loss: 0.035968031734228134 | MAE Test Loss: 0.08406206965446472 \n",
      "Epoch: 663 | MAE Train Loss: 0.03593437746167183 | MAE Test Loss: 0.08395187556743622 \n",
      "Epoch: 664 | MAE Train Loss: 0.03589947521686554 | MAE Test Loss: 0.08384167402982712 \n",
      "Epoch: 665 | MAE Train Loss: 0.035865504294633865 | MAE Test Loss: 0.08380012214183807 \n",
      "Epoch: 666 | MAE Train Loss: 0.03583095222711563 | MAE Test Loss: 0.08368994295597076 \n",
      "Epoch: 667 | MAE Train Loss: 0.03579659387469292 | MAE Test Loss: 0.08364837616682053 \n",
      "Epoch: 668 | MAE Train Loss: 0.03576242923736572 | MAE Test Loss: 0.08353818953037262 \n",
      "Epoch: 669 | MAE Train Loss: 0.03572769835591316 | MAE Test Loss: 0.08349661529064178 \n",
      "Epoch: 670 | MAE Train Loss: 0.035693906247615814 | MAE Test Loss: 0.08338643610477448 \n",
      "Epoch: 671 | MAE Train Loss: 0.03565899655222893 | MAE Test Loss: 0.08327624946832657 \n",
      "Epoch: 672 | MAE Train Loss: 0.035625167191028595 | MAE Test Loss: 0.08323469758033752 \n",
      "Epoch: 673 | MAE Train Loss: 0.03559047356247902 | MAE Test Loss: 0.08312450349330902 \n",
      "Epoch: 674 | MAE Train Loss: 0.03555626422166824 | MAE Test Loss: 0.08308294415473938 \n",
      "Epoch: 675 | MAE Train Loss: 0.03552195802330971 | MAE Test Loss: 0.08297275751829147 \n",
      "Epoch: 676 | MAE Train Loss: 0.03548736125230789 | MAE Test Loss: 0.08293122053146362 \n",
      "Epoch: 677 | MAE Train Loss: 0.0354534275829792 | MAE Test Loss: 0.08282099664211273 \n",
      "Epoch: 678 | MAE Train Loss: 0.035418521612882614 | MAE Test Loss: 0.08271081745624542 \n",
      "Epoch: 679 | MAE Train Loss: 0.035384830087423325 | MAE Test Loss: 0.08266927301883698 \n",
      "Epoch: 680 | MAE Train Loss: 0.035350002348423004 | MAE Test Loss: 0.08255907148122787 \n",
      "Epoch: 681 | MAE Train Loss: 0.035315923392772675 | MAE Test Loss: 0.08251753449440002 \n",
      "Epoch: 682 | MAE Train Loss: 0.0352814719080925 | MAE Test Loss: 0.08240732550621033 \n",
      "Epoch: 683 | MAE Train Loss: 0.03524700924754143 | MAE Test Loss: 0.08236578106880188 \n",
      "Epoch: 684 | MAE Train Loss: 0.03521294146776199 | MAE Test Loss: 0.08225558698177338 \n",
      "Epoch: 685 | MAE Train Loss: 0.03517811372876167 | MAE Test Loss: 0.08221404999494553 \n",
      "Epoch: 686 | MAE Train Loss: 0.03514442220330238 | MAE Test Loss: 0.08210383355617523 \n",
      "Epoch: 687 | MAE Train Loss: 0.0351095125079155 | MAE Test Loss: 0.08199366927146912 \n",
      "Epoch: 688 | MAE Train Loss: 0.035075593739748 | MAE Test Loss: 0.08195210248231888 \n",
      "Epoch: 689 | MAE Train Loss: 0.03504099324345589 | MAE Test Loss: 0.08184190839529037 \n",
      "Epoch: 690 | MAE Train Loss: 0.035006679594516754 | MAE Test Loss: 0.08180035650730133 \n",
      "Epoch: 691 | MAE Train Loss: 0.03497246652841568 | MAE Test Loss: 0.08169016242027283 \n",
      "Epoch: 692 | MAE Train Loss: 0.0349377766251564 | MAE Test Loss: 0.08164862543344498 \n",
      "Epoch: 693 | MAE Train Loss: 0.03490393981337547 | MAE Test Loss: 0.08153841644525528 \n",
      "Epoch: 694 | MAE Train Loss: 0.03486904129385948 | MAE Test Loss: 0.08142823725938797 \n",
      "Epoch: 695 | MAE Train Loss: 0.03483524173498154 | MAE Test Loss: 0.08138667792081833 \n",
      "Epoch: 696 | MAE Train Loss: 0.03480052202939987 | MAE Test Loss: 0.08127648383378983 \n",
      "Epoch: 697 | MAE Train Loss: 0.034766342490911484 | MAE Test Loss: 0.08123494684696198 \n",
      "Epoch: 698 | MAE Train Loss: 0.034731991589069366 | MAE Test Loss: 0.08112473785877228 \n",
      "Epoch: 699 | MAE Train Loss: 0.034697435796260834 | MAE Test Loss: 0.08108319342136383 \n",
      "Epoch: 700 | MAE Train Loss: 0.03466346859931946 | MAE Test Loss: 0.08097299933433533 \n",
      "Epoch: 701 | MAE Train Loss: 0.03462856262922287 | MAE Test Loss: 0.08086280524730682 \n",
      "Epoch: 702 | MAE Train Loss: 0.03459491580724716 | MAE Test Loss: 0.08082125335931778 \n",
      "Epoch: 703 | MAE Train Loss: 0.03456003591418266 | MAE Test Loss: 0.08071105927228928 \n",
      "Epoch: 704 | MAE Train Loss: 0.034526001662015915 | MAE Test Loss: 0.08066950738430023 \n",
      "Epoch: 705 | MAE Train Loss: 0.034491509199142456 | MAE Test Loss: 0.08055931329727173 \n",
      "Epoch: 706 | MAE Train Loss: 0.03445709869265556 | MAE Test Loss: 0.08051777631044388 \n",
      "Epoch: 707 | MAE Train Loss: 0.03442298620939255 | MAE Test Loss: 0.08040755987167358 \n",
      "Epoch: 708 | MAE Train Loss: 0.03438819572329521 | MAE Test Loss: 0.08036604523658752 \n",
      "Epoch: 709 | MAE Train Loss: 0.03435446694493294 | MAE Test Loss: 0.08025582134723663 \n",
      "Epoch: 710 | MAE Train Loss: 0.03431956097483635 | MAE Test Loss: 0.08014564216136932 \n",
      "Epoch: 711 | MAE Train Loss: 0.034285664558410645 | MAE Test Loss: 0.08010408282279968 \n",
      "Epoch: 712 | MAE Train Loss: 0.034251030534505844 | MAE Test Loss: 0.07999388873577118 \n",
      "Epoch: 713 | MAE Train Loss: 0.03421676158905029 | MAE Test Loss: 0.07995234429836273 \n",
      "Epoch: 714 | MAE Train Loss: 0.034182511270046234 | MAE Test Loss: 0.07984215021133423 \n",
      "Epoch: 715 | MAE Train Loss: 0.034147851169109344 | MAE Test Loss: 0.07980061322450638 \n",
      "Epoch: 716 | MAE Train Loss: 0.03411398082971573 | MAE Test Loss: 0.07969042658805847 \n",
      "Epoch: 717 | MAE Train Loss: 0.03407908231019974 | MAE Test Loss: 0.07958020269870758 \n",
      "Epoch: 718 | MAE Train Loss: 0.03404533118009567 | MAE Test Loss: 0.07953865826129913 \n",
      "Epoch: 719 | MAE Train Loss: 0.03401055932044983 | MAE Test Loss: 0.07942847162485123 \n",
      "Epoch: 720 | MAE Train Loss: 0.03397642448544502 | MAE Test Loss: 0.07938691228628159 \n",
      "Epoch: 721 | MAE Train Loss: 0.03394203260540962 | MAE Test Loss: 0.07927673310041428 \n",
      "Epoch: 722 | MAE Train Loss: 0.033907510340213776 | MAE Test Loss: 0.07923518121242523 \n",
      "Epoch: 723 | MAE Train Loss: 0.03387351706624031 | MAE Test Loss: 0.07912497967481613 \n",
      "Epoch: 724 | MAE Train Loss: 0.033838607370853424 | MAE Test Loss: 0.07908343523740768 \n",
      "Epoch: 725 | MAE Train Loss: 0.03380498290061951 | MAE Test Loss: 0.07897323369979858 \n",
      "Epoch: 726 | MAE Train Loss: 0.033770088106393814 | MAE Test Loss: 0.07886303961277008 \n",
      "Epoch: 727 | MAE Train Loss: 0.033736079931259155 | MAE Test Loss: 0.07882149517536163 \n",
      "Epoch: 728 | MAE Train Loss: 0.03370155766606331 | MAE Test Loss: 0.07871129363775253 \n",
      "Epoch: 729 | MAE Train Loss: 0.033667173236608505 | MAE Test Loss: 0.07866974920034409 \n",
      "Epoch: 730 | MAE Train Loss: 0.0336330309510231 | MAE Test Loss: 0.07855955511331558 \n",
      "Epoch: 731 | MAE Train Loss: 0.033598270267248154 | MAE Test Loss: 0.07851801812648773 \n",
      "Epoch: 732 | MAE Train Loss: 0.033564500510692596 | MAE Test Loss: 0.07840781658887863 \n",
      "Epoch: 733 | MAE Train Loss: 0.033529605716466904 | MAE Test Loss: 0.07829762250185013 \n",
      "Epoch: 734 | MAE Train Loss: 0.03349574655294418 | MAE Test Loss: 0.07825606316328049 \n",
      "Epoch: 735 | MAE Train Loss: 0.0334610790014267 | MAE Test Loss: 0.07814587652683258 \n",
      "Epoch: 736 | MAE Train Loss: 0.03342684358358383 | MAE Test Loss: 0.07810431718826294 \n",
      "Epoch: 737 | MAE Train Loss: 0.03339255228638649 | MAE Test Loss: 0.07799413055181503 \n",
      "Epoch: 738 | MAE Train Loss: 0.03335793316364288 | MAE Test Loss: 0.07795257866382599 \n",
      "Epoch: 739 | MAE Train Loss: 0.03332402929663658 | MAE Test Loss: 0.07784239202737808 \n",
      "Epoch: 740 | MAE Train Loss: 0.03328912332653999 | MAE Test Loss: 0.07773219794034958 \n",
      "Epoch: 741 | MAE Train Loss: 0.033255405724048615 | MAE Test Loss: 0.07769063860177994 \n",
      "Epoch: 742 | MAE Train Loss: 0.033220600336790085 | MAE Test Loss: 0.07758044451475143 \n",
      "Epoch: 743 | MAE Train Loss: 0.03318650275468826 | MAE Test Loss: 0.07753890007734299 \n",
      "Epoch: 744 | MAE Train Loss: 0.03315207362174988 | MAE Test Loss: 0.07742870599031448 \n",
      "Epoch: 745 | MAE Train Loss: 0.03311759606003761 | MAE Test Loss: 0.07738716900348663 \n",
      "Epoch: 746 | MAE Train Loss: 0.03308354690670967 | MAE Test Loss: 0.07727696001529694 \n",
      "Epoch: 747 | MAE Train Loss: 0.033048685640096664 | MAE Test Loss: 0.07723541557788849 \n",
      "Epoch: 748 | MAE Train Loss: 0.033015020191669464 | MAE Test Loss: 0.07712522149085999 \n",
      "Epoch: 749 | MAE Train Loss: 0.03298012539744377 | MAE Test Loss: 0.07701502740383148 \n",
      "Epoch: 750 | MAE Train Loss: 0.032946161925792694 | MAE Test Loss: 0.07697348296642303 \n",
      "Epoch: 751 | MAE Train Loss: 0.032911598682403564 | MAE Test Loss: 0.07686327397823334 \n",
      "Epoch: 752 | MAE Train Loss: 0.03287725895643234 | MAE Test Loss: 0.07682173699140549 \n",
      "Epoch: 753 | MAE Train Loss: 0.03284307196736336 | MAE Test Loss: 0.07671154290437698 \n",
      "Epoch: 754 | MAE Train Loss: 0.03280835971236229 | MAE Test Loss: 0.07666999846696854 \n",
      "Epoch: 755 | MAE Train Loss: 0.03277454525232315 | MAE Test Loss: 0.07655977457761765 \n",
      "Epoch: 756 | MAE Train Loss: 0.032739631831645966 | MAE Test Loss: 0.07644960284233093 \n",
      "Epoch: 757 | MAE Train Loss: 0.032705824822187424 | MAE Test Loss: 0.07640805840492249 \n",
      "Epoch: 758 | MAE Train Loss: 0.032671116292476654 | MAE Test Loss: 0.07629784941673279 \n",
      "Epoch: 759 | MAE Train Loss: 0.03263692185282707 | MAE Test Loss: 0.07625630497932434 \n",
      "Epoch: 760 | MAE Train Loss: 0.03260258957743645 | MAE Test Loss: 0.07614611089229584 \n",
      "Epoch: 761 | MAE Train Loss: 0.03256801888346672 | MAE Test Loss: 0.07610457390546799 \n",
      "Epoch: 762 | MAE Train Loss: 0.03253406286239624 | MAE Test Loss: 0.07599435746669769 \n",
      "Epoch: 763 | MAE Train Loss: 0.03249916434288025 | MAE Test Loss: 0.075884148478508 \n",
      "Epoch: 764 | MAE Train Loss: 0.03246549516916275 | MAE Test Loss: 0.07584261894226074 \n",
      "Epoch: 765 | MAE Train Loss: 0.03243063762784004 | MAE Test Loss: 0.07573243975639343 \n",
      "Epoch: 766 | MAE Train Loss: 0.0323965810239315 | MAE Test Loss: 0.07569089531898499 \n",
      "Epoch: 767 | MAE Train Loss: 0.032362114638090134 | MAE Test Loss: 0.07558067888021469 \n",
      "Epoch: 768 | MAE Train Loss: 0.03232767805457115 | MAE Test Loss: 0.07553914934396744 \n",
      "Epoch: 769 | MAE Train Loss: 0.032293591648340225 | MAE Test Loss: 0.07542894035577774 \n",
      "Epoch: 770 | MAE Train Loss: 0.0322587676346302 | MAE Test Loss: 0.07538740336894989 \n",
      "Epoch: 771 | MAE Train Loss: 0.03222506120800972 | MAE Test Loss: 0.07527719438076019 \n",
      "Epoch: 772 | MAE Train Loss: 0.03219016641378403 | MAE Test Loss: 0.07516699284315109 \n",
      "Epoch: 773 | MAE Train Loss: 0.03215624764561653 | MAE Test Loss: 0.07512547075748444 \n",
      "Epoch: 774 | MAE Train Loss: 0.03212163969874382 | MAE Test Loss: 0.07501526176929474 \n",
      "Epoch: 775 | MAE Train Loss: 0.03208733722567558 | MAE Test Loss: 0.07497371733188629 \n",
      "Epoch: 776 | MAE Train Loss: 0.032053105533123016 | MAE Test Loss: 0.07486351579427719 \n",
      "Epoch: 777 | MAE Train Loss: 0.03201843053102493 | MAE Test Loss: 0.07482197880744934 \n",
      "Epoch: 778 | MAE Train Loss: 0.03198458254337311 | MAE Test Loss: 0.07471177726984024 \n",
      "Epoch: 779 | MAE Train Loss: 0.031949687749147415 | MAE Test Loss: 0.07460158318281174 \n",
      "Epoch: 780 | MAE Train Loss: 0.031915903091430664 | MAE Test Loss: 0.07456003129482269 \n",
      "Epoch: 781 | MAE Train Loss: 0.03188116103410721 | MAE Test Loss: 0.07444985210895538 \n",
      "Epoch: 782 | MAE Train Loss: 0.031846996396780014 | MAE Test Loss: 0.07440828531980515 \n",
      "Epoch: 783 | MAE Train Loss: 0.0318126380443573 | MAE Test Loss: 0.07429809868335724 \n",
      "Epoch: 784 | MAE Train Loss: 0.03177809715270996 | MAE Test Loss: 0.0742565244436264 \n",
      "Epoch: 785 | MAE Train Loss: 0.03174411505460739 | MAE Test Loss: 0.0741463452577591 \n",
      "Epoch: 786 | MAE Train Loss: 0.031709205359220505 | MAE Test Loss: 0.07403616607189178 \n",
      "Epoch: 787 | MAE Train Loss: 0.03167556971311569 | MAE Test Loss: 0.07399461418390274 \n",
      "Epoch: 788 | MAE Train Loss: 0.031640682369470596 | MAE Test Loss: 0.07388440519571304 \n",
      "Epoch: 789 | MAE Train Loss: 0.03160666301846504 | MAE Test Loss: 0.073842853307724 \n",
      "Epoch: 790 | MAE Train Loss: 0.031572166830301285 | MAE Test Loss: 0.07373266667127609 \n",
      "Epoch: 791 | MAE Train Loss: 0.03153776004910469 | MAE Test Loss: 0.07369112968444824 \n",
      "Epoch: 792 | MAE Train Loss: 0.03150363638997078 | MAE Test Loss: 0.07358090579509735 \n",
      "Epoch: 793 | MAE Train Loss: 0.03146884962916374 | MAE Test Loss: 0.0735393688082695 \n",
      "Epoch: 794 | MAE Train Loss: 0.03143510967493057 | MAE Test Loss: 0.0734291821718216 \n",
      "Epoch: 795 | MAE Train Loss: 0.03140020743012428 | MAE Test Loss: 0.0733189806342125 \n",
      "Epoch: 796 | MAE Train Loss: 0.03136632218956947 | MAE Test Loss: 0.07327743619680405 \n",
      "Epoch: 797 | MAE Train Loss: 0.031331680715084076 | MAE Test Loss: 0.07316723465919495 \n",
      "Epoch: 798 | MAE Train Loss: 0.031297408044338226 | MAE Test Loss: 0.0731256827712059 \n",
      "Epoch: 799 | MAE Train Loss: 0.03126315027475357 | MAE Test Loss: 0.073015496134758 \n",
      "Epoch: 800 | MAE Train Loss: 0.03122851625084877 | MAE Test Loss: 0.07297395914793015 \n",
      "Epoch: 801 | MAE Train Loss: 0.03119463101029396 | MAE Test Loss: 0.07286374270915985 \n",
      "Epoch: 802 | MAE Train Loss: 0.031159725040197372 | MAE Test Loss: 0.07275357842445374 \n",
      "Epoch: 803 | MAE Train Loss: 0.0311259925365448 | MAE Test Loss: 0.0727120116353035 \n",
      "Epoch: 804 | MAE Train Loss: 0.031091203913092613 | MAE Test Loss: 0.07260182499885559 \n",
      "Epoch: 805 | MAE Train Loss: 0.031057080253958702 | MAE Test Loss: 0.07256026566028595 \n",
      "Epoch: 806 | MAE Train Loss: 0.031022677198052406 | MAE Test Loss: 0.07245006412267685 \n",
      "Epoch: 807 | MAE Train Loss: 0.03098817728459835 | MAE Test Loss: 0.07240854203701019 \n",
      "Epoch: 808 | MAE Train Loss: 0.03095415234565735 | MAE Test Loss: 0.0722983330488205 \n",
      "Epoch: 809 | MAE Train Loss: 0.03091926872730255 | MAE Test Loss: 0.07225678116083145 \n",
      "Epoch: 810 | MAE Train Loss: 0.03088562563061714 | MAE Test Loss: 0.07214658707380295 \n",
      "Epoch: 811 | MAE Train Loss: 0.03085072711110115 | MAE Test Loss: 0.07203639298677444 \n",
      "Epoch: 812 | MAE Train Loss: 0.03081674501299858 | MAE Test Loss: 0.0719948559999466 \n",
      "Epoch: 813 | MAE Train Loss: 0.030782198533415794 | MAE Test Loss: 0.0718846470117569 \n",
      "Epoch: 814 | MAE Train Loss: 0.03074783645570278 | MAE Test Loss: 0.07184310257434845 \n",
      "Epoch: 815 | MAE Train Loss: 0.030713677406311035 | MAE Test Loss: 0.07173290848731995 \n",
      "Epoch: 816 | MAE Train Loss: 0.030678927898406982 | MAE Test Loss: 0.0716913565993309 \n",
      "Epoch: 817 | MAE Train Loss: 0.030645150691270828 | MAE Test Loss: 0.071581169962883 \n",
      "Epoch: 818 | MAE Train Loss: 0.03061024472117424 | MAE Test Loss: 0.0714709609746933 \n",
      "Epoch: 819 | MAE Train Loss: 0.030576402321457863 | MAE Test Loss: 0.07142942398786545 \n",
      "Epoch: 820 | MAE Train Loss: 0.03054172359406948 | MAE Test Loss: 0.07131922990083694 \n",
      "Epoch: 821 | MAE Train Loss: 0.03050749935209751 | MAE Test Loss: 0.0712776854634285 \n",
      "Epoch: 822 | MAE Train Loss: 0.030473193153738976 | MAE Test Loss: 0.0711674615740776 \n",
      "Epoch: 823 | MAE Train Loss: 0.03043859638273716 | MAE Test Loss: 0.07112595438957214 \n",
      "Epoch: 824 | MAE Train Loss: 0.030404681339859962 | MAE Test Loss: 0.07101573050022125 \n",
      "Epoch: 825 | MAE Train Loss: 0.030369769781827927 | MAE Test Loss: 0.07090555131435394 \n",
      "Epoch: 826 | MAE Train Loss: 0.030336061492562294 | MAE Test Loss: 0.0708639919757843 \n",
      "Epoch: 827 | MAE Train Loss: 0.03030124306678772 | MAE Test Loss: 0.0707537978887558 \n",
      "Epoch: 828 | MAE Train Loss: 0.030267158523201942 | MAE Test Loss: 0.07071225345134735 \n",
      "Epoch: 829 | MAE Train Loss: 0.03023272193968296 | MAE Test Loss: 0.07060205936431885 \n",
      "Epoch: 830 | MAE Train Loss: 0.030198251828551292 | MAE Test Loss: 0.0705605149269104 \n",
      "Epoch: 831 | MAE Train Loss: 0.030164187774062157 | MAE Test Loss: 0.07045033574104309 \n",
      "Epoch: 832 | MAE Train Loss: 0.030129343271255493 | MAE Test Loss: 0.07040876895189285 \n",
      "Epoch: 833 | MAE Train Loss: 0.030095672234892845 | MAE Test Loss: 0.07029856741428375 \n",
      "Epoch: 834 | MAE Train Loss: 0.030060768127441406 | MAE Test Loss: 0.07018838077783585 \n",
      "Epoch: 835 | MAE Train Loss: 0.03002682328224182 | MAE Test Loss: 0.0701468288898468 \n",
      "Epoch: 836 | MAE Train Loss: 0.0299922414124012 | MAE Test Loss: 0.07003664970397949 \n",
      "Epoch: 837 | MAE Train Loss: 0.02995791658759117 | MAE Test Loss: 0.06999509036540985 \n",
      "Epoch: 838 | MAE Train Loss: 0.02992371842265129 | MAE Test Loss: 0.06988489627838135 \n",
      "Epoch: 839 | MAE Train Loss: 0.029889006167650223 | MAE Test Loss: 0.0698433369398117 \n",
      "Epoch: 840 | MAE Train Loss: 0.029855191707611084 | MAE Test Loss: 0.0697331428527832 \n",
      "Epoch: 841 | MAE Train Loss: 0.029820293188095093 | MAE Test Loss: 0.0696229487657547 \n",
      "Epoch: 842 | MAE Train Loss: 0.029786478728055954 | MAE Test Loss: 0.06958140432834625 \n",
      "Epoch: 843 | MAE Train Loss: 0.02975175902247429 | MAE Test Loss: 0.06947120279073715 \n",
      "Epoch: 844 | MAE Train Loss: 0.029717573896050453 | MAE Test Loss: 0.0694296583533287 \n",
      "Epoch: 845 | MAE Train Loss: 0.02968323789536953 | MAE Test Loss: 0.0693194642663002 \n",
      "Epoch: 846 | MAE Train Loss: 0.0296486709266901 | MAE Test Loss: 0.06927792727947235 \n",
      "Epoch: 847 | MAE Train Loss: 0.029614707455039024 | MAE Test Loss: 0.06916771829128265 \n",
      "Epoch: 848 | MAE Train Loss: 0.02957981266081333 | MAE Test Loss: 0.06905753165483475 \n",
      "Epoch: 849 | MAE Train Loss: 0.02954614721238613 | MAE Test Loss: 0.0690159797668457 \n",
      "Epoch: 850 | MAE Train Loss: 0.029511287808418274 | MAE Test Loss: 0.0689057856798172 \n",
      "Epoch: 851 | MAE Train Loss: 0.029477238655090332 | MAE Test Loss: 0.06886423379182816 \n",
      "Epoch: 852 | MAE Train Loss: 0.029442761093378067 | MAE Test Loss: 0.06875403970479965 \n",
      "Epoch: 853 | MAE Train Loss: 0.029408331960439682 | MAE Test Loss: 0.06871248781681061 \n",
      "Epoch: 854 | MAE Train Loss: 0.02937423624098301 | MAE Test Loss: 0.0686022937297821 \n",
      "Epoch: 855 | MAE Train Loss: 0.02933942899107933 | MAE Test Loss: 0.06856075674295425 \n",
      "Epoch: 856 | MAE Train Loss: 0.02930571138858795 | MAE Test Loss: 0.06845054775476456 \n",
      "Epoch: 857 | MAE Train Loss: 0.029270809143781662 | MAE Test Loss: 0.06834035366773605 \n",
      "Epoch: 858 | MAE Train Loss: 0.02923690341413021 | MAE Test Loss: 0.0682988092303276 \n",
      "Epoch: 859 | MAE Train Loss: 0.029202282428741455 | MAE Test Loss: 0.0681886151432991 \n",
      "Epoch: 860 | MAE Train Loss: 0.02916799485683441 | MAE Test Loss: 0.06814707070589066 \n",
      "Epoch: 861 | MAE Train Loss: 0.029133755713701248 | MAE Test Loss: 0.06803686916828156 \n",
      "Epoch: 862 | MAE Train Loss: 0.029099086299538612 | MAE Test Loss: 0.06799532473087311 \n",
      "Epoch: 863 | MAE Train Loss: 0.029065227136015892 | MAE Test Loss: 0.0678851306438446 \n",
      "Epoch: 864 | MAE Train Loss: 0.02903033420443535 | MAE Test Loss: 0.0677749365568161 \n",
      "Epoch: 865 | MAE Train Loss: 0.028996562585234642 | MAE Test Loss: 0.06773339211940765 \n",
      "Epoch: 866 | MAE Train Loss: 0.02896180748939514 | MAE Test Loss: 0.06762318313121796 \n",
      "Epoch: 867 | MAE Train Loss: 0.02892765775322914 | MAE Test Loss: 0.0675816461443901 \n",
      "Epoch: 868 | MAE Train Loss: 0.028893280774354935 | MAE Test Loss: 0.0674714595079422 \n",
      "Epoch: 869 | MAE Train Loss: 0.02885875664651394 | MAE Test Loss: 0.06742990016937256 \n",
      "Epoch: 870 | MAE Train Loss: 0.028824755921959877 | MAE Test Loss: 0.06731969118118286 \n",
      "Epoch: 871 | MAE Train Loss: 0.028789842501282692 | MAE Test Loss: 0.06720949709415436 \n",
      "Epoch: 872 | MAE Train Loss: 0.02875622548162937 | MAE Test Loss: 0.0671679675579071 \n",
      "Epoch: 873 | MAE Train Loss: 0.02872132696211338 | MAE Test Loss: 0.06705774366855621 \n",
      "Epoch: 874 | MAE Train Loss: 0.02868732251226902 | MAE Test Loss: 0.06701621413230896 \n",
      "Epoch: 875 | MAE Train Loss: 0.028652798384428024 | MAE Test Loss: 0.06690602004528046 \n",
      "Epoch: 876 | MAE Train Loss: 0.02861841954290867 | MAE Test Loss: 0.0668644830584526 \n",
      "Epoch: 877 | MAE Train Loss: 0.028584271669387817 | MAE Test Loss: 0.06675426661968231 \n",
      "Epoch: 878 | MAE Train Loss: 0.02854951098561287 | MAE Test Loss: 0.06671272963285446 \n",
      "Epoch: 879 | MAE Train Loss: 0.028515750542283058 | MAE Test Loss: 0.06660252809524536 \n",
      "Epoch: 880 | MAE Train Loss: 0.02848084643483162 | MAE Test Loss: 0.06649234890937805 \n",
      "Epoch: 881 | MAE Train Loss: 0.02844698168337345 | MAE Test Loss: 0.06645079702138901 \n",
      "Epoch: 882 | MAE Train Loss: 0.02841232344508171 | MAE Test Loss: 0.06634058058261871 \n",
      "Epoch: 883 | MAE Train Loss: 0.0283780749887228 | MAE Test Loss: 0.06629905849695206 \n",
      "Epoch: 884 | MAE Train Loss: 0.028343800455331802 | MAE Test Loss: 0.06618884950876236 \n",
      "Epoch: 885 | MAE Train Loss: 0.028309166431427002 | MAE Test Loss: 0.06614731252193451 \n",
      "Epoch: 886 | MAE Train Loss: 0.028275271877646446 | MAE Test Loss: 0.06603710353374481 \n",
      "Epoch: 887 | MAE Train Loss: 0.028240377083420753 | MAE Test Loss: 0.06592690199613571 \n",
      "Epoch: 888 | MAE Train Loss: 0.02820664644241333 | MAE Test Loss: 0.06588537245988846 \n",
      "Epoch: 889 | MAE Train Loss: 0.028171848505735397 | MAE Test Loss: 0.06577517092227936 \n",
      "Epoch: 890 | MAE Train Loss: 0.02813773788511753 | MAE Test Loss: 0.06573362648487091 \n",
      "Epoch: 891 | MAE Train Loss: 0.028103316202759743 | MAE Test Loss: 0.06562343239784241 \n",
      "Epoch: 892 | MAE Train Loss: 0.02806883119046688 | MAE Test Loss: 0.06558187305927277 \n",
      "Epoch: 893 | MAE Train Loss: 0.028034795075654984 | MAE Test Loss: 0.06547168642282486 \n",
      "Epoch: 894 | MAE Train Loss: 0.02799992822110653 | MAE Test Loss: 0.06543011963367462 \n",
      "Epoch: 895 | MAE Train Loss: 0.027966270223259926 | MAE Test Loss: 0.06531994044780731 \n",
      "Epoch: 896 | MAE Train Loss: 0.027931367978453636 | MAE Test Loss: 0.0652097538113594 \n",
      "Epoch: 897 | MAE Train Loss: 0.027897397056221962 | MAE Test Loss: 0.06516819447278976 \n",
      "Epoch: 898 | MAE Train Loss: 0.027862846851348877 | MAE Test Loss: 0.06505800783634186 \n",
      "Epoch: 899 | MAE Train Loss: 0.02782849594950676 | MAE Test Loss: 0.06501643359661102 \n",
      "Epoch: 900 | MAE Train Loss: 0.027794325724244118 | MAE Test Loss: 0.06490625441074371 \n",
      "Epoch: 901 | MAE Train Loss: 0.02775958739221096 | MAE Test Loss: 0.06486472487449646 \n",
      "Epoch: 902 | MAE Train Loss: 0.027725791558623314 | MAE Test Loss: 0.06475453078746796 \n",
      "Epoch: 903 | MAE Train Loss: 0.027690891176462173 | MAE Test Loss: 0.06464431434869766 \n",
      "Epoch: 904 | MAE Train Loss: 0.02765706181526184 | MAE Test Loss: 0.06460276246070862 \n",
      "Epoch: 905 | MAE Train Loss: 0.027622371912002563 | MAE Test Loss: 0.06449256837368011 \n",
      "Epoch: 906 | MAE Train Loss: 0.02758815884590149 | MAE Test Loss: 0.06445103138685226 \n",
      "Epoch: 907 | MAE Train Loss: 0.027553845196962357 | MAE Test Loss: 0.06434081494808197 \n",
      "Epoch: 908 | MAE Train Loss: 0.02751925028860569 | MAE Test Loss: 0.06429927796125412 \n",
      "Epoch: 909 | MAE Train Loss: 0.027485316619277 | MAE Test Loss: 0.06418909132480621 \n",
      "Epoch: 910 | MAE Train Loss: 0.02745041623711586 | MAE Test Loss: 0.06407888978719711 \n",
      "Epoch: 911 | MAE Train Loss: 0.02741672471165657 | MAE Test Loss: 0.06403734534978867 \n",
      "Epoch: 912 | MAE Train Loss: 0.027381891384720802 | MAE Test Loss: 0.06392714381217957 \n",
      "Epoch: 913 | MAE Train Loss: 0.027347808703780174 | MAE Test Loss: 0.06388559192419052 \n",
      "Epoch: 914 | MAE Train Loss: 0.027313362807035446 | MAE Test Loss: 0.06377541273832321 \n",
      "Epoch: 915 | MAE Train Loss: 0.02727891504764557 | MAE Test Loss: 0.06373386085033417 \n",
      "Epoch: 916 | MAE Train Loss: 0.02724483609199524 | MAE Test Loss: 0.06362365186214447 \n",
      "Epoch: 917 | MAE Train Loss: 0.02721000649034977 | MAE Test Loss: 0.06358212977647781 \n",
      "Epoch: 918 | MAE Train Loss: 0.027176309376955032 | MAE Test Loss: 0.06347192078828812 \n",
      "Epoch: 919 | MAE Train Loss: 0.02714141272008419 | MAE Test Loss: 0.06336172670125961 \n",
      "Epoch: 920 | MAE Train Loss: 0.0271074827760458 | MAE Test Loss: 0.06332017481327057 \n",
      "Epoch: 921 | MAE Train Loss: 0.027072886005043983 | MAE Test Loss: 0.06320997327566147 \n",
      "Epoch: 922 | MAE Train Loss: 0.0270385779440403 | MAE Test Loss: 0.06316845118999481 \n",
      "Epoch: 923 | MAE Train Loss: 0.027004361152648926 | MAE Test Loss: 0.06305824220180511 \n",
      "Epoch: 924 | MAE Train Loss: 0.0269696656614542 | MAE Test Loss: 0.06301669031381607 \n",
      "Epoch: 925 | MAE Train Loss: 0.02693583443760872 | MAE Test Loss: 0.06290650367736816 \n",
      "Epoch: 926 | MAE Train Loss: 0.026900935918092728 | MAE Test Loss: 0.06279630213975906 \n",
      "Epoch: 927 | MAE Train Loss: 0.02686714567244053 | MAE Test Loss: 0.06275476515293121 \n",
      "Epoch: 928 | MAE Train Loss: 0.02683240734040737 | MAE Test Loss: 0.06264455616474152 \n",
      "Epoch: 929 | MAE Train Loss: 0.02679823711514473 | MAE Test Loss: 0.06260301172733307 \n",
      "Epoch: 930 | MAE Train Loss: 0.026763886213302612 | MAE Test Loss: 0.062492817640304565 \n",
      "Epoch: 931 | MAE Train Loss: 0.02672932669520378 | MAE Test Loss: 0.06245126575231552 \n",
      "Epoch: 932 | MAE Train Loss: 0.026695359498262405 | MAE Test Loss: 0.06234106421470642 \n",
      "Epoch: 933 | MAE Train Loss: 0.026660453528165817 | MAE Test Loss: 0.062230873852968216 \n",
      "Epoch: 934 | MAE Train Loss: 0.02662680111825466 | MAE Test Loss: 0.06218933314085007 \n",
      "Epoch: 935 | MAE Train Loss: 0.026591932401061058 | MAE Test Loss: 0.062079139053821564 \n",
      "Epoch: 936 | MAE Train Loss: 0.02655789814889431 | MAE Test Loss: 0.062037594616413116 \n",
      "Epoch: 937 | MAE Train Loss: 0.026523401960730553 | MAE Test Loss: 0.06192737817764282 \n",
      "Epoch: 938 | MAE Train Loss: 0.026488998904824257 | MAE Test Loss: 0.061885856091976166 \n",
      "Epoch: 939 | MAE Train Loss: 0.02645489014685154 | MAE Test Loss: 0.06177564337849617 \n",
      "Epoch: 940 | MAE Train Loss: 0.02642008289694786 | MAE Test Loss: 0.06173409894108772 \n",
      "Epoch: 941 | MAE Train Loss: 0.026386354118585587 | MAE Test Loss: 0.06162390112876892 \n",
      "Epoch: 942 | MAE Train Loss: 0.026351448148489 | MAE Test Loss: 0.06151369959115982 \n",
      "Epoch: 943 | MAE Train Loss: 0.02631755731999874 | MAE Test Loss: 0.06147215515375137 \n",
      "Epoch: 944 | MAE Train Loss: 0.026282930746674538 | MAE Test Loss: 0.061361975967884064 \n",
      "Epoch: 945 | MAE Train Loss: 0.02624865248799324 | MAE Test Loss: 0.06132042407989502 \n",
      "Epoch: 946 | MAE Train Loss: 0.026214396581053734 | MAE Test Loss: 0.06121024489402771 \n",
      "Epoch: 947 | MAE Train Loss: 0.026179740205407143 | MAE Test Loss: 0.061168670654296875 \n",
      "Epoch: 948 | MAE Train Loss: 0.026145881041884422 | MAE Test Loss: 0.06105848029255867 \n",
      "Epoch: 949 | MAE Train Loss: 0.026110976934432983 | MAE Test Loss: 0.060948289930820465 \n",
      "Epoch: 950 | MAE Train Loss: 0.02607722207903862 | MAE Test Loss: 0.06090673804283142 \n",
      "Epoch: 951 | MAE Train Loss: 0.026042452082037926 | MAE Test Loss: 0.060796551406383514 \n",
      "Epoch: 952 | MAE Train Loss: 0.02600831352174282 | MAE Test Loss: 0.06075499206781387 \n",
      "Epoch: 953 | MAE Train Loss: 0.025973927229642868 | MAE Test Loss: 0.06064480543136597 \n",
      "Epoch: 954 | MAE Train Loss: 0.02593940868973732 | MAE Test Loss: 0.060603249818086624 \n",
      "Epoch: 955 | MAE Train Loss: 0.02590540051460266 | MAE Test Loss: 0.06049305200576782 \n",
      "Epoch: 956 | MAE Train Loss: 0.025870507583022118 | MAE Test Loss: 0.06045151501893997 \n",
      "Epoch: 957 | MAE Train Loss: 0.025836873799562454 | MAE Test Loss: 0.06034131720662117 \n",
      "Epoch: 958 | MAE Train Loss: 0.025801967829465866 | MAE Test Loss: 0.06023111194372177 \n",
      "Epoch: 959 | MAE Train Loss: 0.025767972692847252 | MAE Test Loss: 0.060189567506313324 \n",
      "Epoch: 960 | MAE Train Loss: 0.025733450427651405 | MAE Test Loss: 0.06007937341928482 \n",
      "Epoch: 961 | MAE Train Loss: 0.0256990734487772 | MAE Test Loss: 0.06003783270716667 \n",
      "Epoch: 962 | MAE Train Loss: 0.0256649199873209 | MAE Test Loss: 0.05992763116955757 \n",
      "Epoch: 963 | MAE Train Loss: 0.02563016675412655 | MAE Test Loss: 0.05988607555627823 \n",
      "Epoch: 964 | MAE Train Loss: 0.025596395134925842 | MAE Test Loss: 0.05977589637041092 \n",
      "Epoch: 965 | MAE Train Loss: 0.02556149661540985 | MAE Test Loss: 0.05966568738222122 \n",
      "Epoch: 966 | MAE Train Loss: 0.02552764117717743 | MAE Test Loss: 0.05962413549423218 \n",
      "Epoch: 967 | MAE Train Loss: 0.025492969900369644 | MAE Test Loss: 0.05951394885778427 \n",
      "Epoch: 968 | MAE Train Loss: 0.02545873448252678 | MAE Test Loss: 0.059472404420375824 \n",
      "Epoch: 969 | MAE Train Loss: 0.025424445047974586 | MAE Test Loss: 0.059362202882766724 \n",
      "Epoch: 970 | MAE Train Loss: 0.02538982965052128 | MAE Test Loss: 0.05932066589593887 \n",
      "Epoch: 971 | MAE Train Loss: 0.02535592019557953 | MAE Test Loss: 0.059210460633039474 \n",
      "Epoch: 972 | MAE Train Loss: 0.02532101795077324 | MAE Test Loss: 0.05910026282072067 \n",
      "Epoch: 973 | MAE Train Loss: 0.02528730034828186 | MAE Test Loss: 0.059058718383312225 \n",
      "Epoch: 974 | MAE Train Loss: 0.025252491235733032 | MAE Test Loss: 0.058948516845703125 \n",
      "Epoch: 975 | MAE Train Loss: 0.02521839737892151 | MAE Test Loss: 0.05890697240829468 \n",
      "Epoch: 976 | MAE Train Loss: 0.025183964520692825 | MAE Test Loss: 0.058796774595975876 \n",
      "Epoch: 977 | MAE Train Loss: 0.02514948509633541 | MAE Test Loss: 0.05875522643327713 \n",
      "Epoch: 978 | MAE Train Loss: 0.02511543594300747 | MAE Test Loss: 0.058645039796829224 \n",
      "Epoch: 979 | MAE Train Loss: 0.025080587714910507 | MAE Test Loss: 0.05860348790884018 \n",
      "Epoch: 980 | MAE Train Loss: 0.02504691109061241 | MAE Test Loss: 0.058493297547101974 \n",
      "Epoch: 981 | MAE Train Loss: 0.02501201629638672 | MAE Test Loss: 0.058383096009492874 \n",
      "Epoch: 982 | MAE Train Loss: 0.02497805655002594 | MAE Test Loss: 0.058341555297374725 \n",
      "Epoch: 983 | MAE Train Loss: 0.024943487718701363 | MAE Test Loss: 0.05823137238621712 \n",
      "Epoch: 984 | MAE Train Loss: 0.024909157305955887 | MAE Test Loss: 0.05818980187177658 \n",
      "Epoch: 985 | MAE Train Loss: 0.024874964728951454 | MAE Test Loss: 0.05807960033416748 \n",
      "Epoch: 986 | MAE Train Loss: 0.024840235710144043 | MAE Test Loss: 0.05803806334733963 \n",
      "Epoch: 987 | MAE Train Loss: 0.024806439876556396 | MAE Test Loss: 0.057927876710891724 \n",
      "Epoch: 988 | MAE Train Loss: 0.024771535769104958 | MAE Test Loss: 0.05781765654683113 \n",
      "Epoch: 989 | MAE Train Loss: 0.02473771944642067 | MAE Test Loss: 0.05777612328529358 \n",
      "Epoch: 990 | MAE Train Loss: 0.0247030109167099 | MAE Test Loss: 0.057665932923555374 \n",
      "Epoch: 991 | MAE Train Loss: 0.024668816477060318 | MAE Test Loss: 0.057624392211437225 \n",
      "Epoch: 992 | MAE Train Loss: 0.024634480476379395 | MAE Test Loss: 0.05751417949795723 \n",
      "Epoch: 993 | MAE Train Loss: 0.024599911645054817 | MAE Test Loss: 0.05747263878583908 \n",
      "Epoch: 994 | MAE Train Loss: 0.024565961211919785 | MAE Test Loss: 0.05736243724822998 \n",
      "Epoch: 995 | MAE Train Loss: 0.024531055241823196 | MAE Test Loss: 0.05725225806236267 \n",
      "Epoch: 996 | MAE Train Loss: 0.02449738048017025 | MAE Test Loss: 0.05721070617437363 \n",
      "Epoch: 997 | MAE Train Loss: 0.024462532252073288 | MAE Test Loss: 0.057100486010313034 \n",
      "Epoch: 998 | MAE Train Loss: 0.02442847564816475 | MAE Test Loss: 0.057058971375226974 \n",
      "Epoch: 999 | MAE Train Loss: 0.02439401112496853 | MAE Test Loss: 0.05694875866174698 \n",
      "Epoch: 1000 | MAE Train Loss: 0.02435956709086895 | MAE Test Loss: 0.05690721794962883 \n",
      "Epoch: 1001 | MAE Train Loss: 0.024325478821992874 | MAE Test Loss: 0.05679702013731003 \n",
      "Epoch: 1002 | MAE Train Loss: 0.024290667846798897 | MAE Test Loss: 0.05675547197461128 \n",
      "Epoch: 1003 | MAE Train Loss: 0.024256955832242966 | MAE Test Loss: 0.05664528161287308 \n",
      "Epoch: 1004 | MAE Train Loss: 0.024222057312726974 | MAE Test Loss: 0.05653507634997368 \n",
      "Epoch: 1005 | MAE Train Loss: 0.02418813668191433 | MAE Test Loss: 0.05649354308843613 \n",
      "Epoch: 1006 | MAE Train Loss: 0.02415352500975132 | MAE Test Loss: 0.056383341550827026 \n",
      "Epoch: 1007 | MAE Train Loss: 0.02411923184990883 | MAE Test Loss: 0.056341785937547684 \n",
      "Epoch: 1008 | MAE Train Loss: 0.02408500388264656 | MAE Test Loss: 0.05623159557580948 \n",
      "Epoch: 1009 | MAE Train Loss: 0.024050328880548477 | MAE Test Loss: 0.05619003251194954 \n",
      "Epoch: 1010 | MAE Train Loss: 0.024016480892896652 | MAE Test Loss: 0.05607985332608223 \n",
      "Epoch: 1011 | MAE Train Loss: 0.023981576785445213 | MAE Test Loss: 0.055969662964344025 \n",
      "Epoch: 1012 | MAE Train Loss: 0.02394779585301876 | MAE Test Loss: 0.055928103625774384 \n",
      "Epoch: 1013 | MAE Train Loss: 0.023913055658340454 | MAE Test Loss: 0.05581791326403618 \n",
      "Epoch: 1014 | MAE Train Loss: 0.023878900334239006 | MAE Test Loss: 0.055776339024305344 \n",
      "Epoch: 1015 | MAE Train Loss: 0.023844534531235695 | MAE Test Loss: 0.05566616728901863 \n",
      "Epoch: 1016 | MAE Train Loss: 0.02380998805165291 | MAE Test Loss: 0.05562462657690048 \n",
      "Epoch: 1017 | MAE Train Loss: 0.02377600036561489 | MAE Test Loss: 0.05551443621516228 \n",
      "Epoch: 1018 | MAE Train Loss: 0.0237411018460989 | MAE Test Loss: 0.05540422722697258 \n",
      "Epoch: 1019 | MAE Train Loss: 0.02370746247470379 | MAE Test Loss: 0.05536267161369324 \n",
      "Epoch: 1020 | MAE Train Loss: 0.02367258258163929 | MAE Test Loss: 0.055252473801374435 \n",
      "Epoch: 1021 | MAE Train Loss: 0.023638557642698288 | MAE Test Loss: 0.055210936814546585 \n",
      "Epoch: 1022 | MAE Train Loss: 0.023604054003953934 | MAE Test Loss: 0.055100731551647186 \n",
      "Epoch: 1023 | MAE Train Loss: 0.023569650948047638 | MAE Test Loss: 0.05505918711423874 \n",
      "Epoch: 1024 | MAE Train Loss: 0.02353552170097828 | MAE Test Loss: 0.05494900420308113 \n",
      "Epoch: 1025 | MAE Train Loss: 0.023500746116042137 | MAE Test Loss: 0.054907459765672684 \n",
      "Epoch: 1026 | MAE Train Loss: 0.02346699871122837 | MAE Test Loss: 0.054797254502773285 \n",
      "Epoch: 1027 | MAE Train Loss: 0.02343210019171238 | MAE Test Loss: 0.054687052965164185 \n",
      "Epoch: 1028 | MAE Train Loss: 0.023398209363222122 | MAE Test Loss: 0.05464550852775574 \n",
      "Epoch: 1029 | MAE Train Loss: 0.023363569751381874 | MAE Test Loss: 0.05453531816601753 \n",
      "Epoch: 1030 | MAE Train Loss: 0.023329313844442368 | MAE Test Loss: 0.054493773728609085 \n",
      "Epoch: 1031 | MAE Train Loss: 0.023295046761631966 | MAE Test Loss: 0.05438356474041939 \n",
      "Epoch: 1032 | MAE Train Loss: 0.02326040528714657 | MAE Test Loss: 0.054342031478881836 \n",
      "Epoch: 1033 | MAE Train Loss: 0.02322651818394661 | MAE Test Loss: 0.054231829941272736 \n",
      "Epoch: 1034 | MAE Train Loss: 0.023191621527075768 | MAE Test Loss: 0.054121632128953934 \n",
      "Epoch: 1035 | MAE Train Loss: 0.023157883435487747 | MAE Test Loss: 0.05408008024096489 \n",
      "Epoch: 1036 | MAE Train Loss: 0.02312309481203556 | MAE Test Loss: 0.05396988242864609 \n",
      "Epoch: 1037 | MAE Train Loss: 0.023088976740837097 | MAE Test Loss: 0.05392835661768913 \n",
      "Epoch: 1038 | MAE Train Loss: 0.023054569959640503 | MAE Test Loss: 0.05381814390420914 \n",
      "Epoch: 1039 | MAE Train Loss: 0.02302006632089615 | MAE Test Loss: 0.05377660319209099 \n",
      "Epoch: 1040 | MAE Train Loss: 0.022986043244600296 | MAE Test Loss: 0.05366641283035278 \n",
      "Epoch: 1041 | MAE Train Loss: 0.022951165214180946 | MAE Test Loss: 0.053624849766492844 \n",
      "Epoch: 1042 | MAE Train Loss: 0.022917520254850388 | MAE Test Loss: 0.05351467803120613 \n",
      "Epoch: 1043 | MAE Train Loss: 0.02288261614739895 | MAE Test Loss: 0.05340446159243584 \n",
      "Epoch: 1044 | MAE Train Loss: 0.02284863591194153 | MAE Test Loss: 0.05336291715502739 \n",
      "Epoch: 1045 | MAE Train Loss: 0.02281409129500389 | MAE Test Loss: 0.053252726793289185 \n",
      "Epoch: 1046 | MAE Train Loss: 0.022779732942581177 | MAE Test Loss: 0.05321118235588074 \n",
      "Epoch: 1047 | MAE Train Loss: 0.022745568305253983 | MAE Test Loss: 0.05310098081827164 \n",
      "Epoch: 1048 | MAE Train Loss: 0.022710826247930527 | MAE Test Loss: 0.05305942893028259 \n",
      "Epoch: 1049 | MAE Train Loss: 0.02267703041434288 | MAE Test Loss: 0.052949242293834686 \n",
      "Epoch: 1050 | MAE Train Loss: 0.022642139345407486 | MAE Test Loss: 0.05283904820680618 \n",
      "Epoch: 1051 | MAE Train Loss: 0.022608298808336258 | MAE Test Loss: 0.05279749631881714 \n",
      "Epoch: 1052 | MAE Train Loss: 0.02257360890507698 | MAE Test Loss: 0.05268728733062744 \n",
      "Epoch: 1053 | MAE Train Loss: 0.022539397701621056 | MAE Test Loss: 0.052645765244960785 \n",
      "Epoch: 1054 | MAE Train Loss: 0.022505097091197968 | MAE Test Loss: 0.05253554508090019 \n",
      "Epoch: 1055 | MAE Train Loss: 0.02247048355638981 | MAE Test Loss: 0.05249400809407234 \n",
      "Epoch: 1056 | MAE Train Loss: 0.022436564788222313 | MAE Test Loss: 0.05238381028175354 \n",
      "Epoch: 1057 | MAE Train Loss: 0.022401660680770874 | MAE Test Loss: 0.05227361246943474 \n",
      "Epoch: 1058 | MAE Train Loss: 0.02236795797944069 | MAE Test Loss: 0.05223206430673599 \n",
      "Epoch: 1059 | MAE Train Loss: 0.022333137691020966 | MAE Test Loss: 0.05212188512086868 \n",
      "Epoch: 1060 | MAE Train Loss: 0.02229905314743519 | MAE Test Loss: 0.05208033323287964 \n",
      "Epoch: 1061 | MAE Train Loss: 0.02226460725069046 | MAE Test Loss: 0.05197015404701233 \n",
      "Epoch: 1062 | MAE Train Loss: 0.02223013900220394 | MAE Test Loss: 0.05192858725786209 \n",
      "Epoch: 1063 | MAE Train Loss: 0.02219608798623085 | MAE Test Loss: 0.05181838944554329 \n",
      "Epoch: 1064 | MAE Train Loss: 0.022161245346069336 | MAE Test Loss: 0.051776837557554245 \n",
      "Epoch: 1065 | MAE Train Loss: 0.022127559408545494 | MAE Test Loss: 0.05166664719581604 \n",
      "Epoch: 1066 | MAE Train Loss: 0.022092660889029503 | MAE Test Loss: 0.05155646800994873 \n",
      "Epoch: 1067 | MAE Train Loss: 0.02205871418118477 | MAE Test Loss: 0.05151490122079849 \n",
      "Epoch: 1068 | MAE Train Loss: 0.022024136036634445 | MAE Test Loss: 0.051404714584350586 \n",
      "Epoch: 1069 | MAE Train Loss: 0.021989809349179268 | MAE Test Loss: 0.051363151520490646 \n",
      "Epoch: 1070 | MAE Train Loss: 0.02195560745894909 | MAE Test Loss: 0.05125296115875244 \n",
      "Epoch: 1071 | MAE Train Loss: 0.021920906379818916 | MAE Test Loss: 0.05121142417192459 \n",
      "Epoch: 1072 | MAE Train Loss: 0.02188708260655403 | MAE Test Loss: 0.05110122635960579 \n",
      "Epoch: 1073 | MAE Train Loss: 0.02185218036174774 | MAE Test Loss: 0.05099101737141609 \n",
      "Epoch: 1074 | MAE Train Loss: 0.0218183733522892 | MAE Test Loss: 0.05094947665929794 \n",
      "Epoch: 1075 | MAE Train Loss: 0.021783655509352684 | MAE Test Loss: 0.05083928257226944 \n",
      "Epoch: 1076 | MAE Train Loss: 0.02174947038292885 | MAE Test Loss: 0.05079774186015129 \n",
      "Epoch: 1077 | MAE Train Loss: 0.021715128794312477 | MAE Test Loss: 0.05068754032254219 \n",
      "Epoch: 1078 | MAE Train Loss: 0.021680567413568497 | MAE Test Loss: 0.050645988434553146 \n",
      "Epoch: 1079 | MAE Train Loss: 0.02164660580456257 | MAE Test Loss: 0.05053580552339554 \n",
      "Epoch: 1080 | MAE Train Loss: 0.021611705422401428 | MAE Test Loss: 0.05042559653520584 \n",
      "Epoch: 1081 | MAE Train Loss: 0.021578039973974228 | MAE Test Loss: 0.050384052097797394 \n",
      "Epoch: 1082 | MAE Train Loss: 0.02154317870736122 | MAE Test Loss: 0.05027385801076889 \n",
      "Epoch: 1083 | MAE Train Loss: 0.021509135141968727 | MAE Test Loss: 0.05023231357336044 \n",
      "Epoch: 1084 | MAE Train Loss: 0.021474653854966164 | MAE Test Loss: 0.05012211948633194 \n",
      "Epoch: 1085 | MAE Train Loss: 0.021440228447318077 | MAE Test Loss: 0.05008057504892349 \n",
      "Epoch: 1086 | MAE Train Loss: 0.021406125277280807 | MAE Test Loss: 0.049970369786024094 \n",
      "Epoch: 1087 | MAE Train Loss: 0.021371323615312576 | MAE Test Loss: 0.04992884397506714 \n",
      "Epoch: 1088 | MAE Train Loss: 0.02133760042488575 | MAE Test Loss: 0.049818623811006546 \n",
      "Epoch: 1089 | MAE Train Loss: 0.02130269818007946 | MAE Test Loss: 0.04970841854810715 \n",
      "Epoch: 1090 | MAE Train Loss: 0.021268798038363457 | MAE Test Loss: 0.0496668815612793 \n",
      "Epoch: 1091 | MAE Train Loss: 0.021234173327684402 | MAE Test Loss: 0.049556683748960495 \n",
      "Epoch: 1092 | MAE Train Loss: 0.021199887618422508 | MAE Test Loss: 0.04951513558626175 \n",
      "Epoch: 1093 | MAE Train Loss: 0.021165648475289345 | MAE Test Loss: 0.04940494894981384 \n",
      "Epoch: 1094 | MAE Train Loss: 0.021130988374352455 | MAE Test Loss: 0.0493633933365345 \n",
      "Epoch: 1095 | MAE Train Loss: 0.02109711989760399 | MAE Test Loss: 0.049253206700086594 \n",
      "Epoch: 1096 | MAE Train Loss: 0.021062226966023445 | MAE Test Loss: 0.04914300516247749 \n",
      "Epoch: 1097 | MAE Train Loss: 0.02102845534682274 | MAE Test Loss: 0.049101464450359344 \n",
      "Epoch: 1098 | MAE Train Loss: 0.02099369652569294 | MAE Test Loss: 0.048991281539201736 \n",
      "Epoch: 1099 | MAE Train Loss: 0.020959556102752686 | MAE Test Loss: 0.0489497110247612 \n",
      "Epoch: 1100 | MAE Train Loss: 0.02092517353594303 | MAE Test Loss: 0.0488395169377327 \n",
      "Epoch: 1101 | MAE Train Loss: 0.02089063450694084 | MAE Test Loss: 0.04879797250032425 \n",
      "Epoch: 1102 | MAE Train Loss: 0.020856648683547974 | MAE Test Loss: 0.048687778413295746 \n",
      "Epoch: 1103 | MAE Train Loss: 0.020821744576096535 | MAE Test Loss: 0.048577576875686646 \n",
      "Epoch: 1104 | MAE Train Loss: 0.020788121968507767 | MAE Test Loss: 0.0485360324382782 \n",
      "Epoch: 1105 | MAE Train Loss: 0.020753219723701477 | MAE Test Loss: 0.04842584207653999 \n",
      "Epoch: 1106 | MAE Train Loss: 0.020719215273857117 | MAE Test Loss: 0.04838430881500244 \n",
      "Epoch: 1107 | MAE Train Loss: 0.02068468928337097 | MAE Test Loss: 0.04827408120036125 \n",
      "Epoch: 1108 | MAE Train Loss: 0.020650310441851616 | MAE Test Loss: 0.0482325553894043 \n",
      "Epoch: 1109 | MAE Train Loss: 0.02061617001891136 | MAE Test Loss: 0.0481223464012146 \n",
      "Epoch: 1110 | MAE Train Loss: 0.020581401884555817 | MAE Test Loss: 0.04808080196380615 \n",
      "Epoch: 1111 | MAE Train Loss: 0.020547647029161453 | MAE Test Loss: 0.047970615327358246 \n",
      "Epoch: 1112 | MAE Train Loss: 0.020512741059064865 | MAE Test Loss: 0.04786039516329765 \n",
      "Epoch: 1113 | MAE Train Loss: 0.020478874444961548 | MAE Test Loss: 0.047818876802921295 \n",
      "Epoch: 1114 | MAE Train Loss: 0.020444219931960106 | MAE Test Loss: 0.0477086678147316 \n",
      "Epoch: 1115 | MAE Train Loss: 0.020409967750310898 | MAE Test Loss: 0.04766712710261345 \n",
      "Epoch: 1116 | MAE Train Loss: 0.02037569135427475 | MAE Test Loss: 0.04755692556500435 \n",
      "Epoch: 1117 | MAE Train Loss: 0.020341066643595695 | MAE Test Loss: 0.0475153811275959 \n",
      "Epoch: 1118 | MAE Train Loss: 0.020307164639234543 | MAE Test Loss: 0.0474051907658577 \n",
      "Epoch: 1119 | MAE Train Loss: 0.02027226611971855 | MAE Test Loss: 0.047294992953538895 \n",
      "Epoch: 1120 | MAE Train Loss: 0.020238537341356277 | MAE Test Loss: 0.047253452241420746 \n",
      "Epoch: 1121 | MAE Train Loss: 0.020203733816742897 | MAE Test Loss: 0.047143250703811646 \n",
      "Epoch: 1122 | MAE Train Loss: 0.020169630646705627 | MAE Test Loss: 0.0471016988158226 \n",
      "Epoch: 1123 | MAE Train Loss: 0.020135212689638138 | MAE Test Loss: 0.0469915047287941 \n",
      "Epoch: 1124 | MAE Train Loss: 0.020100727677345276 | MAE Test Loss: 0.046949952840805054 \n",
      "Epoch: 1125 | MAE Train Loss: 0.02006668969988823 | MAE Test Loss: 0.04683975502848625 \n",
      "Epoch: 1126 | MAE Train Loss: 0.020031820982694626 | MAE Test Loss: 0.0467982180416584 \n",
      "Epoch: 1127 | MAE Train Loss: 0.01999816671013832 | MAE Test Loss: 0.046688012778759 \n",
      "Epoch: 1128 | MAE Train Loss: 0.01996326446533203 | MAE Test Loss: 0.0465778224170208 \n",
      "Epoch: 1129 | MAE Train Loss: 0.019929300993680954 | MAE Test Loss: 0.04653624817728996 \n",
      "Epoch: 1130 | MAE Train Loss: 0.019894743338227272 | MAE Test Loss: 0.04642607644200325 \n",
      "Epoch: 1131 | MAE Train Loss: 0.019860386848449707 | MAE Test Loss: 0.0463845357298851 \n",
      "Epoch: 1132 | MAE Train Loss: 0.019826212897896767 | MAE Test Loss: 0.0462743416428566 \n",
      "Epoch: 1133 | MAE Train Loss: 0.019791483879089355 | MAE Test Loss: 0.04623277112841606 \n",
      "Epoch: 1134 | MAE Train Loss: 0.01975768432021141 | MAE Test Loss: 0.046122580766677856 \n",
      "Epoch: 1135 | MAE Train Loss: 0.019722791388630867 | MAE Test Loss: 0.046012382954359055 \n",
      "Epoch: 1136 | MAE Train Loss: 0.019688956439495087 | MAE Test Loss: 0.045970845967531204 \n",
      "Epoch: 1137 | MAE Train Loss: 0.01965426094830036 | MAE Test Loss: 0.0458606481552124 \n",
      "Epoch: 1138 | MAE Train Loss: 0.019620049744844437 | MAE Test Loss: 0.045819103717803955 \n",
      "Epoch: 1139 | MAE Train Loss: 0.019585730507969856 | MAE Test Loss: 0.04570891708135605 \n",
      "Epoch: 1140 | MAE Train Loss: 0.019551146775484085 | MAE Test Loss: 0.0456673689186573 \n",
      "Epoch: 1141 | MAE Train Loss: 0.019517207518219948 | MAE Test Loss: 0.045557163655757904 \n",
      "Epoch: 1142 | MAE Train Loss: 0.019482305273413658 | MAE Test Loss: 0.045446962118148804 \n",
      "Epoch: 1143 | MAE Train Loss: 0.01944860816001892 | MAE Test Loss: 0.045405417680740356 \n",
      "Epoch: 1144 | MAE Train Loss: 0.01941377855837345 | MAE Test Loss: 0.04529522731900215 \n",
      "Epoch: 1145 | MAE Train Loss: 0.019379712641239166 | MAE Test Loss: 0.045253682881593704 \n",
      "Epoch: 1146 | MAE Train Loss: 0.019345253705978394 | MAE Test Loss: 0.04514347389340401 \n",
      "Epoch: 1147 | MAE Train Loss: 0.019310805946588516 | MAE Test Loss: 0.045101940631866455 \n",
      "Epoch: 1148 | MAE Train Loss: 0.019276728853583336 | MAE Test Loss: 0.044991739094257355 \n",
      "Epoch: 1149 | MAE Train Loss: 0.019241899251937866 | MAE Test Loss: 0.044950198382139206 \n",
      "Epoch: 1150 | MAE Train Loss: 0.019208211451768875 | MAE Test Loss: 0.04483998939394951 \n",
      "Epoch: 1151 | MAE Train Loss: 0.019173303619027138 | MAE Test Loss: 0.044729799032211304 \n",
      "Epoch: 1152 | MAE Train Loss: 0.019139375537633896 | MAE Test Loss: 0.04468826204538345 \n",
      "Epoch: 1153 | MAE Train Loss: 0.01910477876663208 | MAE Test Loss: 0.044578056782484055 \n",
      "Epoch: 1154 | MAE Train Loss: 0.019070465117692947 | MAE Test Loss: 0.04453650861978531 \n",
      "Epoch: 1155 | MAE Train Loss: 0.019036252051591873 | MAE Test Loss: 0.0444263219833374 \n",
      "Epoch: 1156 | MAE Train Loss: 0.019001564010977745 | MAE Test Loss: 0.04438475891947746 \n",
      "Epoch: 1157 | MAE Train Loss: 0.018967729061841965 | MAE Test Loss: 0.04427458718419075 \n",
      "Epoch: 1158 | MAE Train Loss: 0.018932823091745377 | MAE Test Loss: 0.044164370745420456 \n",
      "Epoch: 1159 | MAE Train Loss: 0.018899032846093178 | MAE Test Loss: 0.04412282630801201 \n",
      "Epoch: 1160 | MAE Train Loss: 0.018864300101995468 | MAE Test Loss: 0.044012635946273804 \n",
      "Epoch: 1161 | MAE Train Loss: 0.018830131739377975 | MAE Test Loss: 0.043971091508865356 \n",
      "Epoch: 1162 | MAE Train Loss: 0.01879577711224556 | MAE Test Loss: 0.043860889971256256 \n",
      "Epoch: 1163 | MAE Train Loss: 0.018761225044727325 | MAE Test Loss: 0.04381933808326721 \n",
      "Epoch: 1164 | MAE Train Loss: 0.018727242946624756 | MAE Test Loss: 0.043709151446819305 \n",
      "Epoch: 1165 | MAE Train Loss: 0.018692348152399063 | MAE Test Loss: 0.0435989573597908 \n",
      "Epoch: 1166 | MAE Train Loss: 0.018658697605133057 | MAE Test Loss: 0.04355739802122116 \n",
      "Epoch: 1167 | MAE Train Loss: 0.018623817712068558 | MAE Test Loss: 0.043447189033031464 \n",
      "Epoch: 1168 | MAE Train Loss: 0.018589798361063004 | MAE Test Loss: 0.043405670672655106 \n",
      "Epoch: 1169 | MAE Train Loss: 0.018555304035544395 | MAE Test Loss: 0.04329545423388481 \n",
      "Epoch: 1170 | MAE Train Loss: 0.018520886078476906 | MAE Test Loss: 0.04325391724705696 \n",
      "Epoch: 1171 | MAE Train Loss: 0.01848677359521389 | MAE Test Loss: 0.04314371943473816 \n",
      "Epoch: 1172 | MAE Train Loss: 0.018451979383826256 | MAE Test Loss: 0.043102167546749115 \n",
      "Epoch: 1173 | MAE Train Loss: 0.018418248742818832 | MAE Test Loss: 0.04299197718501091 \n",
      "Epoch: 1174 | MAE Train Loss: 0.018383344635367393 | MAE Test Loss: 0.0428817942738533 \n",
      "Epoch: 1175 | MAE Train Loss: 0.018349451944231987 | MAE Test Loss: 0.04284024238586426 \n",
      "Epoch: 1176 | MAE Train Loss: 0.018314816057682037 | MAE Test Loss: 0.04273006319999695 \n",
      "Epoch: 1177 | MAE Train Loss: 0.01828053966164589 | MAE Test Loss: 0.04268849641084671 \n",
      "Epoch: 1178 | MAE Train Loss: 0.018246296793222427 | MAE Test Loss: 0.04257829859852791 \n",
      "Epoch: 1179 | MAE Train Loss: 0.018211644142866135 | MAE Test Loss: 0.042536746710538864 \n",
      "Epoch: 1180 | MAE Train Loss: 0.01817776821553707 | MAE Test Loss: 0.04242655634880066 \n",
      "Epoch: 1181 | MAE Train Loss: 0.01814286969602108 | MAE Test Loss: 0.04231637716293335 \n",
      "Epoch: 1182 | MAE Train Loss: 0.018109114840626717 | MAE Test Loss: 0.04227481037378311 \n",
      "Epoch: 1183 | MAE Train Loss: 0.018074344843626022 | MAE Test Loss: 0.04216461628675461 \n",
      "Epoch: 1184 | MAE Train Loss: 0.018040208145976067 | MAE Test Loss: 0.042123060673475266 \n",
      "Epoch: 1185 | MAE Train Loss: 0.018005816265940666 | MAE Test Loss: 0.04201287031173706 \n",
      "Epoch: 1186 | MAE Train Loss: 0.017971305176615715 | MAE Test Loss: 0.04197133332490921 \n",
      "Epoch: 1187 | MAE Train Loss: 0.01793729141354561 | MAE Test Loss: 0.04186113923788071 \n",
      "Epoch: 1188 | MAE Train Loss: 0.017902398481965065 | MAE Test Loss: 0.04181956499814987 \n",
      "Epoch: 1189 | MAE Train Loss: 0.017868772149086 | MAE Test Loss: 0.04170939326286316 \n",
      "Epoch: 1190 | MAE Train Loss: 0.01783386431634426 | MAE Test Loss: 0.04159919545054436 \n",
      "Epoch: 1191 | MAE Train Loss: 0.017799871042370796 | MAE Test Loss: 0.04155765101313591 \n",
      "Epoch: 1192 | MAE Train Loss: 0.017765337601304054 | MAE Test Loss: 0.04144744947552681 \n",
      "Epoch: 1193 | MAE Train Loss: 0.017730968073010445 | MAE Test Loss: 0.041405897587537766 \n",
      "Epoch: 1194 | MAE Train Loss: 0.017696814611554146 | MAE Test Loss: 0.04129571467638016 \n",
      "Epoch: 1195 | MAE Train Loss: 0.017662061378359795 | MAE Test Loss: 0.04125417023897171 \n",
      "Epoch: 1196 | MAE Train Loss: 0.017628289759159088 | MAE Test Loss: 0.04114396125078201 \n",
      "Epoch: 1197 | MAE Train Loss: 0.0175933875143528 | MAE Test Loss: 0.04103376343846321 \n",
      "Epoch: 1198 | MAE Train Loss: 0.017559533938765526 | MAE Test Loss: 0.04099222272634506 \n",
      "Epoch: 1199 | MAE Train Loss: 0.01752486266195774 | MAE Test Loss: 0.04088203236460686 \n",
      "Epoch: 1200 | MAE Train Loss: 0.017490629106760025 | MAE Test Loss: 0.04084048420190811 \n",
      "Epoch: 1201 | MAE Train Loss: 0.017456334084272385 | MAE Test Loss: 0.040730275213718414 \n",
      "Epoch: 1202 | MAE Train Loss: 0.017421722412109375 | MAE Test Loss: 0.04068875312805176 \n",
      "Epoch: 1203 | MAE Train Loss: 0.017387809231877327 | MAE Test Loss: 0.040578536689281464 \n",
      "Epoch: 1204 | MAE Train Loss: 0.017352908849716187 | MAE Test Loss: 0.04046833515167236 \n",
      "Epoch: 1205 | MAE Train Loss: 0.017319198697805405 | MAE Test Loss: 0.040426790714263916 \n",
      "Epoch: 1206 | MAE Train Loss: 0.01728438213467598 | MAE Test Loss: 0.040316592901945114 \n",
      "Epoch: 1207 | MAE Train Loss: 0.017250288277864456 | MAE Test Loss: 0.04027504473924637 \n",
      "Epoch: 1208 | MAE Train Loss: 0.017215853556990623 | MAE Test Loss: 0.04016486555337906 \n",
      "Epoch: 1209 | MAE Train Loss: 0.017181387171149254 | MAE Test Loss: 0.04012330621480942 \n",
      "Epoch: 1210 | MAE Train Loss: 0.017147328704595566 | MAE Test Loss: 0.040013112127780914 \n",
      "Epoch: 1211 | MAE Train Loss: 0.017112482339143753 | MAE Test Loss: 0.039971571415662766 \n",
      "Epoch: 1212 | MAE Train Loss: 0.017078805714845657 | MAE Test Loss: 0.039861373603343964 \n",
      "Epoch: 1213 | MAE Train Loss: 0.017043905332684517 | MAE Test Loss: 0.039751190692186356 \n",
      "Epoch: 1214 | MAE Train Loss: 0.017009954899549484 | MAE Test Loss: 0.03970962017774582 \n",
      "Epoch: 1215 | MAE Train Loss: 0.01697538234293461 | MAE Test Loss: 0.039599429816007614 \n",
      "Epoch: 1216 | MAE Train Loss: 0.01694103702902794 | MAE Test Loss: 0.03955788165330887 \n",
      "Epoch: 1217 | MAE Train Loss: 0.01690686121582985 | MAE Test Loss: 0.03944769501686096 \n",
      "Epoch: 1218 | MAE Train Loss: 0.016872137784957886 | MAE Test Loss: 0.03940613940358162 \n",
      "Epoch: 1219 | MAE Train Loss: 0.016838330775499344 | MAE Test Loss: 0.03929593041539192 \n",
      "Epoch: 1220 | MAE Train Loss: 0.016803432255983353 | MAE Test Loss: 0.03918575122952461 \n",
      "Epoch: 1221 | MAE Train Loss: 0.016769614070653915 | MAE Test Loss: 0.03914421796798706 \n",
      "Epoch: 1222 | MAE Train Loss: 0.01673489809036255 | MAE Test Loss: 0.039034001529216766 \n",
      "Epoch: 1223 | MAE Train Loss: 0.016700709238648415 | MAE Test Loss: 0.038992464542388916 \n",
      "Epoch: 1224 | MAE Train Loss: 0.01666637882590294 | MAE Test Loss: 0.038882263004779816 \n",
      "Epoch: 1225 | MAE Train Loss: 0.016631800681352615 | MAE Test Loss: 0.03884071111679077 \n",
      "Epoch: 1226 | MAE Train Loss: 0.01659785583615303 | MAE Test Loss: 0.03873053193092346 \n",
      "Epoch: 1227 | MAE Train Loss: 0.016562949866056442 | MAE Test Loss: 0.03862030431628227 \n",
      "Epoch: 1228 | MAE Train Loss: 0.016529273241758347 | MAE Test Loss: 0.03857877850532532 \n",
      "Epoch: 1229 | MAE Train Loss: 0.016494428738951683 | MAE Test Loss: 0.03846857696771622 \n",
      "Epoch: 1230 | MAE Train Loss: 0.016460370272397995 | MAE Test Loss: 0.03842703625559807 \n",
      "Epoch: 1231 | MAE Train Loss: 0.016425900161266327 | MAE Test Loss: 0.03831683471798897 \n",
      "Epoch: 1232 | MAE Train Loss: 0.016391465440392494 | MAE Test Loss: 0.03827529028058052 \n",
      "Epoch: 1233 | MAE Train Loss: 0.01635737530887127 | MAE Test Loss: 0.038165103644132614 \n",
      "Epoch: 1234 | MAE Train Loss: 0.016322556883096695 | MAE Test Loss: 0.038123566657304764 \n",
      "Epoch: 1235 | MAE Train Loss: 0.01628885231912136 | MAE Test Loss: 0.038013357669115067 \n",
      "Epoch: 1236 | MAE Train Loss: 0.016253944486379623 | MAE Test Loss: 0.037903159856796265 \n",
      "Epoch: 1237 | MAE Train Loss: 0.016220029443502426 | MAE Test Loss: 0.03786160424351692 \n",
      "Epoch: 1238 | MAE Train Loss: 0.016185421496629715 | MAE Test Loss: 0.03775141388177872 \n",
      "Epoch: 1239 | MAE Train Loss: 0.016151126474142075 | MAE Test Loss: 0.03770986199378967 \n",
      "Epoch: 1240 | MAE Train Loss: 0.016116898506879807 | MAE Test Loss: 0.03759966418147087 \n",
      "Epoch: 1241 | MAE Train Loss: 0.016082221642136574 | MAE Test Loss: 0.03755812719464302 \n",
      "Epoch: 1242 | MAE Train Loss: 0.016048375517129898 | MAE Test Loss: 0.03744792938232422 \n",
      "Epoch: 1243 | MAE Train Loss: 0.01601347327232361 | MAE Test Loss: 0.03733773157000542 \n",
      "Epoch: 1244 | MAE Train Loss: 0.015979699790477753 | MAE Test Loss: 0.03729615360498428 \n",
      "Epoch: 1245 | MAE Train Loss: 0.01594495214521885 | MAE Test Loss: 0.03718598559498787 \n",
      "Epoch: 1246 | MAE Train Loss: 0.015910785645246506 | MAE Test Loss: 0.03714444115757942 \n",
      "Epoch: 1247 | MAE Train Loss: 0.015876421704888344 | MAE Test Loss: 0.03703425079584122 \n",
      "Epoch: 1248 | MAE Train Loss: 0.015841882675886154 | MAE Test Loss: 0.03699268028140068 \n",
      "Epoch: 1249 | MAE Train Loss: 0.015807893127202988 | MAE Test Loss: 0.036882489919662476 \n",
      "Epoch: 1250 | MAE Train Loss: 0.015772998332977295 | MAE Test Loss: 0.036772288382053375 \n",
      "Epoch: 1251 | MAE Train Loss: 0.015739355236291885 | MAE Test Loss: 0.03673075884580612 \n",
      "Epoch: 1252 | MAE Train Loss: 0.01570446975529194 | MAE Test Loss: 0.03662055730819702 \n",
      "Epoch: 1253 | MAE Train Loss: 0.015670450404286385 | MAE Test Loss: 0.03657899424433708 \n",
      "Epoch: 1254 | MAE Train Loss: 0.015635941177606583 | MAE Test Loss: 0.03646882623434067 \n",
      "Epoch: 1255 | MAE Train Loss: 0.015601545572280884 | MAE Test Loss: 0.03642727807164192 \n",
      "Epoch: 1256 | MAE Train Loss: 0.015567416325211525 | MAE Test Loss: 0.03631708025932312 \n",
      "Epoch: 1257 | MAE Train Loss: 0.015532639808952808 | MAE Test Loss: 0.03627553582191467 \n",
      "Epoch: 1258 | MAE Train Loss: 0.015498891472816467 | MAE Test Loss: 0.036165326833724976 \n",
      "Epoch: 1259 | MAE Train Loss: 0.015463987365365028 | MAE Test Loss: 0.036055129021406174 \n",
      "Epoch: 1260 | MAE Train Loss: 0.01543011236935854 | MAE Test Loss: 0.03601359575986862 \n",
      "Epoch: 1261 | MAE Train Loss: 0.01539546251296997 | MAE Test Loss: 0.035903383046388626 \n",
      "Epoch: 1262 | MAE Train Loss: 0.015361204743385315 | MAE Test Loss: 0.03586184233427048 \n",
      "Epoch: 1263 | MAE Train Loss: 0.015326937660574913 | MAE Test Loss: 0.035751648247241974 \n",
      "Epoch: 1264 | MAE Train Loss: 0.015292299911379814 | MAE Test Loss: 0.035710107535123825 \n",
      "Epoch: 1265 | MAE Train Loss: 0.015258421190083027 | MAE Test Loss: 0.03559989854693413 \n",
      "Epoch: 1266 | MAE Train Loss: 0.015223512426018715 | MAE Test Loss: 0.035489700734615326 \n",
      "Epoch: 1267 | MAE Train Loss: 0.015189772471785545 | MAE Test Loss: 0.03544817119836807 \n",
      "Epoch: 1268 | MAE Train Loss: 0.015154987573623657 | MAE Test Loss: 0.035337965935468674 \n",
      "Epoch: 1269 | MAE Train Loss: 0.01512086670845747 | MAE Test Loss: 0.03529641777276993 \n",
      "Epoch: 1270 | MAE Train Loss: 0.015086461789906025 | MAE Test Loss: 0.03518623113632202 \n",
      "Epoch: 1271 | MAE Train Loss: 0.015051963739097118 | MAE Test Loss: 0.035144656896591187 \n",
      "Epoch: 1272 | MAE Train Loss: 0.015017936937510967 | MAE Test Loss: 0.03503449633717537 \n",
      "Epoch: 1273 | MAE Train Loss: 0.014983056113123894 | MAE Test Loss: 0.03499293327331543 \n",
      "Epoch: 1274 | MAE Train Loss: 0.014949413016438484 | MAE Test Loss: 0.03488273546099663 \n",
      "Epoch: 1275 | MAE Train Loss: 0.01491450984030962 | MAE Test Loss: 0.03477254509925842 \n",
      "Epoch: 1276 | MAE Train Loss: 0.014880528673529625 | MAE Test Loss: 0.034731000661849976 \n",
      "Epoch: 1277 | MAE Train Loss: 0.014845984987914562 | MAE Test Loss: 0.034620802849531174 \n",
      "Epoch: 1278 | MAE Train Loss: 0.014811624772846699 | MAE Test Loss: 0.03457924723625183 \n",
      "Epoch: 1279 | MAE Train Loss: 0.014777451753616333 | MAE Test Loss: 0.034469056874513626 \n",
      "Epoch: 1280 | MAE Train Loss: 0.014742719009518623 | MAE Test Loss: 0.03442750498652458 \n",
      "Epoch: 1281 | MAE Train Loss: 0.014708934351801872 | MAE Test Loss: 0.03431730717420578 \n",
      "Epoch: 1282 | MAE Train Loss: 0.01467402745038271 | MAE Test Loss: 0.03420709818601608 \n",
      "Epoch: 1283 | MAE Train Loss: 0.014640195295214653 | MAE Test Loss: 0.03416557237505913 \n",
      "Epoch: 1284 | MAE Train Loss: 0.014605514705181122 | MAE Test Loss: 0.03405536338686943 \n",
      "Epoch: 1285 | MAE Train Loss: 0.014571284875273705 | MAE Test Loss: 0.03401382640004158 \n",
      "Epoch: 1286 | MAE Train Loss: 0.014536982402205467 | MAE Test Loss: 0.03390362858772278 \n",
      "Epoch: 1287 | MAE Train Loss: 0.014502379111945629 | MAE Test Loss: 0.033862076699733734 \n",
      "Epoch: 1288 | MAE Train Loss: 0.01446845568716526 | MAE Test Loss: 0.033751893788576126 \n",
      "Epoch: 1289 | MAE Train Loss: 0.01443355344235897 | MAE Test Loss: 0.03364170342683792 \n",
      "Epoch: 1290 | MAE Train Loss: 0.014399850741028786 | MAE Test Loss: 0.03360014408826828 \n",
      "Epoch: 1291 | MAE Train Loss: 0.014365026727318764 | MAE Test Loss: 0.03348997235298157 \n",
      "Epoch: 1292 | MAE Train Loss: 0.014330940321087837 | MAE Test Loss: 0.03344840556383133 \n",
      "Epoch: 1293 | MAE Train Loss: 0.01429650466889143 | MAE Test Loss: 0.03333820775151253 \n",
      "Epoch: 1294 | MAE Train Loss: 0.014262044802308083 | MAE Test Loss: 0.033296652138233185 \n",
      "Epoch: 1295 | MAE Train Loss: 0.014227977022528648 | MAE Test Loss: 0.03318646550178528 \n",
      "Epoch: 1296 | MAE Train Loss: 0.014193138107657433 | MAE Test Loss: 0.03314492106437683 \n",
      "Epoch: 1297 | MAE Train Loss: 0.014159453101456165 | MAE Test Loss: 0.03303471952676773 \n",
      "Epoch: 1298 | MAE Train Loss: 0.014124554581940174 | MAE Test Loss: 0.03292452543973923 \n",
      "Epoch: 1299 | MAE Train Loss: 0.014090606942772865 | MAE Test Loss: 0.032882969826459885 \n",
      "Epoch: 1300 | MAE Train Loss: 0.014056024141609669 | MAE Test Loss: 0.03277278691530228 \n",
      "Epoch: 1301 | MAE Train Loss: 0.014021704904735088 | MAE Test Loss: 0.03273124247789383 \n",
      "Epoch: 1302 | MAE Train Loss: 0.013987499289214611 | MAE Test Loss: 0.03262104466557503 \n",
      "Epoch: 1303 | MAE Train Loss: 0.013952797278761864 | MAE Test Loss: 0.03257947415113449 \n",
      "Epoch: 1304 | MAE Train Loss: 0.013918980956077576 | MAE Test Loss: 0.03246930241584778 \n",
      "Epoch: 1305 | MAE Train Loss: 0.013884072192013264 | MAE Test Loss: 0.032359104603528976 \n",
      "Epoch: 1306 | MAE Train Loss: 0.01385026890784502 | MAE Test Loss: 0.03231755644083023 \n",
      "Epoch: 1307 | MAE Train Loss: 0.013815549202263355 | MAE Test Loss: 0.03220735862851143 \n",
      "Epoch: 1308 | MAE Train Loss: 0.013781366869807243 | MAE Test Loss: 0.032165806740522385 \n",
      "Epoch: 1309 | MAE Train Loss: 0.013747021555900574 | MAE Test Loss: 0.03205562382936478 \n",
      "Epoch: 1310 | MAE Train Loss: 0.013712462969124317 | MAE Test Loss: 0.03201407939195633 \n",
      "Epoch: 1311 | MAE Train Loss: 0.013678496703505516 | MAE Test Loss: 0.03190387412905693 \n",
      "Epoch: 1312 | MAE Train Loss: 0.013643595390021801 | MAE Test Loss: 0.03179367259144783 \n",
      "Epoch: 1313 | MAE Train Loss: 0.013609932735562325 | MAE Test Loss: 0.03175212815403938 \n",
      "Epoch: 1314 | MAE Train Loss: 0.013575072400271893 | MAE Test Loss: 0.031641941517591476 \n",
      "Epoch: 1315 | MAE Train Loss: 0.013541030697524548 | MAE Test Loss: 0.03160039335489273 \n",
      "Epoch: 1316 | MAE Train Loss: 0.01350654661655426 | MAE Test Loss: 0.03149018436670303 \n",
      "Epoch: 1317 | MAE Train Loss: 0.013472122140228748 | MAE Test Loss: 0.03144865483045578 \n",
      "Epoch: 1318 | MAE Train Loss: 0.013438018038868904 | MAE Test Loss: 0.03133844584226608 \n",
      "Epoch: 1319 | MAE Train Loss: 0.013403216376900673 | MAE Test Loss: 0.031296901404857635 \n",
      "Epoch: 1320 | MAE Train Loss: 0.013369491323828697 | MAE Test Loss: 0.031186699867248535 \n",
      "Epoch: 1321 | MAE Train Loss: 0.013334590010344982 | MAE Test Loss: 0.031076502054929733 \n",
      "Epoch: 1322 | MAE Train Loss: 0.013300687074661255 | MAE Test Loss: 0.03103495202958584 \n",
      "Epoch: 1323 | MAE Train Loss: 0.0132660623639822 | MAE Test Loss: 0.030924778431653976 \n",
      "Epoch: 1324 | MAE Train Loss: 0.013231784105300903 | MAE Test Loss: 0.030883217230439186 \n",
      "Epoch: 1325 | MAE Train Loss: 0.013197538442909718 | MAE Test Loss: 0.030773013830184937 \n",
      "Epoch: 1326 | MAE Train Loss: 0.013162882998585701 | MAE Test Loss: 0.030731480568647385 \n",
      "Epoch: 1327 | MAE Train Loss: 0.01312901359051466 | MAE Test Loss: 0.030621284618973732 \n",
      "Epoch: 1328 | MAE Train Loss: 0.013094114139676094 | MAE Test Loss: 0.030511099845170975 \n",
      "Epoch: 1329 | MAE Train Loss: 0.013060351833701134 | MAE Test Loss: 0.03046952560544014 \n",
      "Epoch: 1330 | MAE Train Loss: 0.01302559394389391 | MAE Test Loss: 0.030359338968992233 \n",
      "Epoch: 1331 | MAE Train Loss: 0.012991437688469887 | MAE Test Loss: 0.03031778894364834 \n",
      "Epoch: 1332 | MAE Train Loss: 0.012957069091498852 | MAE Test Loss: 0.03020760416984558 \n",
      "Epoch: 1333 | MAE Train Loss: 0.012922537513077259 | MAE Test Loss: 0.03016604855656624 \n",
      "Epoch: 1334 | MAE Train Loss: 0.012888537719845772 | MAE Test Loss: 0.03005584515631199 \n",
      "Epoch: 1335 | MAE Train Loss: 0.01285363920032978 | MAE Test Loss: 0.02994566038250923 \n",
      "Epoch: 1336 | MAE Train Loss: 0.012820012867450714 | MAE Test Loss: 0.029904121533036232 \n",
      "Epoch: 1337 | MAE Train Loss: 0.012785108759999275 | MAE Test Loss: 0.029793912544846535 \n",
      "Epoch: 1338 | MAE Train Loss: 0.012751109898090363 | MAE Test Loss: 0.029752373695373535 \n",
      "Epoch: 1339 | MAE Train Loss: 0.012716586701571941 | MAE Test Loss: 0.029642170295119286 \n",
      "Epoch: 1340 | MAE Train Loss: 0.012682202272117138 | MAE Test Loss: 0.029600614681839943 \n",
      "Epoch: 1341 | MAE Train Loss: 0.012648063711822033 | MAE Test Loss: 0.02949044108390808 \n",
      "Epoch: 1342 | MAE Train Loss: 0.012613298371434212 | MAE Test Loss: 0.02944887802004814 \n",
      "Epoch: 1343 | MAE Train Loss: 0.012579533271491528 | MAE Test Loss: 0.029338687658309937 \n",
      "Epoch: 1344 | MAE Train Loss: 0.01254463754594326 | MAE Test Loss: 0.029228484258055687 \n",
      "Epoch: 1345 | MAE Train Loss: 0.012510770931839943 | MAE Test Loss: 0.029186945408582687 \n",
      "Epoch: 1346 | MAE Train Loss: 0.01247610803693533 | MAE Test Loss: 0.029076749458909035 \n",
      "Epoch: 1347 | MAE Train Loss: 0.012441864237189293 | MAE Test Loss: 0.02903519943356514 \n",
      "Epoch: 1348 | MAE Train Loss: 0.012407584115862846 | MAE Test Loss: 0.028925007209181786 \n",
      "Epoch: 1349 | MAE Train Loss: 0.012372957542538643 | MAE Test Loss: 0.028883475810289383 \n",
      "Epoch: 1350 | MAE Train Loss: 0.012339059263467789 | MAE Test Loss: 0.028773266822099686 \n",
      "Epoch: 1351 | MAE Train Loss: 0.012304151430726051 | MAE Test Loss: 0.028663069009780884 \n",
      "Epoch: 1352 | MAE Train Loss: 0.012270430102944374 | MAE Test Loss: 0.028621505945920944 \n",
      "Epoch: 1353 | MAE Train Loss: 0.012235632166266441 | MAE Test Loss: 0.028511321172118187 \n",
      "Epoch: 1354 | MAE Train Loss: 0.012201527133584023 | MAE Test Loss: 0.028469771146774292 \n",
      "Epoch: 1355 | MAE Train Loss: 0.012167108245193958 | MAE Test Loss: 0.02835957333445549 \n",
      "Epoch: 1356 | MAE Train Loss: 0.012132621370255947 | MAE Test Loss: 0.02831803634762764 \n",
      "Epoch: 1357 | MAE Train Loss: 0.012098582461476326 | MAE Test Loss: 0.028207844123244286 \n",
      "Epoch: 1358 | MAE Train Loss: 0.012063717469573021 | MAE Test Loss: 0.028166288509964943 \n",
      "Epoch: 1359 | MAE Train Loss: 0.012030057609081268 | MAE Test Loss: 0.028056055307388306 \n",
      "Epoch: 1360 | MAE Train Loss: 0.011995160952210426 | MAE Test Loss: 0.02794589474797249 \n",
      "Epoch: 1361 | MAE Train Loss: 0.011961189098656178 | MAE Test Loss: 0.02790435031056404 \n",
      "Epoch: 1362 | MAE Train Loss: 0.011926629580557346 | MAE Test Loss: 0.027794158086180687 \n",
      "Epoch: 1363 | MAE Train Loss: 0.011892282404005527 | MAE Test Loss: 0.027752583846449852 \n",
      "Epoch: 1364 | MAE Train Loss: 0.011858103796839714 | MAE Test Loss: 0.027642399072647095 \n",
      "Epoch: 1365 | MAE Train Loss: 0.01182338036596775 | MAE Test Loss: 0.027600860223174095 \n",
      "Epoch: 1366 | MAE Train Loss: 0.011789577081799507 | MAE Test Loss: 0.02749066986143589 \n",
      "Epoch: 1367 | MAE Train Loss: 0.011754677630960941 | MAE Test Loss: 0.02738046646118164 \n",
      "Epoch: 1368 | MAE Train Loss: 0.011720849201083183 | MAE Test Loss: 0.0273389033973217 \n",
      "Epoch: 1369 | MAE Train Loss: 0.011686149053275585 | MAE Test Loss: 0.027228742837905884 \n",
      "Epoch: 1370 | MAE Train Loss: 0.011651946231722832 | MAE Test Loss: 0.02718718722462654 \n",
      "Epoch: 1371 | MAE Train Loss: 0.011617625132203102 | MAE Test Loss: 0.02707698382437229 \n",
      "Epoch: 1372 | MAE Train Loss: 0.011583036743104458 | MAE Test Loss: 0.027035444974899292 \n",
      "Epoch: 1373 | MAE Train Loss: 0.011549100279808044 | MAE Test Loss: 0.026925235986709595 \n",
      "Epoch: 1374 | MAE Train Loss: 0.011514198035001755 | MAE Test Loss: 0.026815038174390793 \n",
      "Epoch: 1375 | MAE Train Loss: 0.011480512097477913 | MAE Test Loss: 0.026773501187562943 \n",
      "Epoch: 1376 | MAE Train Loss: 0.011445674113929272 | MAE Test Loss: 0.026663292199373245 \n",
      "Epoch: 1377 | MAE Train Loss: 0.011411604471504688 | MAE Test Loss: 0.026621753349900246 \n",
      "Epoch: 1378 | MAE Train Loss: 0.01137714646756649 | MAE Test Loss: 0.026511555537581444 \n",
      "Epoch: 1379 | MAE Train Loss: 0.011342699639499187 | MAE Test Loss: 0.026470016688108444 \n",
      "Epoch: 1380 | MAE Train Loss: 0.011308628134429455 | MAE Test Loss: 0.026359815150499344 \n",
      "Epoch: 1381 | MAE Train Loss: 0.011273792013525963 | MAE Test Loss: 0.026318270713090897 \n",
      "Epoch: 1382 | MAE Train Loss: 0.01124009769409895 | MAE Test Loss: 0.026208072900772095 \n",
      "Epoch: 1383 | MAE Train Loss: 0.01120519544929266 | MAE Test Loss: 0.026097875088453293 \n",
      "Epoch: 1384 | MAE Train Loss: 0.011171268299221992 | MAE Test Loss: 0.026056325063109398 \n",
      "Epoch: 1385 | MAE Train Loss: 0.011136669665575027 | MAE Test Loss: 0.02594614028930664 \n",
      "Epoch: 1386 | MAE Train Loss: 0.011102361604571342 | MAE Test Loss: 0.025904566049575806 \n",
      "Epoch: 1387 | MAE Train Loss: 0.011068146675825119 | MAE Test Loss: 0.02579440549015999 \n",
      "Epoch: 1388 | MAE Train Loss: 0.011033458635210991 | MAE Test Loss: 0.02575284242630005 \n",
      "Epoch: 1389 | MAE Train Loss: 0.010999620892107487 | MAE Test Loss: 0.025642644613981247 \n",
      "Epoch: 1390 | MAE Train Loss: 0.010964717715978622 | MAE Test Loss: 0.025532448664307594 \n",
      "Epoch: 1391 | MAE Train Loss: 0.010930929332971573 | MAE Test Loss: 0.025490909814834595 \n",
      "Epoch: 1392 | MAE Train Loss: 0.01089619193226099 | MAE Test Loss: 0.025380712002515793 \n",
      "Epoch: 1393 | MAE Train Loss: 0.010862023569643497 | MAE Test Loss: 0.02533915638923645 \n",
      "Epoch: 1394 | MAE Train Loss: 0.01082766242325306 | MAE Test Loss: 0.025228966027498245 \n",
      "Epoch: 1395 | MAE Train Loss: 0.010793117806315422 | MAE Test Loss: 0.0251874141395092 \n",
      "Epoch: 1396 | MAE Train Loss: 0.01075914315879345 | MAE Test Loss: 0.02507721818983555 \n",
      "Epoch: 1397 | MAE Train Loss: 0.010724237188696861 | MAE Test Loss: 0.02496700920164585 \n",
      "Epoch: 1398 | MAE Train Loss: 0.010690595954656601 | MAE Test Loss: 0.024925481528043747 \n",
      "Epoch: 1399 | MAE Train Loss: 0.010655724443495274 | MAE Test Loss: 0.02481527253985405 \n",
      "Epoch: 1400 | MAE Train Loss: 0.010621682740747929 | MAE Test Loss: 0.0247737355530262 \n",
      "Epoch: 1401 | MAE Train Loss: 0.010587191209197044 | MAE Test Loss: 0.024663537740707397 \n",
      "Epoch: 1402 | MAE Train Loss: 0.010552778840065002 | MAE Test Loss: 0.024621987715363503 \n",
      "Epoch: 1403 | MAE Train Loss: 0.010518664494156837 | MAE Test Loss: 0.024511802941560745 \n",
      "Epoch: 1404 | MAE Train Loss: 0.010483875870704651 | MAE Test Loss: 0.0244702510535717 \n",
      "Epoch: 1405 | MAE Train Loss: 0.010450141504406929 | MAE Test Loss: 0.02436005510389805 \n",
      "Epoch: 1406 | MAE Train Loss: 0.010415233671665192 | MAE Test Loss: 0.024249881505966187 \n",
      "Epoch: 1407 | MAE Train Loss: 0.01038134004920721 | MAE Test Loss: 0.0242083128541708 \n",
      "Epoch: 1408 | MAE Train Loss: 0.010346716269850731 | MAE Test Loss: 0.024098116904497147 \n",
      "Epoch: 1409 | MAE Train Loss: 0.010312443599104881 | MAE Test Loss: 0.024056559428572655 \n",
      "Epoch: 1410 | MAE Train Loss: 0.010278185829520226 | MAE Test Loss: 0.023946374654769897 \n",
      "Epoch: 1411 | MAE Train Loss: 0.01024353876709938 | MAE Test Loss: 0.023904824629426003 \n",
      "Epoch: 1412 | MAE Train Loss: 0.010209662839770317 | MAE Test Loss: 0.0237946268171072 \n",
      "Epoch: 1413 | MAE Train Loss: 0.010174764320254326 | MAE Test Loss: 0.023684436455368996 \n",
      "Epoch: 1414 | MAE Train Loss: 0.010141006670892239 | MAE Test Loss: 0.023642878979444504 \n",
      "Epoch: 1415 | MAE Train Loss: 0.010106234811246395 | MAE Test Loss: 0.023532694205641747 \n",
      "Epoch: 1416 | MAE Train Loss: 0.010072106495499611 | MAE Test Loss: 0.0234911497682333 \n",
      "Epoch: 1417 | MAE Train Loss: 0.010037708096206188 | MAE Test Loss: 0.023380953818559647 \n",
      "Epoch: 1418 | MAE Train Loss: 0.010003196075558662 | MAE Test Loss: 0.02333938516676426 \n",
      "Epoch: 1419 | MAE Train Loss: 0.009969188831746578 | MAE Test Loss: 0.023229211568832397 \n",
      "Epoch: 1420 | MAE Train Loss: 0.009934291243553162 | MAE Test Loss: 0.023187648504972458 \n",
      "Epoch: 1421 | MAE Train Loss: 0.009900657460093498 | MAE Test Loss: 0.0230774637311697 \n",
      "Epoch: 1422 | MAE Train Loss: 0.00986576173454523 | MAE Test Loss: 0.022967267781496048 \n",
      "Epoch: 1423 | MAE Train Loss: 0.009831766597926617 | MAE Test Loss: 0.022925715893507004 \n",
      "Epoch: 1424 | MAE Train Loss: 0.009797231294214725 | MAE Test Loss: 0.02281551994383335 \n",
      "Epoch: 1425 | MAE Train Loss: 0.009762861765921116 | MAE Test Loss: 0.0227739866822958 \n",
      "Epoch: 1426 | MAE Train Loss: 0.009728707373142242 | MAE Test Loss: 0.02266378328204155 \n",
      "Epoch: 1427 | MAE Train Loss: 0.009693953208625317 | MAE Test Loss: 0.022622257471084595 \n",
      "Epoch: 1428 | MAE Train Loss: 0.009660175070166588 | MAE Test Loss: 0.022512037307024002 \n",
      "Epoch: 1429 | MAE Train Loss: 0.00962528120726347 | MAE Test Loss: 0.022401850670576096 \n",
      "Epoch: 1430 | MAE Train Loss: 0.009591431356966496 | MAE Test Loss: 0.0223603006452322 \n",
      "Epoch: 1431 | MAE Train Loss: 0.009556754492223263 | MAE Test Loss: 0.022250091657042503 \n",
      "Epoch: 1432 | MAE Train Loss: 0.009522520937025547 | MAE Test Loss: 0.02220856584608555 \n",
      "Epoch: 1433 | MAE Train Loss: 0.009488226845860481 | MAE Test Loss: 0.02209835685789585 \n",
      "Epoch: 1434 | MAE Train Loss: 0.009453615173697472 | MAE Test Loss: 0.022056812420487404 \n",
      "Epoch: 1435 | MAE Train Loss: 0.009419701062142849 | MAE Test Loss: 0.021946609020233154 \n",
      "Epoch: 1436 | MAE Train Loss: 0.009384801611304283 | MAE Test Loss: 0.021836411207914352 \n",
      "Epoch: 1437 | MAE Train Loss: 0.009351085871458054 | MAE Test Loss: 0.021794861182570457 \n",
      "Epoch: 1438 | MAE Train Loss: 0.009316272102296352 | MAE Test Loss: 0.021684687584638596 \n",
      "Epoch: 1439 | MAE Train Loss: 0.009282185696065426 | MAE Test Loss: 0.021643126383423805 \n",
      "Epoch: 1440 | MAE Train Loss: 0.00924774818122387 | MAE Test Loss: 0.021532922983169556 \n",
      "Epoch: 1441 | MAE Train Loss: 0.0092132817953825 | MAE Test Loss: 0.021491389721632004 \n",
      "Epoch: 1442 | MAE Train Loss: 0.009179223328828812 | MAE Test Loss: 0.02138119377195835 \n",
      "Epoch: 1443 | MAE Train Loss: 0.009144370444118977 | MAE Test Loss: 0.021339643746614456 \n",
      "Epoch: 1444 | MAE Train Loss: 0.009110702201724052 | MAE Test Loss: 0.02122943475842476 \n",
      "Epoch: 1445 | MAE Train Loss: 0.009075800888240337 | MAE Test Loss: 0.021119248121976852 \n",
      "Epoch: 1446 | MAE Train Loss: 0.00904183741658926 | MAE Test Loss: 0.021077698096632957 \n",
      "Epoch: 1447 | MAE Train Loss: 0.009007277898490429 | MAE Test Loss: 0.0209675133228302 \n",
      "Epoch: 1448 | MAE Train Loss: 0.008972937241196632 | MAE Test Loss: 0.020925957709550858 \n",
      "Epoch: 1449 | MAE Train Loss: 0.008938746526837349 | MAE Test Loss: 0.020815754309296608 \n",
      "Epoch: 1450 | MAE Train Loss: 0.008904037065804005 | MAE Test Loss: 0.020774226635694504 \n",
      "Epoch: 1451 | MAE Train Loss: 0.008870227262377739 | MAE Test Loss: 0.02066403068602085 \n",
      "Epoch: 1452 | MAE Train Loss: 0.008835317566990852 | MAE Test Loss: 0.020553821697831154 \n",
      "Epoch: 1453 | MAE Train Loss: 0.008801509626209736 | MAE Test Loss: 0.020512282848358154 \n",
      "Epoch: 1454 | MAE Train Loss: 0.008766795508563519 | MAE Test Loss: 0.020402079448103905 \n",
      "Epoch: 1455 | MAE Train Loss: 0.008732601068913937 | MAE Test Loss: 0.020360523834824562 \n",
      "Epoch: 1456 | MAE Train Loss: 0.008698273450136185 | MAE Test Loss: 0.0202503502368927 \n",
      "Epoch: 1457 | MAE Train Loss: 0.00866369716823101 | MAE Test Loss: 0.02020878717303276 \n",
      "Epoch: 1458 | MAE Train Loss: 0.00862974114716053 | MAE Test Loss: 0.020098591223359108 \n",
      "Epoch: 1459 | MAE Train Loss: 0.008594844490289688 | MAE Test Loss: 0.019988393411040306 \n",
      "Epoch: 1460 | MAE Train Loss: 0.008561169728636742 | MAE Test Loss: 0.019946854561567307 \n",
      "Epoch: 1461 | MAE Train Loss: 0.008526316843926907 | MAE Test Loss: 0.019836658611893654 \n",
      "Epoch: 1462 | MAE Train Loss: 0.008492263033986092 | MAE Test Loss: 0.01979510858654976 \n",
      "Epoch: 1463 | MAE Train Loss: 0.008457791991531849 | MAE Test Loss: 0.019684916362166405 \n",
      "Epoch: 1464 | MAE Train Loss: 0.00842335820198059 | MAE Test Loss: 0.019643384963274002 \n",
      "Epoch: 1465 | MAE Train Loss: 0.00838927086442709 | MAE Test Loss: 0.019533175975084305 \n",
      "Epoch: 1466 | MAE Train Loss: 0.008354445919394493 | MAE Test Loss: 0.01949162408709526 \n",
      "Epoch: 1467 | MAE Train Loss: 0.008320735767483711 | MAE Test Loss: 0.019381415098905563 \n",
      "Epoch: 1468 | MAE Train Loss: 0.008285840973258018 | MAE Test Loss: 0.019271230325102806 \n",
      "Epoch: 1469 | MAE Train Loss: 0.008251926861703396 | MAE Test Loss: 0.01922968029975891 \n",
      "Epoch: 1470 | MAE Train Loss: 0.008217317052185535 | MAE Test Loss: 0.01911948248744011 \n",
      "Epoch: 1471 | MAE Train Loss: 0.00818302109837532 | MAE Test Loss: 0.01907794550061226 \n",
      "Epoch: 1472 | MAE Train Loss: 0.008148789405822754 | MAE Test Loss: 0.018967753276228905 \n",
      "Epoch: 1473 | MAE Train Loss: 0.00811411626636982 | MAE Test Loss: 0.018926197662949562 \n",
      "Epoch: 1474 | MAE Train Loss: 0.008080266416072845 | MAE Test Loss: 0.018815964460372925 \n",
      "Epoch: 1475 | MAE Train Loss: 0.008045373484492302 | MAE Test Loss: 0.018705803900957108 \n",
      "Epoch: 1476 | MAE Train Loss: 0.008011586964130402 | MAE Test Loss: 0.01866425946354866 \n",
      "Epoch: 1477 | MAE Train Loss: 0.007976839318871498 | MAE Test Loss: 0.018554067239165306 \n",
      "Epoch: 1478 | MAE Train Loss: 0.007942684926092625 | MAE Test Loss: 0.01851249299943447 \n",
      "Epoch: 1479 | MAE Train Loss: 0.007908310741186142 | MAE Test Loss: 0.018402308225631714 \n",
      "Epoch: 1480 | MAE Train Loss: 0.007873778231441975 | MAE Test Loss: 0.018360769376158714 \n",
      "Epoch: 1481 | MAE Train Loss: 0.007839785888791084 | MAE Test Loss: 0.01825057901442051 \n",
      "Epoch: 1482 | MAE Train Loss: 0.0078048864379525185 | MAE Test Loss: 0.01814037561416626 \n",
      "Epoch: 1483 | MAE Train Loss: 0.007771248463541269 | MAE Test Loss: 0.01809881255030632 \n",
      "Epoch: 1484 | MAE Train Loss: 0.007736357860267162 | MAE Test Loss: 0.017988651990890503 \n",
      "Epoch: 1485 | MAE Train Loss: 0.00770234689116478 | MAE Test Loss: 0.01794709637761116 \n",
      "Epoch: 1486 | MAE Train Loss: 0.007667834404855967 | MAE Test Loss: 0.01783689297735691 \n",
      "Epoch: 1487 | MAE Train Loss: 0.007633437868207693 | MAE Test Loss: 0.01779535412788391 \n",
      "Epoch: 1488 | MAE Train Loss: 0.007599309086799622 | MAE Test Loss: 0.017685145139694214 \n",
      "Epoch: 1489 | MAE Train Loss: 0.007564532104879618 | MAE Test Loss: 0.017643606290221214 \n",
      "Epoch: 1490 | MAE Train Loss: 0.0075307851657271385 | MAE Test Loss: 0.01753341034054756 \n",
      "Epoch: 1491 | MAE Train Loss: 0.007495882920920849 | MAE Test Loss: 0.017423201352357864 \n",
      "Epoch: 1492 | MAE Train Loss: 0.007462003733962774 | MAE Test Loss: 0.017381662502884865 \n",
      "Epoch: 1493 | MAE Train Loss: 0.00742735480889678 | MAE Test Loss: 0.017271464690566063 \n",
      "Epoch: 1494 | MAE Train Loss: 0.007393099367618561 | MAE Test Loss: 0.017229925841093063 \n",
      "Epoch: 1495 | MAE Train Loss: 0.00735883554443717 | MAE Test Loss: 0.017119724303483963 \n",
      "Epoch: 1496 | MAE Train Loss: 0.007324191741645336 | MAE Test Loss: 0.017078179866075516 \n",
      "Epoch: 1497 | MAE Train Loss: 0.007290305104106665 | MAE Test Loss: 0.016967982053756714 \n",
      "Epoch: 1498 | MAE Train Loss: 0.007255404256284237 | MAE Test Loss: 0.016857784241437912 \n",
      "Epoch: 1499 | MAE Train Loss: 0.0072216675616800785 | MAE Test Loss: 0.016816234216094017 \n",
      "Epoch: 1500 | MAE Train Loss: 0.007186878472566605 | MAE Test Loss: 0.01670604944229126 \n",
      "Epoch: 1501 | MAE Train Loss: 0.007152761332690716 | MAE Test Loss: 0.016664475202560425 \n",
      "Epoch: 1502 | MAE Train Loss: 0.007118356879800558 | MAE Test Loss: 0.016554314643144608 \n",
      "Epoch: 1503 | MAE Train Loss: 0.007083857897669077 | MAE Test Loss: 0.016512751579284668 \n",
      "Epoch: 1504 | MAE Train Loss: 0.007049829699099064 | MAE Test Loss: 0.016402553766965866 \n",
      "Epoch: 1505 | MAE Train Loss: 0.00701494887471199 | MAE Test Loss: 0.01636102795600891 \n",
      "Epoch: 1506 | MAE Train Loss: 0.006981306709349155 | MAE Test Loss: 0.016250818967819214 \n",
      "Epoch: 1507 | MAE Train Loss: 0.006946398876607418 | MAE Test Loss: 0.016140621155500412 \n",
      "Epoch: 1508 | MAE Train Loss: 0.0069124214351177216 | MAE Test Loss: 0.01609906554222107 \n",
      "Epoch: 1509 | MAE Train Loss: 0.006877870764583349 | MAE Test Loss: 0.015988875180482864 \n",
      "Epoch: 1510 | MAE Train Loss: 0.006843519397079945 | MAE Test Loss: 0.01594732329249382 \n",
      "Epoch: 1511 | MAE Train Loss: 0.006809352431446314 | MAE Test Loss: 0.015837127342820168 \n",
      "Epoch: 1512 | MAE Train Loss: 0.00677460664883256 | MAE Test Loss: 0.015795577317476273 \n",
      "Epoch: 1513 | MAE Train Loss: 0.00674082338809967 | MAE Test Loss: 0.015685390681028366 \n",
      "Epoch: 1514 | MAE Train Loss: 0.006705933716148138 | MAE Test Loss: 0.015575182624161243 \n",
      "Epoch: 1515 | MAE Train Loss: 0.006672080606222153 | MAE Test Loss: 0.015533643774688244 \n",
      "Epoch: 1516 | MAE Train Loss: 0.006637400947511196 | MAE Test Loss: 0.015423446893692017 \n",
      "Epoch: 1517 | MAE Train Loss: 0.006603178568184376 | MAE Test Loss: 0.015381896868348122 \n",
      "Epoch: 1518 | MAE Train Loss: 0.006568872835487127 | MAE Test Loss: 0.01527171116322279 \n",
      "Epoch: 1519 | MAE Train Loss: 0.006534276995807886 | MAE Test Loss: 0.015230161137878895 \n",
      "Epoch: 1520 | MAE Train Loss: 0.006500349845737219 | MAE Test Loss: 0.015119964256882668 \n",
      "Epoch: 1521 | MAE Train Loss: 0.006465443875640631 | MAE Test Loss: 0.015009790658950806 \n",
      "Epoch: 1522 | MAE Train Loss: 0.006431739777326584 | MAE Test Loss: 0.014968222007155418 \n",
      "Epoch: 1523 | MAE Train Loss: 0.006396924611181021 | MAE Test Loss: 0.014858025126159191 \n",
      "Epoch: 1524 | MAE Train Loss: 0.006362842861562967 | MAE Test Loss: 0.014816468581557274 \n",
      "Epoch: 1525 | MAE Train Loss: 0.00632839510217309 | MAE Test Loss: 0.014706283807754517 \n",
      "Epoch: 1526 | MAE Train Loss: 0.006293938495218754 | MAE Test Loss: 0.014664733782410622 \n",
      "Epoch: 1527 | MAE Train Loss: 0.006259871181100607 | MAE Test Loss: 0.01455453597009182 \n",
      "Epoch: 1528 | MAE Train Loss: 0.006225032266229391 | MAE Test Loss: 0.014512998051941395 \n",
      "Epoch: 1529 | MAE Train Loss: 0.0061913421377539635 | MAE Test Loss: 0.014402789063751698 \n",
      "Epoch: 1530 | MAE Train Loss: 0.006156443618237972 | MAE Test Loss: 0.014292603358626366 \n",
      "Epoch: 1531 | MAE Train Loss: 0.006122505757957697 | MAE Test Loss: 0.014251058921217918 \n",
      "Epoch: 1532 | MAE Train Loss: 0.006087916903197765 | MAE Test Loss: 0.014140862040221691 \n",
      "Epoch: 1533 | MAE Train Loss: 0.006053595803678036 | MAE Test Loss: 0.014099294319748878 \n",
      "Epoch: 1534 | MAE Train Loss: 0.006019397638738155 | MAE Test Loss: 0.013989120721817017 \n",
      "Epoch: 1535 | MAE Train Loss: 0.005984690971672535 | MAE Test Loss: 0.013947558589279652 \n",
      "Epoch: 1536 | MAE Train Loss: 0.005950864404439926 | MAE Test Loss: 0.01383737288415432 \n",
      "Epoch: 1537 | MAE Train Loss: 0.005915970541536808 | MAE Test Loss: 0.013727176003158092 \n",
      "Epoch: 1538 | MAE Train Loss: 0.00588216632604599 | MAE Test Loss: 0.013685625977814198 \n",
      "Epoch: 1539 | MAE Train Loss: 0.005847440101206303 | MAE Test Loss: 0.01357542909681797 \n",
      "Epoch: 1540 | MAE Train Loss: 0.005813261028379202 | MAE Test Loss: 0.013533895835280418 \n",
      "Epoch: 1541 | MAE Train Loss: 0.00577891618013382 | MAE Test Loss: 0.013423693366348743 \n",
      "Epoch: 1542 | MAE Train Loss: 0.00574435293674469 | MAE Test Loss: 0.013382166624069214 \n",
      "Epoch: 1543 | MAE Train Loss: 0.005710383411496878 | MAE Test Loss: 0.013271945528686047 \n",
      "Epoch: 1544 | MAE Train Loss: 0.005675490014255047 | MAE Test Loss: 0.01316176075488329 \n",
      "Epoch: 1545 | MAE Train Loss: 0.0056418320164084435 | MAE Test Loss: 0.01312020979821682 \n",
      "Epoch: 1546 | MAE Train Loss: 0.005606961902230978 | MAE Test Loss: 0.013010000810027122 \n",
      "Epoch: 1547 | MAE Train Loss: 0.005572921130806208 | MAE Test Loss: 0.012968474999070168 \n",
      "Epoch: 1548 | MAE Train Loss: 0.005538438446819782 | MAE Test Loss: 0.01285826601088047 \n",
      "Epoch: 1549 | MAE Train Loss: 0.005504013504832983 | MAE Test Loss: 0.012816721573472023 \n",
      "Epoch: 1550 | MAE Train Loss: 0.005469909869134426 | MAE Test Loss: 0.012706518173217773 \n",
      "Epoch: 1551 | MAE Train Loss: 0.005435112863779068 | MAE Test Loss: 0.012664979323744774 \n",
      "Epoch: 1552 | MAE Train Loss: 0.005401390604674816 | MAE Test Loss: 0.012554770335555077 \n",
      "Epoch: 1553 | MAE Train Loss: 0.0053664809092879295 | MAE Test Loss: 0.01244459766894579 \n",
      "Epoch: 1554 | MAE Train Loss: 0.005332584492862225 | MAE Test Loss: 0.012403035536408424 \n",
      "Epoch: 1555 | MAE Train Loss: 0.005297956522554159 | MAE Test Loss: 0.012292832136154175 \n",
      "Epoch: 1556 | MAE Train Loss: 0.005263681057840586 | MAE Test Loss: 0.012251299805939198 \n",
      "Epoch: 1557 | MAE Train Loss: 0.005229432135820389 | MAE Test Loss: 0.01214110292494297 \n",
      "Epoch: 1558 | MAE Train Loss: 0.005194769706577063 | MAE Test Loss: 0.0120995519682765 \n",
      "Epoch: 1559 | MAE Train Loss: 0.005160911474376917 | MAE Test Loss: 0.011989342980086803 \n",
      "Epoch: 1560 | MAE Train Loss: 0.0051260096952319145 | MAE Test Loss: 0.011879158206284046 \n",
      "Epoch: 1561 | MAE Train Loss: 0.005092238541692495 | MAE Test Loss: 0.011837607249617577 \n",
      "Epoch: 1562 | MAE Train Loss: 0.005057486705482006 | MAE Test Loss: 0.01172742247581482 \n",
      "Epoch: 1563 | MAE Train Loss: 0.00502333790063858 | MAE Test Loss: 0.011685865931212902 \n",
      "Epoch: 1564 | MAE Train Loss: 0.004988954868167639 | MAE Test Loss: 0.011575663462281227 \n",
      "Epoch: 1565 | MAE Train Loss: 0.004954436328262091 | MAE Test Loss: 0.011534136720001698 \n",
      "Epoch: 1566 | MAE Train Loss: 0.004920437000691891 | MAE Test Loss: 0.01142393983900547 \n",
      "Epoch: 1567 | MAE Train Loss: 0.004885525908321142 | MAE Test Loss: 0.011348068714141846 \n",
      "Epoch: 1568 | MAE Train Loss: 0.004851267673075199 | MAE Test Loss: 0.011237871833145618 \n",
      "Epoch: 1569 | MAE Train Loss: 0.004817450884729624 | MAE Test Loss: 0.011196320876479149 \n",
      "Epoch: 1570 | MAE Train Loss: 0.004782737232744694 | MAE Test Loss: 0.011086148209869862 \n",
      "Epoch: 1571 | MAE Train Loss: 0.0047485483810305595 | MAE Test Loss: 0.011044586077332497 \n",
      "Epoch: 1572 | MAE Train Loss: 0.004714212380349636 | MAE Test Loss: 0.010934382677078247 \n",
      "Epoch: 1573 | MAE Train Loss: 0.004679643549025059 | MAE Test Loss: 0.01089285034686327 \n",
      "Epoch: 1574 | MAE Train Loss: 0.004645687993615866 | MAE Test Loss: 0.010782653465867043 \n",
      "Epoch: 1575 | MAE Train Loss: 0.004610785748809576 | MAE Test Loss: 0.01067246776074171 \n",
      "Epoch: 1576 | MAE Train Loss: 0.004577117506414652 | MAE Test Loss: 0.010630893521010876 \n",
      "Epoch: 1577 | MAE Train Loss: 0.004542266018688679 | MAE Test Loss: 0.010520708747208118 \n",
      "Epoch: 1578 | MAE Train Loss: 0.00450820242986083 | MAE Test Loss: 0.010479157790541649 \n",
      "Epoch: 1579 | MAE Train Loss: 0.00447374302893877 | MAE Test Loss: 0.010368973016738892 \n",
      "Epoch: 1580 | MAE Train Loss: 0.004439301788806915 | MAE Test Loss: 0.010327416472136974 \n",
      "Epoch: 1581 | MAE Train Loss: 0.004405210725963116 | MAE Test Loss: 0.0102172140032053 \n",
      "Epoch: 1582 | MAE Train Loss: 0.004370400216430426 | MAE Test Loss: 0.01017568726092577 \n",
      "Epoch: 1583 | MAE Train Loss: 0.004336693324148655 | MAE Test Loss: 0.010065490379929543 \n",
      "Epoch: 1584 | MAE Train Loss: 0.004301781766116619 | MAE Test Loss: 0.009955281391739845 \n",
      "Epoch: 1585 | MAE Train Loss: 0.0042678723111748695 | MAE Test Loss: 0.009913742542266846 \n",
      "Epoch: 1586 | MAE Train Loss: 0.00423326063901186 | MAE Test Loss: 0.009803539142012596 \n",
      "Epoch: 1587 | MAE Train Loss: 0.00419896375387907 | MAE Test Loss: 0.009761983528733253 \n",
      "Epoch: 1588 | MAE Train Loss: 0.004164738114923239 | MAE Test Loss: 0.009651809930801392 \n",
      "Epoch: 1589 | MAE Train Loss: 0.004130060784518719 | MAE Test Loss: 0.009610247798264027 \n",
      "Epoch: 1590 | MAE Train Loss: 0.004096207674592733 | MAE Test Loss: 0.0095000509172678 \n",
      "Epoch: 1591 | MAE Train Loss: 0.004061309155076742 | MAE Test Loss: 0.009389853104948997 \n",
      "Epoch: 1592 | MAE Train Loss: 0.00402753334492445 | MAE Test Loss: 0.009348315186798573 \n",
      "Epoch: 1593 | MAE Train Loss: 0.00399278337135911 | MAE Test Loss: 0.009238118305802345 \n",
      "Epoch: 1594 | MAE Train Loss: 0.0039586266502738 | MAE Test Loss: 0.009196567349135876 \n",
      "Epoch: 1595 | MAE Train Loss: 0.003924256656318903 | MAE Test Loss: 0.009086376056075096 \n",
      "Epoch: 1596 | MAE Train Loss: 0.003889723215252161 | MAE Test Loss: 0.009044843725860119 \n",
      "Epoch: 1597 | MAE Train Loss: 0.0038557343650609255 | MAE Test Loss: 0.008934634737670422 \n",
      "Epoch: 1598 | MAE Train Loss: 0.00382082536816597 | MAE Test Loss: 0.008824437856674194 \n",
      "Epoch: 1599 | MAE Train Loss: 0.0037871920503675938 | MAE Test Loss: 0.008782869204878807 \n",
      "Epoch: 1600 | MAE Train Loss: 0.003752306802198291 | MAE Test Loss: 0.008672690019011497 \n",
      "Epoch: 1601 | MAE Train Loss: 0.003718290477991104 | MAE Test Loss: 0.008631139993667603 \n",
      "Epoch: 1602 | MAE Train Loss: 0.0036837817169725895 | MAE Test Loss: 0.008520943112671375 \n",
      "Epoch: 1603 | MAE Train Loss: 0.003649384481832385 | MAE Test Loss: 0.008479404263198376 \n",
      "Epoch: 1604 | MAE Train Loss: 0.003615252673625946 | MAE Test Loss: 0.008369212970137596 \n",
      "Epoch: 1605 | MAE Train Loss: 0.0035804794169962406 | MAE Test Loss: 0.008327657356858253 \n",
      "Epoch: 1606 | MAE Train Loss: 0.0035467303823679686 | MAE Test Loss: 0.008217424154281616 \n",
      "Epoch: 1607 | MAE Train Loss: 0.0035118362866342068 | MAE Test Loss: 0.008107262663543224 \n",
      "Epoch: 1608 | MAE Train Loss: 0.003477951977401972 | MAE Test Loss: 0.008065718226134777 \n",
      "Epoch: 1609 | MAE Train Loss: 0.0034433044493198395 | MAE Test Loss: 0.007955526933073997 \n",
      "Epoch: 1610 | MAE Train Loss: 0.0034090480767190456 | MAE Test Loss: 0.007913952693343163 \n",
      "Epoch: 1611 | MAE Train Loss: 0.003374775405973196 | MAE Test Loss: 0.007803767919540405 \n",
      "Epoch: 1612 | MAE Train Loss: 0.0033401413820683956 | MAE Test Loss: 0.007762229535728693 \n",
      "Epoch: 1613 | MAE Train Loss: 0.0033062517177313566 | MAE Test Loss: 0.0076520382426679134 \n",
      "Epoch: 1614 | MAE Train Loss: 0.003271349472925067 | MAE Test Loss: 0.007541835308074951 \n",
      "Epoch: 1615 | MAE Train Loss: 0.0032376102171838284 | MAE Test Loss: 0.007500273175537586 \n",
      "Epoch: 1616 | MAE Train Loss: 0.00320282275788486 | MAE Test Loss: 0.007390111684799194 \n",
      "Epoch: 1617 | MAE Train Loss: 0.0031687088776379824 | MAE Test Loss: 0.007348555140197277 \n",
      "Epoch: 1618 | MAE Train Loss: 0.0031342990696430206 | MAE Test Loss: 0.007238352205604315 \n",
      "Epoch: 1619 | MAE Train Loss: 0.0030998014844954014 | MAE Test Loss: 0.0071968138217926025 \n",
      "Epoch: 1620 | MAE Train Loss: 0.0030657730530947447 | MAE Test Loss: 0.007086604833602905 \n",
      "Epoch: 1621 | MAE Train Loss: 0.0030308954883366823 | MAE Test Loss: 0.007045066449791193 \n",
      "Epoch: 1622 | MAE Train Loss: 0.0029972500633448362 | MAE Test Loss: 0.0069348691031336784 \n",
      "Epoch: 1623 | MAE Train Loss: 0.0029623478185385466 | MAE Test Loss: 0.006824660114943981 \n",
      "Epoch: 1624 | MAE Train Loss: 0.0029283673502504826 | MAE Test Loss: 0.006783121731132269 \n",
      "Epoch: 1625 | MAE Train Loss: 0.0028938204050064087 | MAE Test Loss: 0.006672924850136042 \n",
      "Epoch: 1626 | MAE Train Loss: 0.0028594627510756254 | MAE Test Loss: 0.006631386466324329 \n",
      "Epoch: 1627 | MAE Train Loss: 0.0028253011405467987 | MAE Test Loss: 0.00652118306607008 \n",
      "Epoch: 1628 | MAE Train Loss: 0.0027905553579330444 | MAE Test Loss: 0.0064796386286616325 \n",
      "Epoch: 1629 | MAE Train Loss: 0.0027567713987082243 | MAE Test Loss: 0.006369441747665405 \n",
      "Epoch: 1630 | MAE Train Loss: 0.0027218691539019346 | MAE Test Loss: 0.006259244866669178 \n",
      "Epoch: 1631 | MAE Train Loss: 0.002688030945137143 | MAE Test Loss: 0.006217694375663996 \n",
      "Epoch: 1632 | MAE Train Loss: 0.0026533431373536587 | MAE Test Loss: 0.006107509136199951 \n",
      "Epoch: 1633 | MAE Train Loss: 0.002619124948978424 | MAE Test Loss: 0.006065934896469116 \n",
      "Epoch: 1634 | MAE Train Loss: 0.0025848224759101868 | MAE Test Loss: 0.005955773405730724 \n",
      "Epoch: 1635 | MAE Train Loss: 0.0025502212811261415 | MAE Test Loss: 0.005914211273193359 \n",
      "Epoch: 1636 | MAE Train Loss: 0.0025162927340716124 | MAE Test Loss: 0.005804014392197132 \n",
      "Epoch: 1637 | MAE Train Loss: 0.0024813897907733917 | MAE Test Loss: 0.0056938170455396175 \n",
      "Epoch: 1638 | MAE Train Loss: 0.002447692211717367 | MAE Test Loss: 0.005652278661727905 \n",
      "Epoch: 1639 | MAE Train Loss: 0.0024128661025315523 | MAE Test Loss: 0.005542081780731678 \n",
      "Epoch: 1640 | MAE Train Loss: 0.0023787864483892918 | MAE Test Loss: 0.005500525236129761 \n",
      "Epoch: 1641 | MAE Train Loss: 0.002344336360692978 | MAE Test Loss: 0.005390333943068981 \n",
      "Epoch: 1642 | MAE Train Loss: 0.002309884177520871 | MAE Test Loss: 0.005348783917725086 \n",
      "Epoch: 1643 | MAE Train Loss: 0.002275817096233368 | MAE Test Loss: 0.005238586571067572 \n",
      "Epoch: 1644 | MAE Train Loss: 0.002240970032289624 | MAE Test Loss: 0.005197036080062389 \n",
      "Epoch: 1645 | MAE Train Loss: 0.0022072880528867245 | MAE Test Loss: 0.005086851306259632 \n",
      "Epoch: 1646 | MAE Train Loss: 0.0021723962854593992 | MAE Test Loss: 0.0049766362644732 \n",
      "Epoch: 1647 | MAE Train Loss: 0.002138445619493723 | MAE Test Loss: 0.004935103468596935 \n",
      "Epoch: 1648 | MAE Train Loss: 0.002103863749653101 | MAE Test Loss: 0.004824906587600708 \n",
      "Epoch: 1649 | MAE Train Loss: 0.002069540321826935 | MAE Test Loss: 0.004783356096595526 \n",
      "Epoch: 1650 | MAE Train Loss: 0.002035337733104825 | MAE Test Loss: 0.004673170857131481 \n",
      "Epoch: 1651 | MAE Train Loss: 0.0020006403792649508 | MAE Test Loss: 0.004631620831787586 \n",
      "Epoch: 1652 | MAE Train Loss: 0.0019668147433549166 | MAE Test Loss: 0.004521423485130072 \n",
      "Epoch: 1653 | MAE Train Loss: 0.0019319094717502594 | MAE Test Loss: 0.004411250352859497 \n",
      "Epoch: 1654 | MAE Train Loss: 0.0018981031607836485 | MAE Test Loss: 0.004369682166725397 \n",
      "Epoch: 1655 | MAE Train Loss: 0.0018633902072906494 | MAE Test Loss: 0.0042594848200678825 \n",
      "Epoch: 1656 | MAE Train Loss: 0.0018292047316208482 | MAE Test Loss: 0.004217928741127253 \n",
      "Epoch: 1657 | MAE Train Loss: 0.001794859766960144 | MAE Test Loss: 0.004107743501663208 \n",
      "Epoch: 1658 | MAE Train Loss: 0.0017603017622604966 | MAE Test Loss: 0.004066193010658026 \n",
      "Epoch: 1659 | MAE Train Loss: 0.0017263360787183046 | MAE Test Loss: 0.0039559961296617985 \n",
      "Epoch: 1660 | MAE Train Loss: 0.0016914367442950606 | MAE Test Loss: 0.0038457990158349276 \n",
      "Epoch: 1661 | MAE Train Loss: 0.0016577697824686766 | MAE Test Loss: 0.0038042485248297453 \n",
      "Epoch: 1662 | MAE Train Loss: 0.00162290851585567 | MAE Test Loss: 0.0036940635181963444 \n",
      "Epoch: 1663 | MAE Train Loss: 0.0015888691414147615 | MAE Test Loss: 0.003652519080787897 \n",
      "Epoch: 1664 | MAE Train Loss: 0.001554381800815463 | MAE Test Loss: 0.003542321966961026 \n",
      "Epoch: 1665 | MAE Train Loss: 0.001519959419965744 | MAE Test Loss: 0.0035007535479962826 \n",
      "Epoch: 1666 | MAE Train Loss: 0.0014858640497550368 | MAE Test Loss: 0.003390580415725708 \n",
      "Epoch: 1667 | MAE Train Loss: 0.0014510549372062087 | MAE Test Loss: 0.003349012229591608 \n",
      "Epoch: 1668 | MAE Train Loss: 0.0014173306990414858 | MAE Test Loss: 0.0032388330437242985 \n",
      "Epoch: 1669 | MAE Train Loss: 0.0013824350899085402 | MAE Test Loss: 0.0031286359298974276 \n",
      "Epoch: 1670 | MAE Train Loss: 0.0013485297095030546 | MAE Test Loss: 0.0030870854388922453 \n",
      "Epoch: 1671 | MAE Train Loss: 0.0013139061629772186 | MAE Test Loss: 0.0029768883250653744 \n",
      "Epoch: 1672 | MAE Train Loss: 0.0012796238297596574 | MAE Test Loss: 0.002935355994850397 \n",
      "Epoch: 1673 | MAE Train Loss: 0.0012453824747353792 | MAE Test Loss: 0.002825152827426791 \n",
      "Epoch: 1674 | MAE Train Loss: 0.0012107171351090074 | MAE Test Loss: 0.0027836263179779053 \n",
      "Epoch: 1675 | MAE Train Loss: 0.0011768483091145754 | MAE Test Loss: 0.0026734054554253817 \n",
      "Epoch: 1676 | MAE Train Loss: 0.0011419549118727446 | MAE Test Loss: 0.002563220215961337 \n",
      "Epoch: 1677 | MAE Train Loss: 0.0011081956326961517 | MAE Test Loss: 0.0025216699577867985 \n",
      "Epoch: 1678 | MAE Train Loss: 0.001073425286449492 | MAE Test Loss: 0.002411460969597101 \n",
      "Epoch: 1679 | MAE Train Loss: 0.0010392836993560195 | MAE Test Loss: 0.0023699342273175716 \n",
      "Epoch: 1680 | MAE Train Loss: 0.0010049014817923307 | MAE Test Loss: 0.002259713364765048 \n",
      "Epoch: 1681 | MAE Train Loss: 0.0009703792748041451 | MAE Test Loss: 0.0022181749809533358 \n",
      "Epoch: 1682 | MAE Train Loss: 0.0009363748249597847 | MAE Test Loss: 0.002107977867126465 \n",
      "Epoch: 1683 | MAE Train Loss: 0.0009014763054437935 | MAE Test Loss: 0.0020321309566497803 \n",
      "Epoch: 1684 | MAE Train Loss: 0.0008672110852785408 | MAE Test Loss: 0.0019219338428229094 \n",
      "Epoch: 1685 | MAE Train Loss: 0.0008333943551406264 | MAE Test Loss: 0.001880383468233049 \n",
      "Epoch: 1686 | MAE Train Loss: 0.000798691064119339 | MAE Test Loss: 0.0017701864708214998 \n",
      "Epoch: 1687 | MAE Train Loss: 0.0007644928991794586 | MAE Test Loss: 0.0017286359798163176 \n",
      "Epoch: 1688 | MAE Train Loss: 0.0007301606237888336 | MAE Test Loss: 0.0016184389824047685 \n",
      "Epoch: 1689 | MAE Train Loss: 0.0006955877179279923 | MAE Test Loss: 0.0015769064193591475 \n",
      "Epoch: 1690 | MAE Train Loss: 0.0006616368773393333 | MAE Test Loss: 0.0014667033683508635 \n",
      "Epoch: 1691 | MAE Train Loss: 0.0006267346325330436 | MAE Test Loss: 0.0013565004337579012 \n",
      "Epoch: 1692 | MAE Train Loss: 0.0005930595216341317 | MAE Test Loss: 0.001314955996349454 \n",
      "Epoch: 1693 | MAE Train Loss: 0.0005582116427831352 | MAE Test Loss: 0.0012047707568854094 \n",
      "Epoch: 1694 | MAE Train Loss: 0.0005241595208644867 | MAE Test Loss: 0.001163220382295549 \n",
      "Epoch: 1695 | MAE Train Loss: 0.0004896812024526298 | MAE Test Loss: 0.0010530113941058517 \n",
      "Epoch: 1696 | MAE Train Loss: 0.0004552476166281849 | MAE Test Loss: 0.0010114848846569657 \n",
      "Epoch: 1697 | MAE Train Loss: 0.00042115748510695994 | MAE Test Loss: 0.0009012639638967812 \n",
      "Epoch: 1698 | MAE Train Loss: 0.00038634316297248006 | MAE Test Loss: 0.0008597254636697471 \n",
      "Epoch: 1699 | MAE Train Loss: 0.00035263077006675303 | MAE Test Loss: 0.0007495284080505371 \n",
      "Epoch: 1700 | MAE Train Loss: 0.0003177322505507618 | MAE Test Loss: 0.0006393313524313271 \n",
      "Epoch: 1701 | MAE Train Loss: 0.0002838142099790275 | MAE Test Loss: 0.0005977809196338058 \n",
      "Epoch: 1702 | MAE Train Loss: 0.00024920105352066457 | MAE Test Loss: 0.00048760772915557027 \n",
      "Epoch: 1703 | MAE Train Loss: 0.00021491051302291453 | MAE Test Loss: 0.0004460453928913921 \n",
      "Epoch: 1704 | MAE Train Loss: 0.00018083005852531642 | MAE Test Loss: 0.00026807188987731934 \n",
      "Epoch: 1705 | MAE Train Loss: 0.00015336423530243337 | MAE Test Loss: 0.0005101740243844688 \n",
      "Epoch: 1706 | MAE Train Loss: 0.00019887834787368774 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1707 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1708 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1709 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1710 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1711 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1712 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1713 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1714 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1715 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1716 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1717 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1718 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1719 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1720 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1721 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1722 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1723 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1724 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1725 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1726 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1727 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1728 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1729 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1730 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1731 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1732 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1733 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1734 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1735 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1736 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1737 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1738 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1739 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1740 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1741 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1742 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1743 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1744 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1745 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1746 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1747 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1748 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1749 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1750 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1751 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1752 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1753 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1754 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1755 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1756 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1757 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1758 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1759 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1760 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1761 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1762 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1763 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1764 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1765 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1766 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1767 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1768 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1769 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1770 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1771 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1772 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1773 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1774 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1775 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1776 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1777 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1778 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1779 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1780 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1781 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1782 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1783 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1784 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1785 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1786 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1787 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1788 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1789 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1790 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1791 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1792 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1793 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1794 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1795 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1796 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1797 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1798 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1799 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1800 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1801 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1802 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1803 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1804 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1805 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1806 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1807 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1808 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1809 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1810 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1811 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1812 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1813 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1814 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1815 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1816 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1817 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1818 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1819 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1820 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1821 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1822 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1823 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1824 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1825 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1826 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1827 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1828 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1829 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1830 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1831 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1832 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1833 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1834 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1835 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1836 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1837 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1838 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1839 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1840 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1841 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1842 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1843 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1844 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1845 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1846 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1847 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1848 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1849 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1850 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1851 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1852 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1853 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1854 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1855 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1856 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1857 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1858 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1859 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1860 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1861 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1862 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1863 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1864 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1865 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1866 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1867 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1868 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1869 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1870 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1871 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1872 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1873 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1874 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1875 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1876 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1877 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1878 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1879 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1880 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1881 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1882 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1883 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1884 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1885 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1886 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1887 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1888 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1889 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1890 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1891 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1892 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1893 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1894 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1895 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1896 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1897 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1898 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1899 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1900 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1901 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1902 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1903 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1904 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1905 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1906 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1907 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1908 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1909 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1910 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1911 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1912 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1913 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1914 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1915 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1916 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1917 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1918 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1919 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1920 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1921 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1922 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1923 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1924 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1925 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1926 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1927 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1928 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1929 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1930 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1931 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1932 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1933 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1934 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1935 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1936 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1937 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1938 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1939 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1940 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1941 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1942 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1943 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1944 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1945 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1946 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1947 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1948 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1949 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1950 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1951 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1952 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1953 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1954 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1955 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1956 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1957 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1958 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1959 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1960 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1961 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1962 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1963 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1964 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1965 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1966 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1967 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1968 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1969 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1970 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1971 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1972 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1973 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1974 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1975 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1976 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1977 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1978 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1979 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1980 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1981 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1982 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1983 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1984 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1985 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1986 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1987 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1988 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1989 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1990 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1991 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1992 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1993 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1994 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1995 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1996 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1997 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n",
      "Epoch: 1998 | MAE Train Loss: 0.0004444979131221771 | MAE Test Loss: 0.0005780101055279374 \n",
      "Epoch: 1999 | MAE Train Loss: 0.0007075972971506417 | MAE Test Loss: 0.0007690846687182784 \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Número de epocas\n",
    "EPOCAS = 2000\n",
    "\n",
    "# criando listas vazias para comparar os resultados\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "epoch_count = []\n",
    "\n",
    "for epoch in range(EPOCAS):\n",
    "    ### Treino\n",
    "\n",
    "    # Coloca o modelo no modo de treino\n",
    "    model_0.train()\n",
    "\n",
    "    # 1. passa por cada elemento\n",
    "    y_pred = model_0(X_train)\n",
    "    # print(y_pred)\n",
    "\n",
    "    # 2. calcula a perda\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # 3. zera os gradientes\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. calcula o gradiente da perda em relação a cada parâmetro treinável do modelo usando backpropagation.\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. atualiza os pesos do optmizer\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Teste\n",
    "\n",
    "    # Coloca o modelo no modo teste.\n",
    "    model_0.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        # 1. Passa por cada elemento do teste\n",
    "        test_pred = model_0(X_test)\n",
    "\n",
    "        # 2. calcula perda\n",
    "        test_loss = loss_fn(test_pred, y_test.type(torch.float))\n",
    "        # previsões vêm no tipo de dados torch.float, portanto, as comparações precisam ser feitas com tensores do mesmo tipo\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            # printa oq esta acontecendo\n",
    "            epoch_count.append(epoch)\n",
    "            train_loss_values.append(loss.detach().numpy())\n",
    "            test_loss_values.append(test_loss.detach().numpy())\n",
    "            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e080e32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x79253c24aaf0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot da curva de perda\n",
    "plt.plot(epoch_count, train_loss_values, label=\"Train loss\")\n",
    "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
    "plt.title(\"Training and test loss curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacd0c29",
   "metadata": {},
   "source": [
    "Uau! Quão legal é isso?\n",
    "\n",
    "Nosso modelo chegou muito perto de calcular os valores originais exatos de peso e viés (e provavelmente chegaria ainda mais perto se o treinássemos por mais tempo).\n",
    "\n",
    "Provavelmente nunca os adivinharíamos perfeitamente (especialmente ao usar conjuntos de dados mais complicados), mas tudo bem, muitas vezes você pode fazer coisas muito legais com uma aproximação aproximada.\n",
    "\n",
    "Essa é a ideia do aprendizado de máquina e do aprendizado profundo. Existem alguns valores ideais que descrevem nossos dados e, em vez de descobri-los manualmente, podemos treinar um modelo para descobri-los programaticamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe672324",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Fazendo previsões com um modelo PyTorch pre-treinado(inferencia)\n",
    "\n",
    "Há três coisas a serem lembradas ao fazer previsões (também chamadas de inferência) com um modelo PyTorch\n",
    "\n",
    "- Defina o modelo em modo de avaliação (model.eval()).\n",
    "- Faça as previsões usando o gerenciador de contexto do modo de inferência (com torch.inference_mode(): ...).\n",
    "- Todas as previsões devem ser feitas com objetos no mesmo dispositivo (por exemplo, dados e modelo apenas na GPU ou dados e modelo apenas na CPU).\n",
    "\n",
    "Os dois primeiros itens garantem que todos os cálculos e configurações úteis que o PyTorch usa nos bastidores durante o treinamento, mas que não são necessários para inferência, estejam desativados (isso resulta em um cálculo mais rápido). E o terceiro garante que você não encontrará erros entre dispositivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "32c60096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_0.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_0(X_test)\n",
    "\n",
    "plot_predictions(predictions=y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2ab83e",
   "metadata": {},
   "source": [
    "## Salvando e carregando o modelo\n",
    "\n",
    "Depois do modelo treinado, você irá querer salva-lo para usar em alguma aplicação, então é isso que vamos aprender agora\n",
    "\n",
    "Para salvar e carregar modelos no PyTorch, existem três métodos principais que você deve conhecer\n",
    "\n",
    "- torch.save: Salva um objeto serializado em disco usando o pickle utility do Python\n",
    "- torch.load: Usa os recursos de do pickle unpickling para desserializar e carregar arquivos de objetos\n",
    "- torch.nn.Module.load_state_dict: Carrega o dicionário de parâmetros de um modelo (model.state_dict()) usando um objeto state_dict() salvo.\n",
    "\n",
    "A maneira recomendada de salvar e carregar o modelo para fazer inferência(previsão) é salvar e carregar com state_dict(), veja o passo a passo\n",
    "<ol>\n",
    "    <li>Criamos diretorio para salvar o modelo</li>\n",
    "    <li>Criamos um caminho de arquivo para salvar o modelo</li>\n",
    "    <li>chamamos torch.save(state_dict(), nome_do_arquivo)</li>\n",
    "</ol>\n",
    "\n",
    "obs.: por convenção, o modelo deve ser salvo com .pt ou .pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "09a38a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Criando o caminho relativo para salvar o modelo\n",
    "MODEL_SAVE_PATH = \"01.1_Modelo.pth\"\n",
    "oq_salvar = model_0.state_dict() # Salvar só o state_dict() (pesos do modelo) é melhor\n",
    "# Se você salvar o modelo inteiro, ele pode quebrar depois que você mudar o código ou mover arquivos.\n",
    "\n",
    "torch.save(oq_salvar, MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52afb566",
   "metadata": {},
   "source": [
    "## Carregando modelo salvo\n",
    "\n",
    "Passo a passo\n",
    "- Criar uma nova instancia de um mesmo modelo(com pesos aleatórios)\n",
    "- Carregar o state_dict com torch.load()\n",
    "- Aplicar os pesos no novo modelo com .load_state_dict()\n",
    "\n",
    "Para fazer infência:\n",
    "- model.eval()\n",
    "- with torch.inference_mode():\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b5e3eb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instanciando modelo novo\n",
    "modelo_carregado = LinearRegressionModel()\n",
    "\n",
    "modelo_carregado.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
    "\n",
    "modelo_carregado.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    previsoes = modelo_carregado(X_test)\n",
    "\n",
    "plot_predictions(predictions=previsoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f04db85",
   "metadata": {},
   "source": [
    ".load apenas lê os pesos do arquivo e retorna um dicionario<br>\n",
    ".load_state_dict() coloca os pesos dentro do modelo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "specific",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
