{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3784cddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.1+cu126'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68806304",
   "metadata": {},
   "source": [
    "# Tensores\n",
    "\n",
    "Tensores são os blocos fundamentais na construção da aprendizagem de maquina\n",
    "por exemplo, pode-se representar um tensor que recebe uma imagem como [numero_de_canais, altura_da_imagem, Largura_da_imagem]. Esse tensor teria 3 dimensões.\n",
    "\n",
    "Tensores são construidos a partir de listas do Python ou arrays numpy(melhor).\n",
    "\n",
    "\n",
    "Tensor Escalar\n",
    "    É um Tensor com apenas um elemento e de dimensão 0\n",
    "    è instanciado com torch.tensor(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2f04670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(12)\n",
    "scalar        # tensor(12)\n",
    "scalar.item() # 12\n",
    "scalar.ndim   # 0 - O Tensor possui 0 dimensões"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bcc8a0",
   "metadata": {},
   "source": [
    "# Vetores\n",
    "\n",
    "Vetores são tensores de uma unica dimensão que pode conter vários números(em resumo, é uma lista). o primeiro exemplo(o da imagem) é um vetor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c030692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vetor = torch.tensor([1, 2, 3])\n",
    "vetor        # tensor([1, 2, 3])\n",
    "vetor.ndim   # 1 - imprime o número de dimensões do vetor\n",
    "vetor.shape  # torch.Size([3]) - shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9522c6f",
   "metadata": {},
   "source": [
    "# Matrizes\n",
    "\n",
    "Matrizes são basicamente vetores dentro de vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00098d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIZ = torch.tensor([\n",
    "    [7,  8,  9],\n",
    "    [9, 10, 11]\n",
    "])\n",
    "\n",
    "MATRIZ.ndim     # 2\n",
    "MATRIZ.shape    # [2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc502510",
   "metadata": {},
   "source": [
    "# Tensores\n",
    "\n",
    "tensores reais são \"listas\" que possuem 3 dimensões ou mais\n",
    "\n",
    "obs.: Note que matrizes e tensores sõ denotados por letras maiúsculas, enquanto escalares e vetores são denotados por letras minúsculas\n",
    "\n",
    "<img src=00_img_apoio_01.png width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c95be25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR = torch.tensor([\n",
    "    [\n",
    "        [7,  8,  9],\n",
    "        [9, 10, 11]\n",
    "    ],\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [1, 2, 3]\n",
    "    ]\n",
    "])\n",
    "\n",
    "TENSOR.ndim     # 3\n",
    "TENSOR.shape    # [2, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd78d5b",
   "metadata": {},
   "source": [
    "Raramente iremos criar um Tensor manualmente, como tivemos feito até agora. \n",
    "\n",
    "Então, oq faremos? vamos criar um tensor com números aleatórios e deixar a MAchine Learn ir ajustando os números \"sozinho\".\n",
    "\n",
    "O Ideal seria começar o tensor com 0s ou 1s\n",
    "\n",
    "Também pode-se criar tensores com números aleatórios em um intervalo X e Y\n",
    "\n",
    "torch.arange(start, end, step)\n",
    "\n",
    "Para fazer um Tensor com Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fdfdce89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1053, 0.2695, 0.3588, 0.1994],\n",
      "        [0.5472, 0.0062, 0.9516, 0.0753],\n",
      "        [0.8860, 0.5832, 0.3376, 0.8090]])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "randon_tendor = torch.rand(size=(3, 4)) # Note que esse \"Tensor\" na verdade é uma matriz\n",
    "print(randon_tendor)\n",
    "\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "print(zeros)\n",
    "\n",
    "ones = torch.ones(size=(3, 4))\n",
    "print(ones)\n",
    "\n",
    "T = torch.arange(1, 10)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733b033f",
   "metadata": {},
   "source": [
    "Podemos criar um tensor do tamanho de outro com 0s e 1s de forma fácil, com as funções\n",
    "<ul>\n",
    "    <li>zeros_like</li>\n",
    "    <li>ones_like</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e989e95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "zeros2 = torch.zeros_like(zeros)\n",
    "print(zeros2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed393e05",
   "metadata": {},
   "source": [
    "<p>Não entendi muito bem, mas exietem tipos diferentes de tensores. Quando for lidar com tensores, precisamos investigar algumas de suas caracteristicas, como:</p>\n",
    "\n",
    "<ul>\n",
    "    <li>ndim</li>\n",
    "    <li>shape</li>\n",
    "    <li>devide - dispositivo(CPU ou GTU)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c78d58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor:             torch.Size([3, 4])\n",
      "Datatype of tensor:          torch.float32\n",
      "Device tensor is stored on:  cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "\n",
    "# Find out details about it\n",
    "print(f\"Shape of tensor:             {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor:          {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on:  {some_tensor.device}\") # will default to CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650b5582",
   "metadata": {},
   "source": [
    "Um modelo aprende investigando tensores e executando uma série de operações para criar uma representação dos padrões nos dados de entrada.\n",
    "\n",
    "Essas operações costumam ser:\n",
    "\n",
    "<ul>\n",
    "    <li>Adição</li>\n",
    "    <li>Subtração</li>\n",
    "    <li>Multiplicação</li>\n",
    "    <li>Divisão</li>\n",
    "    <li>Multiplicação de matrizes</li>\n",
    "</ul >\n",
    "\n",
    "Para realizar essa operações manualmente, pode-se tratar o tensor da mesma forma que se trata um Array numpy. como:\n",
    "<br>TENSOR = TENSOR * 10\n",
    "\n",
    "É importante saber disso também:\n",
    "\n",
    "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
    "Equals: tensor([1, 4, 9])\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de91532",
   "metadata": {},
   "source": [
    "\n",
    "# Multiplicação de Matriz\n",
    "\n",
    "É extremamente importante para o deep Learning, o Pytorch já têm uma função que faz isso, a <stronger>torch.matmul()</stronger>\n",
    "\n",
    "Mas é importante saber as 2 regras fundamentais da multiplicação de matriz\n",
    "<ol>\n",
    "    <li>Os Shapes internos das Matrizes devem ter dimenções iguais</li>\n",
    "    <p>Tendo 2 Matrizes, A(shape = (m, n)) e B(shape = (p, q)), a multiplização só funaionará se n == p</p>\n",
    "        <ul>\n",
    "            <li>(3, 2) @ (3, 2) -> não funciona</li>\n",
    "            <li>(2, 3) @ (3, 2) -> funciona</li>\n",
    "            <li>(3, 2) @ (2, 3) -> funciona</li>\n",
    "        </ul>\n",
    "    <li>O resultado da multiplicação tem a saida com as dimençoes externas da matriz</li>\n",
    "        <ul>\n",
    "            <li>(3, 2) @ (3, 2) -> (3, 2)</li>\n",
    "            <li>(2, 3) @ (3, 2) -> (2, 2)</li>\n",
    "            <li>(3, 2) @ (2, 3) -> (3, 3)</li>\n",
    "        </ul>\n",
    "</ol>\n",
    "\n",
    "\n",
    "\n",
    "<img src=00_img_apoio_02.png width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3abeff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes causam erros\n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "\n",
    "#torch.matmul(tensor_A, tensor_B)\n",
    "# Não pode multiplicar (3x2 por 3x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5e01553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 97., 126.],\n",
       "        [111., 144.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esse caso da certo\n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10, 12],\n",
    "                         [8, 11, 14], \n",
    "                        ], dtype=torch.float32)\n",
    "\n",
    "torch.matmul(tensor_B, tensor_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82e2d87",
   "metadata": {},
   "source": [
    "Pode-se inverter as dinmeções de um Tensor facilmente utilizando o \"Metodo\" T.\n",
    "\n",
    "como funciona?\n",
    "\n",
    "M = [\n",
    "        [1, 2, 3],\n",
    "        [1, 2, 3]\n",
    "    ]\n",
    "\n",
    "M.T\n",
    "[\n",
    "    [1, 1], \n",
    "    [2, 2], \n",
    "    [3, 3]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "48355ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "\n",
    "x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad393ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
      "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
      "Output:\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Shapes need to be in the right way  \n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "# The operation works when tensor_B is transposed\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\")\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\")\n",
    "print(\"Output:\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output) \n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a95b02",
   "metadata": {},
   "source": [
    "Nota: uma multiplicação de matrizes é chamada de produto escalar (dot product) e são muito usadas em redes neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8783bdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[1.3702, 1.5487, 0.7538],\n",
      "        [3.6252, 2.5165, 0.7293],\n",
      "        [5.8802, 3.4843, 0.7048]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Since the linear layer starts with a random weights matrix, let's make it reproducible (more on this later)\n",
    "torch.manual_seed(42)\n",
    "# This uses matrix multiplication\n",
    "linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input \n",
    "                         out_features=3) # out_features = describes outer value \n",
    "x = tensor_A\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb33b60",
   "metadata": {},
   "source": [
    "<h1>Extração de dados de um tensor</h1>\n",
    "\n",
    "<p>Extraimos os dados do tensor com metodos iguais aos do numpy</p>\n",
    "\n",
    "<ul>\n",
    "    <li>x.min()</li>\n",
    "    <li>x.max()</li>\n",
    "    <li>x.type(torch.float32).mean()</li>\n",
    "    <li>x.sum()</li>\n",
    "    <li>x.median()</li>\n",
    "    <li>torcg.argmax(x) -> index do elemento max</li>\n",
    "    <li>torch.argmin(x) -> index do elemento min</li>\n",
    "    \n",
    "</ul>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1106790",
   "metadata": {},
   "source": [
    "<h2>Tipo de dados nos Tensores</h2>\n",
    "\n",
    "<p>Tensores de tipos diferentes(como float64 e float32) dão erro, então é necessário igualar os tipos. para isso, utilizamos a função</p>\n",
    "\n",
    "<h4>TENSOR.type(dtype)</h4>\n",
    "<p>Por exemplo tensor.type(torch.float16)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57faaa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "TENSOR = torch.tensor([1, 2, 3], dtype=int)\n",
    "print(TENSOR.dtype)\n",
    "TENSOR = TENSOR.type(torch.float32)\n",
    "print(TENSOR.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3940f68",
   "metadata": {},
   "source": [
    "<h2>Algumas operações de tensores</h2>\n",
    "\n",
    "<p>Em alguns momentos, será necessário modificar os tensores, modificando o seu shape e ndim, aqui vai uma lista detalhada dessas funções e oq fazem</p>\n",
    "\n",
    "<ol>\n",
    "    <li>torch.reshape(input, new_shape)</li>\n",
    "        Retorna o novo tensor rearranjado<br>\n",
    "        O segundo argumento é uma túpla<br>\n",
    "        Não é implace<br>\n",
    "        <br>\n",
    "        <li>Tensor.view(shape)</li>\n",
    "        Não modifica o Tensor, só serve para visualização do tensor com o shape alterado<br>\n",
    "        <br>\n",
    "        <li>torch.stack(Tensor, dim=0)</li>\n",
    "        Empilha multiplos Tensores, criando uma nova dimenção<br>\n",
    "        <br>\n",
    "        <li>torch.squeeze(input)</li>\n",
    "        Remove dimenções cujo tamanho é 1<br>\n",
    "        por exemplo, o Tensor torch.randn(1, 3, 1, 5) termina com shape = (3, 5) após a aplicação da função.<br>\n",
    "        Não é in-place<br>\n",
    "        <br>\n",
    "        <li>torch.permute(input, dims)</li>\n",
    "        Reorganiza as dimenções do Tensor<br>\n",
    "        Utiliza o index das dimenções para organizar<br>\n",
    "        Ou seja, torch.permute(torch.rand(2, 3, 4), (0, 2, 1)) == tensor com shape= (2, 4, 3)<br>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0dd8528e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) \n",
      " tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "# torch.reshape(tensor, (new shape))\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor2 = torch.reshape(tensor, (3, 1))\n",
    "\n",
    "print(tensor, '\\n',tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e9730d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) \n",
      " tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor.view(shape)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor, '\\n', tensor.view(3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "15a56770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# torch.stack([lista_tensores], dim=0)\n",
    "\n",
    "tensor  = torch.tensor([1, 2, 3])\n",
    "tensor2 = torch.tensor([4, 5, 6])\n",
    "\n",
    "tensor3 = torch.stack([tensor, tensor2], dim=0)\n",
    "\n",
    "print(tensor3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eb5857e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "# tensor.squeeze(input)\n",
    "\n",
    "tensor = torch.rand(3, 1, 4, 1, 3)\n",
    "tensor = torch.squeeze(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ea6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.6872, -1.0892, -0.3553, -0.9138],\n",
      "         [-0.6581,  0.0780,  0.5258, -0.4880],\n",
      "         [-0.1973, -1.0546,  1.2780,  0.1453]],\n",
      "\n",
      "        [[ 0.2311,  0.0087, -0.1423,  0.1971],\n",
      "         [-0.6417, -2.2064, -0.7508,  2.8140],\n",
      "         [ 0.3598, -0.0898,  0.4584, -0.5644]]]) \n",
      "\n",
      "tensor([[[ 0.6872, -0.6581, -0.1973],\n",
      "         [-1.0892,  0.0780, -1.0546],\n",
      "         [-0.3553,  0.5258,  1.2780],\n",
      "         [-0.9138, -0.4880,  0.1453]],\n",
      "\n",
      "        [[ 0.2311, -0.6417,  0.3598],\n",
      "         [ 0.0087, -2.2064, -0.0898],\n",
      "         [-0.1423, -0.7508,  0.4584],\n",
      "         [ 0.1971,  2.8140, -0.5644]]])\n"
     ]
    }
   ],
   "source": [
    "#torch.permutate(tensor, reshape)\n",
    "\n",
    "x = torch.randn(2, 3, 4)\n",
    "y = torch.permute(x, (0, 2, 1))  # troca eixos 1 e 2\n",
    "\n",
    "print(x, '\\n')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452beb48",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h2>Integração Numpy e PyTorch</h2>\n",
    "\n",
    "Para transformar Tensores em numpy Array e vice-versa, as funções são:\n",
    "\n",
    "<ol>\n",
    "    <li>torch.from_numpy(tensor) -> Array para Tensor</li>\n",
    "    <br>\n",
    "    <li>torch.Tensor.numpy()     -> Tensor para Array</li>\n",
    "</ol>\n",
    "\n",
    "Pode-se criar tensores aleatorios utilizando:\n",
    "\n",
    "- torch.rand() -> só positivos\n",
    "- torch.randn()-> positivos e negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d467686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7] \n",
      " int64\n",
      "\n",
      "tensor([1, 2, 3, 4, 5, 6, 7]) \n",
      " torch.int64\n"
     ]
    }
   ],
   "source": [
    "array = np.arange(1, 8)\n",
    "tensor = torch.from_numpy(array)\n",
    "print(array, '\\n', array.dtype)\n",
    "print()\n",
    "print(tensor, '\\n', tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaf752a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Reprodutibilidade(seed)\n",
    "\n",
    "Redes neurais começam com números aleatórios para descrever padrões nos dados (esses números são descrições ruins) e tentam melhorar esses números aleatórios usando operações tensorais (e algumas outras coisas que ainda não discutimos) para descrever melhor os padrões nos dados.\n",
    "\n",
    "Resumidamente:\n",
    "\n",
    "comece com números aleatórios -> operações de tensor -> tente melhorar (de novo e de novo e de novo)\n",
    "\n",
    "Embora a aleatoriedade seja agradável e poderosa, às vezes você gostaria que houvesse um pouco menos de aleatoriedade.\n",
    "\n",
    "Por que?\n",
    "\n",
    "Assim, você pode realizar experimentos repetíveis.\n",
    "\n",
    "Por exemplo, você cria um algoritmo capaz de atingir desempenho X.\n",
    "\n",
    "E então seu amigo experimenta para verificar se você não está louco.\n",
    "\n",
    "Como eles puderam fazer uma coisa dessas?\n",
    "\n",
    "É aí que entra a reprodutibilidade.\n",
    "\n",
    "Em outras palavras, você pode obter os mesmos resultados (ou muito semelhantes) em seu computador executando o mesmo código que eu obtenho no meu?\n",
    "\n",
    "Vejamos um breve exemplo de reprodutibilidade no PyTorch.\n",
    "\n",
    "Começaremos criando dois tensores aleatórios, já que são aleatórios, você esperaria que fossem diferentes, certo?\n",
    "\n",
    "Assim como você esperava, 2 tensores gerados aleatoriamente apresentam valores diferentes.\n",
    "\n",
    "Mas e se você quisesse criar dois tensores aleatórios com os mesmos valores. Tipo, os tensores ainda conteriam valores aleatórios, mas seriam os mesmos.\n",
    "\n",
    "É aí que entra torch.manual_seed(seed), onde seed é um número inteiro (como 42, mas pode ser qualquer coisa) que dá sabor à aleatoriedade.\n",
    "\n",
    "Vamos experimentar criando alguns tensores aleatórios com mais sabores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "39e57ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]]) \n",
      " tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
      "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
      "        [0.2696, 0.4414, 0.2969, 0.8317]])\n"
     ]
    }
   ],
   "source": [
    "RAMDOM_SEED = 42\n",
    "torch.manual_seed(RAMDOM_SEED) # Graças ao set da seed, o resultado é sempre o mesmo\n",
    "\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_C, '\\n', random_tensor_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af0a85b",
   "metadata": {},
   "source": [
    "# GPU\n",
    "\n",
    "Para treinar uma IA o ideal é ter acesso a uma GPU(unidade de processamento gráfico). como Os da Nvidea são os mais populares, pode-se verificar se o computador tem uma GPU com:\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "e para vê se o Pytorch tem acesso à GPU, usa-se o comando\n",
    "\n",
    "torch.cuda.is_available()\n",
    "<br>\n",
    "A saida deve ser: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b35c4d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7c997a",
   "metadata": {},
   "source": [
    "## Rodando o código na GPU\n",
    "\n",
    "por padrão, os códigos rodam na CPU, então precisamos colocar ela pra rodar na GPU, mas como?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9a6f476e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n",
      "tensor([1, 2, 3], device='cuda:0') cuda:0\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor, tensor.device) # Roda na CPU por padrão\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" # Use NVIDIA GPU (if available)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\" # Use Apple Silicon GPU (if available)\n",
    "else:\n",
    "    device = \"cpu\" # Default to CPU if no GPU is available\n",
    "\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "print(tensor_on_gpu, tensor_on_gpu.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c047069e",
   "metadata": {},
   "source": [
    "Voltando para CPU\n",
    "\n",
    "Numpy só consegue lidar com dados que estão na CPU, então é importante trazer os dados de volta para CPU em algum momento. Para fazer isso, deve-se usar:\n",
    "\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "- .cpu() → **copia** o tensor para a memória da CPU\n",
    "- .numpy() → converte o tensor CPU em array NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da1c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "specific",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
